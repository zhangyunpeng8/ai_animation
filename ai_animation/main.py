#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIé…éŸ³å·¥å‚ - è¶…å¼ºå˜´ç‚®ç‰ˆ 3.4.0 - AIåŠ¨ç”»ç”Ÿæˆé›†æˆç‰ˆ
é›†æˆäº†ComfyUIäººç‰©ä¸€è‡´æ€§å’ŒAIé©±åŠ¨åŠ¨ç”»ç”Ÿæˆ
ä½œè€…: AIåŠ©æ‰‹
ç‰ˆæœ¬: 3.4.0 - AIåŠ¨ç”»ç”Ÿæˆé›†æˆç‰ˆ
"""

import sys
import os
import json
import time
import logging
import warnings
import threading
import subprocess
import concurrent.futures
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any, Union
from pathlib import Path
from datetime import datetime
from enum import Enum
from queue import Queue, Empty
import hashlib
import re

# ç¬¬ä¸‰æ–¹åº“
try:
    import torch
    import torchaudio
    import numpy as np
    import whisper
    import librosa
    import soundfile as sf
    import requests
    from scipy import signal
    from scipy.interpolate import interp1d
    from scipy.signal import butter, filtfilt
    import ffmpeg
    import aiohttp
    import asyncio
    import cv2
    import base64
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
    print("è¯·è¿è¡Œ: pip install -r requirements.txt")
    sys.exit(1)

# GUIåº“
try:
    # å…ˆå¯¼å…¥åŸºç¡€æ¨¡å—
    from PySide6 import QtWidgets, QtCore, QtGui, QtMultimedia
    
    # ç„¶ååˆ›å»ºåˆ«å
    QApplication = QtWidgets.QApplication
    QMainWindow = QtWidgets.QMainWindow
    QWidget = QtWidgets.QWidget
    QVBoxLayout = QtWidgets.QVBoxLayout
    QHBoxLayout = QtWidgets.QHBoxLayout
    QPushButton = QtWidgets.QPushButton
    QLabel = QtWidgets.QLabel
    QLineEdit = QtWidgets.QLineEdit
    QTextEdit = QtWidgets.QTextEdit
    QListWidget = QtWidgets.QListWidget
    QListWidgetItem = QtWidgets.QListWidgetItem
    QFileDialog = QtWidgets.QFileDialog
    QGroupBox = QtWidgets.QGroupBox
    QSpinBox = QtWidgets.QSpinBox
    QComboBox = QtWidgets.QComboBox
    QCheckBox = QtWidgets.QCheckBox
    QProgressBar = QtWidgets.QProgressBar
    QMessageBox = QtWidgets.QMessageBox
    QTableWidget = QtWidgets.QTableWidget
    QTableWidgetItem = QtWidgets.QTableWidgetItem
    QHeaderView = QtWidgets.QHeaderView
    QTabWidget = QtWidgets.QTabWidget
    QDialog = QtWidgets.QDialog
    QDoubleSpinBox = QtWidgets.QDoubleSpinBox
    QSlider = QtWidgets.QSlider
    QSplitter = QtWidgets.QSplitter
    QFrame = QtWidgets.QFrame
    QRadioButton = QtWidgets.QRadioButton
    QButtonGroup = QtWidgets.QButtonGroup
    QScrollArea = QtWidgets.QScrollArea
    QProgressDialog = QtWidgets.QProgressDialog
    QStyleFactory = QtWidgets.QStyleFactory
    QInputDialog = QtWidgets.QInputDialog
    
    Qt = QtCore.Qt
    QThread = QtCore.QThread
    Signal = QtCore.Signal
    Slot = QtCore.Slot
    QTimer = QtCore.QTimer
    QUrl = QtCore.QUrl
    QSize = QtCore.QSize
    QPropertyAnimation = QtCore.QPropertyAnimation
    QEasingCurve = QtCore.QEasingCurve
    QPoint = QtCore.QPoint
    QRect = QtCore.QRect
    QEvent = QtCore.QEvent
    QObject = QtCore.QObject
    QRunnable = QtCore.QRunnable
    QThreadPool = QtCore.QThreadPool
    
    QFont = QtGui.QFont
    QFontDatabase = QtGui.QFontDatabase
    QIcon = QtGui.QIcon
    QPixmap = QtGui.QPixmap
    QColor = QtGui.QColor
    QPalette = QtGui.QPalette
    QBrush = QtGui.QBrush
    QLinearGradient = QtGui.QLinearGradient
    QAction = QtGui.QAction
    QKeySequence = QtGui.QKeySequence
    QShortcut = QtGui.QShortcut
    QPainter = QtGui.QPainter
    QPen = QtGui.QPen
    
    QMediaPlayer = QtMultimedia.QMediaPlayer
    QAudioOutput = QtMultimedia.QAudioOutput
    
except ImportError as e:
    print(f"âŒ ç¼ºå°‘PySide6: {e}")
    print("è¯·è¿è¡Œ: pip install PySide6")
    sys.exit(1)

# å°è¯•å¯¼å…¥OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAIåº“æœªå®‰è£…ï¼Œç›¸å…³åŠŸèƒ½å°†ä¸å¯ç”¨")
    print("   å®‰è£…: pip install openai>=1.0.0")

# å°è¯•å¯¼å…¥ComfyUIå®¢æˆ·ç«¯
try:
    from unified_comfyui_client import (
        UnifiedComfyUIClient,
        GenerationConfig,
        CharacterMethod,
        CharacterReference
    )
    COMFYUI_AVAILABLE = True
except ImportError:
    COMFYUI_AVAILABLE = False
    print("âš ï¸ ComfyUIå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼ŒAIåŠ¨ç”»ç”ŸæˆåŠŸèƒ½å°†å—é™")
    print("   è¯·ç¡®ä¿unified_comfyui_client.pyåœ¨åŒä¸€ç›®å½•ä¸‹")

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('dubbing_factory.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================================
# æ•°æ®ç±»å’Œæšä¸¾ - æ–°å¢åŠ¨ç”»ç›¸å…³
# ============================================

class VoiceStyle(Enum):
    """è¯­éŸ³é£æ ¼æšä¸¾"""
    LI_YUNLONG = "æäº‘é¾™"
    WANG_JINGZE = "ç‹å¢ƒæ³½"
    ZHANG_FEI = "å¼ é£"
    MA_BAOGUO = "é©¬ä¿å›½"
    XIE_GUANGKUN = "è°¢å¹¿å¤"
    LUO_XIANG = "ç½—ç¿”"
    GUO_DEGANG = "éƒ­å¾·çº²"
    SUN_XIAOCHUAN = "å­™ç¬‘å·"
    TONG_XIANGYU = "ä½Ÿæ¹˜ç‰"
    SHELDON = "è°¢å°”é¡¿"
    DEFAULT = "é»˜è®¤"

class AnimationStyle(Enum):
    """åŠ¨ç”»é£æ ¼æšä¸¾"""
    ANIME = "åŠ¨æ¼«"
    CINEMATIC = "ç”µå½±"
    CARTOON = "å¡é€š"
    REALISTIC = "å†™å®"
    PAINTERLY = "ç»˜ç”»"
    PIXEL_ART = "åƒç´ è‰ºæœ¯"

class LipSyncMethod(Enum):
    """å£å‹åŒæ­¥æ–¹æ³•æšä¸¾"""
    WHISPER_PHONEMES = "WhisperéŸ³ç´ åˆ†æ"
    VISEME_BASED = "è§†ä½ç´ æ˜ å°„"
    DEEP_SPEECH = "æ·±åº¦è¯­éŸ³åˆ†æ"
    S2P = "è¯­éŸ³è½¬éŸ³ç´ "

class ExpressionType(Enum):
    """è¡¨æƒ…ç±»å‹æšä¸¾"""
    NEUTRAL = "ä¸­æ€§"
    HAPPY = "å¼€å¿ƒ"
    SAD = "æ‚²ä¼¤"
    ANGRY = "æ„¤æ€’"
    SURPRISED = "æƒŠè®¶"
    FEARFUL = "å®³æ€•"
    DISGUSTED = "åŒæ¶"
    EXCITED = "å…´å¥‹"
    THINKING = "æ€è€ƒ"
    SPEAKING = "è¯´è¯"

class ProcessingStage(Enum):
    """å¤„ç†é˜¶æ®µæšä¸¾"""
    INIT = "åˆå§‹åŒ–"
    EXTRACT_AUDIO = "æå–éŸ³é¢‘"
    TRANSCRIBE = "è¯­éŸ³è¯†åˆ«"
    BATCH_TRANSLATE = "æ‰¹é‡ç¿»è¯‘"
    BATCH_STYLE = "æ‰¹é‡é£æ ¼è½¬æ¢"
    BATCH_TTS = "æ‰¹é‡è¯­éŸ³ç”Ÿæˆ"
    AUDIO_MIX = "éŸ³é¢‘æ··åˆ"
    LIP_SYNC = "å£å‹å¯¹é½"
    VIDEO_SYNTHESIS = "è§†é¢‘åˆæˆ"
    ANIMATION_GENERATION = "AIåŠ¨ç”»ç”Ÿæˆ"
    COMPLETE = "å®Œæˆ"

@dataclass
class CharacterProfile:
    """è§’è‰²é…ç½®æ–‡ä»¶"""
    name: str
    original_name: str
    voice_style: VoiceStyle
    voice_file: str = ""
    speed: float = 1.0
    pitch: float = 1.0
    emotion: str = "neutral"
    intensity: float = 1.0
    catchphrases: List[str] = field(default_factory=list)
    reference_image: str = ""  # æ–°å¢ï¼šåŠ¨ç”»å‚è€ƒå›¾ç‰‡
    
    @classmethod
    def get_preset(cls, char_name: str) -> 'CharacterProfile':
        """è·å–é¢„è®¾è§’è‰²é…ç½®"""
        presets = {
            "å“†å•¦Aæ¢¦": cls(
                name="å“†å•¦Aæ¢¦",
                original_name="ãƒ‰ãƒ©ãˆã‚‚ã‚“",
                voice_style=VoiceStyle.LI_YUNLONG,
                speed=1.2,
                pitch=1.1,
                emotion="aggressive",
                intensity=1.5,
                catchphrases=["ä»–å¨˜çš„", "è€å­", "è¿™ä»—æ€ä¹ˆæ‰“", "çœŸä»–å¨˜çš„ç—›å¿«"]
            ),
            "å¤§é›„": cls(
                name="å¤§é›„",
                original_name="é‡æ¯”ã®ã³å¤ª",
                voice_style=VoiceStyle.WANG_JINGZE,
                speed=0.9,
                pitch=0.9,
                emotion="whiny",
                intensity=1.2,
                catchphrases=["çœŸé¦™", "æˆ‘ç‹å¢ƒæ³½å°±æ˜¯é¥¿æ­»", "å“å‘€å¦ˆå‘€", "è¿™ä¸å¯èƒ½"]
            ),
            "é™é¦™": cls(
                name="é™é¦™",
                original_name="æºé™é¦™",
                voice_style=VoiceStyle.TONG_XIANGYU,
                speed=1.3,
                pitch=1.2,
                emotion="chatty",
                intensity=1.3,
                catchphrases=["é¢æ»´ç¥å•Š", "æˆ‘å¥½åæ‚”å‘€", "è¿™æ˜¯ä¸ºä½ å¥½", "ä½ å¬æˆ‘è¯´"]
            ),
            "èƒ–è™": cls(
                name="èƒ–è™",
                original_name="å‰›ç”°æ­¦",
                voice_style=VoiceStyle.ZHANG_FEI,
                speed=1.5,
                pitch=0.8,
                emotion="angry",
                intensity=2.0,
                catchphrases=["ä¿ºä¹Ÿä¸€æ ·", "ç‡•äººå¼ é£åœ¨æ­¤", "å“‡å‘€å‘€å‘€", "æ‹¿å‘½æ¥"]
            ),
            "å°å¤«": cls(
                name="å°å¤«",
                original_name="éª¨å·ã‚¹ãƒå¤«",
                voice_style=VoiceStyle.MA_BAOGUO,
                speed=1.1,
                pitch=1.0,
                emotion="arrogant",
                intensity=1.4,
                catchphrases=["å¹´è½»äººä¸è®²æ­¦å¾·", "æˆ‘å¤§æ„äº†å•Š", "è€—å­å°¾æ±", "æ¥åŒ–å‘"]
            ),
            "å“†å•¦ç¾": cls(
                name="å“†å•¦ç¾",
                original_name="ãƒ‰ãƒ©ãƒŸ",
                voice_style=VoiceStyle.LUO_XIANG,
                speed=1.4,
                pitch=1.3,
                emotion="lecturing",
                intensity=1.6,
                catchphrases=["å¼ ä¸‰åˆæ¥äº†", "è¿™æ˜¯è¿æ³•è¡Œä¸º", "æ ¹æ®åˆ‘æ³•", "æ³•æ²»ç¤¾ä¼š"]
            ),
            "å‡ºæœ¨æ‰": cls(
                name="å‡ºæœ¨æ‰",
                original_name="å‡ºæœ¨æ‰è‹±æ‰",
                voice_style=VoiceStyle.SHELDON,
                speed=2.0,
                pitch=1.0,
                emotion="condescending",
                intensity=1.7,
                catchphrases=["Bazinga", "æˆ‘æ—©è¯´è¿‡äº†", "è¿™å¾ˆæ˜æ˜¾", "æ ¹æ®æˆ‘çš„è®¡ç®—"]
            ),
            "å°å®å½“": cls(
                name="å°å®å½“",
                original_name="",
                voice_style=VoiceStyle.GUO_DEGANG,
                speed=1.3,
                pitch=1.1,
                emotion="humorous",
                intensity=1.5,
                catchphrases=["äºè°¦çš„çˆ¶äº²", "ç›¸å£°è®²ç©¶è¯´å­¦é€—å”±", "æˆ‘å­—ç³»åˆ—", "ä½ è¦è€ƒç ”å•Š"]
            ),
            "çˆ¸çˆ¸": cls(
                name="çˆ¸çˆ¸",
                original_name="é‡æ¯”ä¼¸åŠ©",
                voice_style=VoiceStyle.XIE_GUANGKUN,
                speed=1.0,
                pitch=0.9,
                emotion="grumpy",
                intensity=1.4,
                catchphrases=["æ°¸å¼ºå•Š", "åˆ˜èƒ½ä¸æ˜¯ä¸œè¥¿", "å¹¿å¤å¾ˆç”Ÿæ°”", "è¿™äº‹æ²¡å®Œ"]
            ),
            "å¦ˆå¦ˆ": cls(
                name="å¦ˆå¦ˆ",
                original_name="é‡æ¯”ç‰å­",
                voice_style=VoiceStyle.SUN_XIAOCHUAN,
                speed=1.2,
                pitch=1.0,
                emotion="complaining",
                intensity=1.3,
                catchphrases=["ä½ å¦ˆæ­»äº†", "å¸¦å“¥ä»¬", "æŠ½è±¡", "ç¼åˆæ€ª"]
            )
        }
        return presets.get(char_name, cls(
            name=char_name,
            original_name=char_name,
            voice_style=VoiceStyle.DEFAULT
        ))

@dataclass
class AnimationConfig:
    """åŠ¨ç”»é…ç½®"""
    resolution: tuple = (512, 768)
    fps: int = 24
    duration: float = 10.0
    style: AnimationStyle = AnimationStyle.ANIME
    background: str = ""
    seed: int = -1
    character_reference: str = ""
    consistency_method: CharacterMethod = CharacterMethod.IP_ADAPTER
    consistency_strength: float = 0.7
    character_scale: float = 0.8
    lip_sync_enabled: bool = True
    lip_sync_method: LipSyncMethod = LipSyncMethod.WHISPER_PHONEMES
    expression_enabled: bool = True
    head_movement_enabled: bool = True
    eye_movement_enabled: bool = True
    body_movement_enabled: bool = True
    scene_description: str = ""
    camera_movement: str = "subtle"
    lighting: str = "natural"
    output_format: str = "mp4"
    output_quality: str = "high"

@dataclass
class CharacterModel:
    """è§’è‰²æ¨¡å‹ï¼ˆç”¨äºåŠ¨ç”»ç”Ÿæˆï¼‰"""
    name: str
    reference_images: List[str] = field(default_factory=list)
    voice_profile: Optional[CharacterProfile] = None
    animation_config: Dict[str, Any] = field(default_factory=dict)
    
    def add_reference_image(self, image_path: str):
        """æ·»åŠ å‚è€ƒå›¾ç‰‡"""
        if os.path.exists(image_path):
            self.reference_images.append(image_path)
            logger.info(f"ä¸ºè§’è‰² {self.name} æ·»åŠ å‚è€ƒå›¾ç‰‡: {image_path}")
        else:
            logger.warning(f"å‚è€ƒå›¾ç‰‡ä¸å­˜åœ¨: {image_path}")

@dataclass
class AnimationSegment:
    """åŠ¨ç”»ç‰‡æ®µ"""
    id: int
    start_time: float
    end_time: float
    text: str
    character: str = "main_character"
    expression: ExpressionType = ExpressionType.SPEAKING
    audio_data: Optional[np.ndarray] = None
    lip_sync_data: Optional[Dict] = None
    prompt: str = ""
    
    def __post_init__(self):
        self.duration = self.end_time - self.start_time

@dataclass
class AudioSegment:
    """éŸ³é¢‘ç‰‡æ®µæ•°æ®ç±»"""
    id: int
    start_time: float
    end_time: float
    text: str
    translated_text: str = ""
    styled_text: str = ""
    character: str = "unknown"
    confidence: float = 0.0
    audio_data: Optional[np.ndarray] = None
    sample_rate: int = 24000
    file_path: str = ""
    volume: float = 1.0
    background: bool = False
    
    def __post_init__(self):
        self.duration = self.end_time - self.start_time
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "id": self.id,
            "start_time": self.start_time,
            "end_time": self.end_time,
            "duration": self.duration,
            "text": self.text,
            "translated_text": self.translated_text,
            "styled_text": self.styled_text,
            "character": self.character,
            "confidence": self.confidence,
            "sample_rate": self.sample_rate,
            "file_path": self.file_path,
            "volume": self.volume,
            "background": self.background
        }

class AudioPostProcessor:
    """éŸ³é¢‘åå¤„ç†å™¨ - ä¼˜åŒ–å£å‹å¯¹é½"""
    
    def __init__(self, config):
        self.config = config
    
    def align_to_lip_sync(self, video_path: str, audio_path: str) -> str:
        """å£å‹åŒæ­¥å¯¹é½"""
        logger.info("è¿›è¡Œå£å‹åŒæ­¥å¯¹é½")
        
        try:
            audio, sr = sf.read(audio_path)
            
            video_info = self._get_video_info(video_path)
            if video_info and 'duration' in video_info:
                video_duration = video_info['duration']
                audio_duration = len(audio) / sr
                
                if abs(video_duration - audio_duration) / video_duration > 0.05:
                    stretch_factor = video_duration / audio_duration
                    if 0.8 <= stretch_factor <= 1.2:
                        try:
                            from librosa.effects import time_stretch
                            audio = time_stretch(audio, rate=1/stretch_factor)
                        except:
                            current_samples = len(audio)
                            target_samples = int(current_samples * stretch_factor)
                            if current_samples > 1:
                                x_old = np.linspace(0, 1, current_samples)
                                x_new = np.linspace(0, 1, target_samples)
                                f = interp1d(x_old, audio, kind='linear')
                                audio = f(x_new)
            
            temp_dir = Path(self.config.temp_dir)
            temp_dir.mkdir(exist_ok=True)
            output_path = temp_dir / "aligned_audio.wav"
            sf.write(str(output_path), audio, self.config.sample_rate)
            
            logger.info(f"å£å‹å¯¹é½å®Œæˆï¼Œä¿å­˜åˆ°: {output_path}")
            return str(output_path)
            
        except Exception as e:
            logger.warning(f"å£å‹å¯¹é½å¤±è´¥ï¼Œä½¿ç”¨åŸéŸ³é¢‘: {e}")
            return audio_path
    
    def _get_video_info(self, video_path: str) -> Optional[Dict]:
        """è·å–è§†é¢‘ä¿¡æ¯"""
        try:
            cmd = [
                'ffprobe',
                '-v', 'quiet',
                '-print_format', 'json',
                '-show_format',
                '-show_streams',
                video_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                info = json.loads(result.stdout)
                video_info = {}
                
                if 'format' in info and 'duration' in info['format']:
                    video_info['duration'] = float(info['format']['duration'])
                
                for stream in info.get('streams', []):
                    if stream.get('codec_type') == 'video':
                        if 'avg_frame_rate' in stream:
                            frame_rate = stream['avg_frame_rate']
                            if '/' in frame_rate:
                                num, den = map(int, frame_rate.split('/'))
                                if den > 0:
                                    video_info['frame_rate'] = num / den
                        break
                
                return video_info
                
        except Exception as e:
            logger.warning(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        
        return None

@dataclass
class ProcessingConfig:
    """å¤„ç†é…ç½®"""
    input_video: str = ""
    output_video: str = ""
    temp_dir: str = "temp"
    sample_rate: int = 24000
    bit_depth: int = 16
    channels: int = 2
    use_gpu: bool = True
    gpu_id: int = 0
    batch_size: int = 4
    num_workers: int = 4
    cache_enabled: bool = True
    cache_dir: str = "cache"
    whisper_model: str = "large-v3"
    translate_model: str = "qwen3:4b"
    tts_api_url: str = "http://127.0.0.1:5021/api/tts"
    ollama_url: str = "http://127.0.0.1:11434"
    keep_background: bool = True
    background_volume: float = 0.3
    voice_volume: float = 0.8
    noise_reduction: bool = True
    normalize_audio: bool = True
    fade_duration: float = 0.05
    translate_to_chinese: bool = True
    use_style_transfer: bool = True
    add_catchphrases: bool = True
    catchphrase_probability: float = 0.3
    translation_batch_size: int = 10
    tts_batch_size: int = 3
    lip_sync_enabled: bool = True
    lip_sync_strength: float = 0.8
    lip_sync_method: str = "æ—¶é—´æ‹‰ä¼¸"
    
    def __post_init__(self):
        if not self.output_video and self.input_video:
            input_path = Path(self.input_video)
            self.output_video = str(input_path.with_stem(f"{input_path.stem}_dubbed"))
    
    def get_ollama_api_url(self) -> str:
        """è·å–Ollama API URL"""
        base_url = self.ollama_url.rstrip('/')
        
        patterns_to_remove = ['/v1', '/api/generate', '/api/chat', '/api/']
        
        for pattern in patterns_to_remove:
            if base_url.endswith(pattern):
                base_url = base_url[:-len(pattern)]
                base_url = base_url.rstrip('/')
            elif pattern in base_url:
                parts = base_url.split(pattern)
                base_url = parts[0].rstrip('/')
                break
        
        if not base_url.startswith('http'):
            base_url = 'http://' + base_url
        
        api_url = f"{base_url}/api/generate"
        
        logger.debug(f"ç”Ÿæˆçš„API URL: {api_url}")
        return api_url

# ============================================
# AIåŠ¨ç”»ç”Ÿæˆå™¨ç±»
# ============================================

class AIAnimationGenerator:
    """AIåŠ¨ç”»ç”Ÿæˆå™¨ - é›†æˆComfyUIäººç‰©ä¸€è‡´æ€§"""
    
    def __init__(self, config: AnimationConfig, comfyui_host: str = "127.0.0.1", comfyui_port: int = 8188):
        self.config = config
        self.comfyui_host = comfyui_host
        self.comfyui_port = comfyui_port
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.comfyui_client = None
        if COMFYUI_AVAILABLE:
            self.comfyui_client = UnifiedComfyUIClient(
                host=comfyui_host,
                port=comfyui_port
            )
        
        # å­˜å‚¨æ•°æ®
        self.characters: Dict[str, CharacterModel] = {}
        self.segments: List[AnimationSegment] = []
        self.generated_frames: List[Dict] = []
        
        # è¾“å‡ºç›®å½•
        self.output_dir = Path("ai_animation_output")
        self.output_dir.mkdir(exist_ok=True)
        
        logger.info("AIåŠ¨ç”»ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self):
        """åˆå§‹åŒ–è¿æ¥"""
        logger.info("æ­£åœ¨åˆå§‹åŒ–AIåŠ¨ç”»ç”Ÿæˆå™¨...")
        
        if not COMFYUI_AVAILABLE:
            logger.error("ComfyUIå®¢æˆ·ç«¯ä¸å¯ç”¨")
            raise ImportError("ComfyUIå®¢æˆ·ç«¯æœªæ‰¾åˆ°")
        
        if not self.comfyui_client:
            logger.error("ComfyUIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return False
        
        # è¿æ¥åˆ°ComfyUI
        logger.info(f"æ­£åœ¨è¿æ¥åˆ°ComfyUI: {self.comfyui_host}:{self.comfyui_port}")
        connected = await self.comfyui_client.connect()
        
        if not connected:
            logger.error("æ— æ³•è¿æ¥åˆ°ComfyUIæœåŠ¡å™¨")
            raise ConnectionError("ComfyUIæœåŠ¡å™¨è¿æ¥å¤±è´¥")
        
        logger.info("âœ… AIåŠ¨ç”»ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
        return True
    
    def add_character(self, character: CharacterModel):
        """æ·»åŠ è§’è‰²"""
        self.characters[character.name] = character
        logger.info(f"å·²æ·»åŠ è§’è‰²: {character.name}")
    
    def create_character_from_profile(self, profile: CharacterProfile, reference_image: str) -> CharacterModel:
        """ä»é…éŸ³è§’è‰²é…ç½®åˆ›å»ºåŠ¨ç”»è§’è‰²"""
        character = CharacterModel(
            name=profile.name,
            voice_profile=profile,
            animation_config={
                "style": self.config.style,
                "consistency_method": self.config.consistency_method,
                "consistency_strength": self.config.consistency_strength
            }
        )
        
        character.add_reference_image(reference_image)
        return character
    
    async def process_script(self, script_path: str):
        """å¤„ç†å‰§æœ¬"""
        logger.info(f"å¤„ç†å‰§æœ¬: {script_path}")
        
        try:
            with open(script_path, 'r', encoding='utf-8') as f:
                script_content = f.read()
            
            lines = script_content.strip().split('\n')
            segments = []
            
            current_time = 0.0
            for i, line in enumerate(lines):
                if line.strip() and not line.startswith('#'):
                    segment_duration = 3.0
                    
                    parts = line.split(':', 1)
                    if len(parts) == 2:
                        character_name, dialogue = parts
                        character_name = character_name.strip()
                        dialogue = dialogue.strip()
                    else:
                        character_name = "æœªçŸ¥è§’è‰²"
                        dialogue = line.strip()
                    
                    if character_name in self.characters:
                        character = character_name
                    else:
                        character = list(self.characters.keys())[0] if self.characters else "main_character"
                    
                    expression = self._detect_expression(dialogue)
                    
                    segment = AnimationSegment(
                        id=i,
                        start_time=current_time,
                        end_time=current_time + segment_duration,
                        text=dialogue,
                        character=character,
                        expression=expression,
                        prompt=self._generate_animation_prompt(dialogue, character, expression)
                    )
                    
                    segments.append(segment)
                    current_time += segment_duration
            
            self.segments = segments
            logger.info(f"è§£æå®Œæˆ: {len(segments)}ä¸ªåŠ¨ç”»ç‰‡æ®µ")
            
            return segments
            
        except Exception as e:
            logger.error(f"å‰§æœ¬å¤„ç†å¤±è´¥: {e}")
            raise
    
    def _detect_expression(self, text: str) -> ExpressionType:
        """æ£€æµ‹è¡¨æƒ…"""
        text_lower = text.lower()
        
        if any(word in text_lower for word in ["å“ˆå“ˆ", "å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "laugh", "happy", "smile"]):
            return ExpressionType.HAPPY
        elif any(word in text_lower for word in ["æ‚²ä¼¤", "ä¼¤å¿ƒ", "éš¾è¿‡", "å“­", "sad", "cry", "unhappy"]):
            return ExpressionType.SAD
        elif any(word in text_lower for word in ["ç”Ÿæ°”", "æ„¤æ€’", "å‘ç«", "angry", "mad", "furious"]):
            return ExpressionType.ANGRY
        elif any(word in text_lower for word in ["æƒŠè®¶", "åƒæƒŠ", "éœ‡æƒŠ", "surprise", "shock", "amazed"]):
            return ExpressionType.SURPRISED
        elif any(word in text_lower for word in ["å®³æ€•", "ææƒ§", "ææ€–", "fear", "scared", "afraid"]):
            return ExpressionType.FEARFUL
        elif any(word in text_lower for word in ["æ¶å¿ƒ", "åŒæ¶", "è®¨åŒ", "disgust", "dislike", "hate"]):
            return ExpressionType.DISGUSTED
        elif any(word in text_lower for word in ["å…´å¥‹", "æ¿€åŠ¨", "excited", "thrilled", "energetic"]):
            return ExpressionType.EXCITED
        elif any(word in text_lower for word in ["æ€è€ƒ", "è€ƒè™‘", "æƒ³", "think", "consider", "ponder"]):
            return ExpressionType.THINKING
        else:
            return ExpressionType.SPEAKING
    
    def _generate_animation_prompt(self, dialogue: str, character: str, expression: ExpressionType) -> str:
        """ç”ŸæˆåŠ¨ç”»æç¤ºè¯"""
        character_model = self.characters.get(character)
        
        base_prompt = f"{self.config.style.value} style, "
        
        if character_model and character_model.voice_profile:
            char_desc = character_model.voice_profile.name
        else:
            char_desc = character
        
        expression_map = {
            ExpressionType.HAPPY: "smiling happily, cheerful expression",
            ExpressionType.SAD: "sad expression, looking down, tearful eyes",
            ExpressionType.ANGRY: "angry expression, furrowed brows, clenched teeth",
            ExpressionType.SURPRISED: "surprised expression, wide eyes, open mouth",
            ExpressionType.FEARFUL: "fearful expression, scared, trembling",
            ExpressionType.DISGUSTED: "disgusted expression, wrinkled nose",
            ExpressionType.EXCITED: "excited expression, enthusiastic, energetic",
            ExpressionType.THINKING: "thinking expression, contemplative, hand on chin",
            ExpressionType.SPEAKING: "speaking, mouth open",
            ExpressionType.NEUTRAL: "neutral expression"
        }
        
        scene_desc = self.config.scene_description if self.config.scene_description else "clean background, cinematic lighting"
        
        prompt = f"{base_prompt}{char_desc}, {expression_map[expression]}, {scene_desc}, "
        prompt += f"full body shot, dynamic pose, {self.config.lighting} lighting, "
        prompt += f"high quality, detailed, 4k, masterpiece"
        
        prompt += f', saying: "{dialogue[:50]}"'
        
        return prompt
    
    async def analyze_lip_sync(self, audio_path: str, segments: List[AnimationSegment]) -> List[Dict]:
        """åˆ†æå£å‹åŒæ­¥æ•°æ®"""
        logger.info("åˆ†æå£å‹åŒæ­¥æ•°æ®...")
        
        if not self.config.lip_sync_enabled:
            logger.info("å£å‹åŒæ­¥å·²ç¦ç”¨")
            return []
        
        lip_sync_data = []
        
        for segment in segments:
            try:
                phoneme_data = {
                    "segment_id": segment.id,
                    "start_time": segment.start_time,
                    "end_time": segment.end_time,
                    "phonemes": self._extract_phonemes(segment.text),
                    "viseme_frames": self._generate_viseme_frames(segment)
                }
                
                segment.lip_sync_data = phoneme_data
                lip_sync_data.append(phoneme_data)
                
                logger.debug(f"åˆ†æç‰‡æ®µ {segment.id} å£å‹æ•°æ®")
                
            except Exception as e:
                logger.warning(f"ç‰‡æ®µ {segment.id} å£å‹åˆ†æå¤±è´¥: {e}")
                segment.lip_sync_data = None
        
        logger.info(f"âœ… å£å‹åŒæ­¥åˆ†æå®Œæˆ: {len(lip_sync_data)}ä¸ªç‰‡æ®µ")
        return lip_sync_data
    
    def _extract_phonemes(self, text: str) -> List[Dict]:
        """æå–éŸ³ç´ """
        phoneme_map = {
            'a': 'AA', 'i': 'IH', 'u': 'UW', 'e': 'EH', 'o': 'AO',
            'b': 'B', 'p': 'P', 'm': 'M', 'f': 'F', 'd': 'D',
            't': 'T', 'n': 'N', 'l': 'L', 'g': 'G', 'k': 'K',
            'h': 'HH', 'j': 'Y', 'q': 'CH', 'x': 'SH', 'zh': 'ZH',
            'ch': 'CH', 'sh': 'SH', 'r': 'R', 'z': 'Z', 'c': 'TS',
            's': 'S', 'y': 'Y', 'w': 'W'
        }
        
        phonemes = []
        for char in text.lower():
            if char in phoneme_map:
                phonemes.append({
                    "phoneme": phoneme_map[char],
                    "duration": 0.1
                })
        
        return phonemes
    
    def _generate_viseme_frames(self, segment: AnimationSegment) -> List[Dict]:
        """ç”Ÿæˆè§†ä½ç´ å¸§"""
        frames = []
        fps = self.config.fps
        duration = segment.duration
        total_frames = int(fps * duration)
        
        for frame_idx in range(total_frames):
            frame_time = segment.start_time + (frame_idx / fps)
            
            viseme = "rest"
            
            if segment.expression == ExpressionType.SPEAKING:
                time_in_segment = frame_time - segment.start_time
                cycle = (time_in_segment * 5) % 1.0
                
                if cycle < 0.3:
                    viseme = "AA"
                elif cycle < 0.6:
                    viseme = "IH"
                else:
                    viseme = "MM"
            
            frames.append({
                "frame": frame_idx,
                "time": frame_time,
                "viseme": viseme,
                "mouth_openness": 0.5 if viseme == "AA" else 0.2
            })
        
        return frames
    
    async def generate_animation_frames(self, segments: List[AnimationSegment]) -> List[Dict]:
        """ç”ŸæˆåŠ¨ç”»å¸§"""
        logger.info("å¼€å§‹ç”ŸæˆåŠ¨ç”»å¸§...")
        
        generated_frames = []
        
        for segment in segments:
            logger.info(f"ç”ŸæˆåŠ¨ç”»ç‰‡æ®µ {segment.id}: {segment.text[:30]}...")
            
            try:
                character_model = self.characters.get(segment.character)
                if not character_model:
                    logger.warning(f"è§’è‰² {segment.character} æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")
                    character_model = next(iter(self.characters.values())) if self.characters else None
                
                if character_model and character_model.reference_images:
                    reference_image = character_model.reference_images[0]
                    
                    uploaded_name = await self.comfyui_client.upload_image(
                        Path(reference_image)
                    )
                    
                    enhanced_prompt = self._enhance_prompt_with_animation(
                        segment.prompt, segment, character_model
                    )
                    
                    result = await self.comfyui_client.generate_character(
                        reference_image=reference_image,
                        prompt=enhanced_prompt,
                        method=self.config.consistency_method,
                        strength=self.config.consistency_strength,
                        config=self._create_generation_config(),
                        output_dir=self.output_dir / "frames" / f"segment_{segment.id}"
                    )
                    
                    if result.get("success") and result.get("images"):
                        for img_info in result["images"]:
                            generated_frames.append({
                                "segment_id": segment.id,
                                "frame_path": img_info.get("filename", ""),
                                "time": segment.start_time,
                                "prompt": enhanced_prompt
                            })
                        
                        logger.info(f"âœ… ç‰‡æ®µ {segment.id} ç”ŸæˆæˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ ç‰‡æ®µ {segment.id} ç”Ÿæˆå¤±è´¥: {result.get('error')}")
                
                else:
                    result = await self.comfyui_client.generate_image(
                        prompt=segment.prompt,
                        config=self._create_generation_config(),
                        output_dir=self.output_dir / "frames" / f"segment_{segment.id}"
                    )
                    
                    if result.get("success"):
                        logger.info(f"âœ… ç‰‡æ®µ {segment.id} ç”ŸæˆæˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ ç‰‡æ®µ {segment.id} ç”Ÿæˆå¤±è´¥")
                
            except Exception as e:
                logger.error(f"âŒ ç‰‡æ®µ {segment.id} ç”Ÿæˆå¼‚å¸¸: {e}")
            
            await asyncio.sleep(1)
        
        self.generated_frames = generated_frames
        logger.info(f"âœ… åŠ¨ç”»å¸§ç”Ÿæˆå®Œæˆ: {len(generated_frames)}ä¸ªå¸§")
        return generated_frames
    
    def _enhance_prompt_with_animation(self, base_prompt: str, segment: AnimationSegment, character_model: CharacterModel) -> str:
        """å¢å¼ºæç¤ºè¯ï¼Œæ·»åŠ åŠ¨ç”»å…ƒç´ """
        enhanced = base_prompt
        
        if self.config.lip_sync_enabled and segment.lip_sync_data:
            if segment.lip_sync_data.get("viseme_frames"):
                first_frame = segment.lip_sync_data["viseme_frames"][0]
                mouth_state = "open mouth" if first_frame.get("mouth_openness", 0) > 0.4 else "closed mouth"
                enhanced += f", {mouth_state}"
        
        expression_map = {
            ExpressionType.HAPPY: "smiling, cheerful expression",
            ExpressionType.SAD: "sad expression, tearful eyes",
            ExpressionType.ANGRY: "angry expression, furrowed brows",
            ExpressionType.SURPRISED: "surprised expression, wide eyes",
            ExpressionType.FEARFUL: "fearful expression, scared look",
            ExpressionType.DISGUSTED: "disgusted expression",
            ExpressionType.EXCITED: "excited expression, enthusiastic",
            ExpressionType.THINKING: "thinking expression, contemplative",
            ExpressionType.SPEAKING: "speaking expression",
            ExpressionType.NEUTRAL: "neutral expression"
        }
        
        enhanced += f", {expression_map.get(segment.expression, 'neutral expression')}"
        
        if self.config.head_movement_enabled:
            head_motions = ["subtle head turn", "slight nod", "head tilt", "looking forward"]
            motion = head_motions[segment.id % len(head_motions)]
            enhanced += f", {motion}"
        
        if self.config.eye_movement_enabled:
            eye_actions = ["looking at viewer", "eye contact", "blinking", "focused gaze"]
            action = eye_actions[segment.id % len(eye_actions)]
            enhanced += f", {action}"
        
        if self.config.body_movement_enabled and segment.id % 3 == 0:
            body_poses = ["hand gesture", "leaning forward", "relaxed posture", "dynamic pose"]
            pose = body_poses[segment.id % len(body_poses)]
            enhanced += f", {pose}"
        
        camera_angles = ["medium shot", "close-up", "full body", "cinematic framing"]
        angle = camera_angles[segment.id % len(camera_angles)]
        enhanced += f", {angle}, {self.config.camera_movement} camera movement"
        
        return enhanced
    
    def _create_generation_config(self) -> GenerationConfig:
        """åˆ›å»ºç”Ÿæˆé…ç½®"""
        width, height = self.config.resolution
        
        return GenerationConfig(
            width=width,
            height=height,
            steps=25,
            cfg=7.0,
            sampler="dpmpp_2m",
            scheduler="karras",
            seed=self.config.seed if self.config.seed != -1 else -1,
            batch_size=1,
            model="sd15.safetensors",
            vae="auto"
        )
    
    async def assemble_animation(self, frames: List[Dict], audio_path: Optional[str] = None) -> str:
        """ç»„è£…åŠ¨ç”»"""
        logger.info("å¼€å§‹ç»„è£…åŠ¨ç”»...")
        
        try:
            output_video_path = self.output_dir / f"animation_{int(time.time())}.{self.config.output_format}"
            
            if frames:
                sorted_frames = sorted(frames, key=lambda x: x.get("time", 0))
                
                width, height = self.config.resolution
                fps = self.config.fps
                
                frame_video_path = self.output_dir / "frame_sequence.mp4"
                self._create_frame_sequence(sorted_frames, str(frame_video_path), fps, (width, height))
                
                if audio_path and os.path.exists(audio_path):
                    self._merge_audio_with_video(str(frame_video_path), audio_path, str(output_video_path))
                else:
                    output_video_path = frame_video_path
                
                logger.info(f"âœ… åŠ¨ç”»ç»„è£…å®Œæˆ: {output_video_path}")
                return str(output_video_path)
            else:
                logger.warning("æ²¡æœ‰å¸§æ•°æ®å¯ä¾›ç»„è£…")
                return ""
                
        except Exception as e:
            logger.error(f"åŠ¨ç”»ç»„è£…å¤±è´¥: {e}")
            return ""
    
    def _create_frame_sequence(self, frames: List[Dict], output_path: str, fps: int, resolution: tuple):
        """åˆ›å»ºå¸§åºåˆ—è§†é¢‘"""
        width, height = resolution
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        for frame_data in frames:
            frame = np.zeros((height, width, 3), dtype=np.uint8)
            
            segment_id = frame_data.get("segment_id", 0)
            text = f"åŠ¨ç”»å¸§ {segment_id}"
            cv2.putText(frame, text, (50, height//2), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            for _ in range(fps):
                out.write(frame)
        
        out.release()
        logger.info(f"åˆ›å»ºå¸§åºåˆ—è§†é¢‘: {output_path}")
    
    def _merge_audio_with_video(self, video_path: str, audio_path: str, output_path: str):
        """åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘"""
        try:
            cmd = [
                'ffmpeg',
                '-i', video_path,
                '-i', audio_path,
                '-c:v', 'copy',
                '-c:a', 'aac',
                '-shortest',
                '-y',
                output_path
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            logger.info(f"éŸ³é¢‘è§†é¢‘åˆå¹¶å®Œæˆ: {output_path}")
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘è§†é¢‘åˆå¹¶å¤±è´¥: {e}")
            import shutil
            shutil.copy(video_path, output_path)
    
    async def generate_complete_animation(self, script_path: str) -> str:
        """ç”Ÿæˆå®Œæ•´åŠ¨ç”»"""
        logger.info("å¼€å§‹ç”Ÿæˆå®Œæ•´åŠ¨ç”»...")
        
        try:
            await self.initialize()
            
            segments = await self.process_script(script_path)
            
            audio_path = self.output_dir / "dubbed_audio.wav"
            
            if self.config.lip_sync_enabled:
                await self.analyze_lip_sync(str(audio_path), segments)
            
            frames = await self.generate_animation_frames(segments)
            
            final_animation = await self.assemble_animation(frames, str(audio_path) if os.path.exists(str(audio_path)) else None)
            
            if final_animation:
                logger.info(f"ğŸ‰ åŠ¨ç”»ç”Ÿæˆå®Œæˆ: {final_animation}")
                return final_animation
            else:
                logger.error("åŠ¨ç”»ç”Ÿæˆå¤±è´¥")
                return ""
                
        except Exception as e:
            logger.error(f"åŠ¨ç”»ç”Ÿæˆè¿‡ç¨‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return ""

# ============================================
# OpenAIé›†æˆç±»
# ============================================

class OpenAIIntegration:
    """OpenAIæ¥å£é›†æˆ"""
    
    def __init__(self, api_key: str, base_url: str = "https://apis.iflow.cn/v1"):
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAIåº“æœªå®‰è£…")
        
        self.client = OpenAI(
            base_url=base_url,
            api_key=api_key
        )
        self.model = "deepseek-v3"
    
    def generate_script_analysis(self, script: str) -> Dict:
        """ç”Ÿæˆå‰§æœ¬åˆ†æ"""
        prompt = f"""
        åˆ†æä»¥ä¸‹å‰§æœ¬ï¼Œæå–å…³é”®ä¿¡æ¯ï¼š
        1. è§’è‰²åˆ—è¡¨
        2. æ¯ä¸ªè§’è‰²çš„å°è¯
        3. æƒ…æ„Ÿå˜åŒ–
        4. å»ºè®®çš„åŠ¨ç”»åœºæ™¯
        5. æ‘„åƒæœºè§’åº¦å»ºè®®
        
        å‰§æœ¬ï¼š
        {script}
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
        """
        
        try:
            completion = self.client.chat.completions.create(
                extra_body={},
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            response = completion.choices[0].message.content
            
            try:
                analysis = json.loads(response)
                return analysis
            except:
                return {"raw_analysis": response}
                
        except Exception as e:
            logger.error(f"OpenAIå‰§æœ¬åˆ†æå¤±è´¥: {e}")
            return {}
    
    def enhance_animation_prompt(self, base_prompt: str, context: Dict) -> str:
        """å¢å¼ºåŠ¨ç”»æç¤ºè¯"""
        prompt = f"""
        æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œä¼˜åŒ–åŠ¨ç”»æç¤ºè¯ï¼š
        åŸºç¡€æç¤ºè¯: {base_prompt}
        ä¸Šä¸‹æ–‡ä¿¡æ¯: {json.dumps(context, ensure_ascii=False)}
        
        è¯·ç”Ÿæˆä¸€ä¸ªæ›´è¯¦ç»†ã€æ›´å…·è§†è§‰è¡¨ç°åŠ›çš„åŠ¨ç”»æç¤ºè¯ã€‚
        åŒ…å«è§’è‰²è¡¨æƒ…ã€åŠ¨ä½œã€åœºæ™¯ç»†èŠ‚ã€å…‰ç…§å’Œæ„å›¾ã€‚
        """
        
        try:
            completion = self.client.chat.completions.create(
                extra_body={},
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            enhanced_prompt = completion.choices[0].message.content
            return enhanced_prompt.strip()
            
        except Exception as e:
            logger.error(f"OpenAIæç¤ºè¯å¢å¼ºå¤±è´¥: {e}")
            return base_prompt

# ============================================
# æ ¸å¿ƒå¼•æ“ç±»
# ============================================

class DubbingEngine:
    """é…éŸ³å¼•æ“æ ¸å¿ƒç±» - ä¼˜åŒ–æ‰¹é‡å¤„ç†ç‰ˆ"""
    
    def __init__(self, config: ProcessingConfig):
        self.config = config
        self.device = self._setup_device()
        self.whisper_model = None
        self.character_profiles: Dict[str, CharacterProfile] = {}
        self.audio_cache: Dict[str, np.ndarray] = {}
        self.segments: List[AudioSegment] = []
        self.background_audio: Optional[np.ndarray] = None
        self._init_directories()
        logger.info("é…éŸ³å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_device(self) -> torch.device:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        if self.config.use_gpu and torch.cuda.is_available():
            device = torch.device(f"cuda:{self.config.gpu_id}")
            logger.info(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name(device)}")
            logger.info(f"GPUå†…å­˜: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.1f} GB")
        else:
            device = torch.device("cpu")
            logger.info("ä½¿ç”¨CPU")
        return device
    
    def _init_directories(self):
        """åˆå§‹åŒ–ç›®å½•"""
        directories = [
            self.config.temp_dir,
            self.config.cache_dir,
            "voices",
            "inputs",
            "outputs",
            "logs",
            "subtitles",
            "ai_animation_output",
            "characters"
        ]
        
        for dir_path in directories:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    def load_whisper_model(self):
        """åŠ è½½Whisperæ¨¡å‹"""
        if not self.whisper_model:
            logger.info(f"åŠ è½½Whisperæ¨¡å‹: {self.config.whisper_model}")
            self.whisper_model = whisper.load_model(
                self.config.whisper_model,
                device=self.device
            )
            logger.info("Whisperæ¨¡å‹åŠ è½½å®Œæˆ")
    
    def add_character_profile(self, profile: CharacterProfile):
        """æ·»åŠ è§’è‰²é…ç½®"""
        self.character_profiles[profile.name] = profile
        logger.info(f"æ·»åŠ è§’è‰²é…ç½®: {profile.name} -> {profile.voice_style.value}")
    
    def extract_audio(self, video_path: str) -> str:
        """æå–è§†é¢‘ä¸­çš„éŸ³é¢‘"""
        logger.info(f"æå–éŸ³é¢‘: {video_path}")
        
        audio_path = Path(self.config.temp_dir) / f"original_audio_{Path(video_path).stem}.wav"
        
        try:
            stream = ffmpeg.input(video_path)
            stream = ffmpeg.output(
                stream,
                str(audio_path),
                acodec='pcm_s16le',
                ac=self.config.channels,
                ar=self.config.sample_rate,
                loglevel='quiet'
            )
            ffmpeg.run(stream, overwrite_output=True)
            
            logger.info(f"éŸ³é¢‘æå–å®Œæˆ: {audio_path}")
            return str(audio_path)
            
        except ffmpeg.Error as e:
            logger.error(f"FFmpegé”™è¯¯: {e}")
            
            cmd = [
                'ffmpeg', '-i', video_path,
                '-vn', '-acodec', 'pcm_s16le',
                '-ac', str(self.config.channels),
                '-ar', str(self.config.sample_rate),
                '-y', str(audio_path)
            ]
            
            try:
                subprocess.run(cmd, check=True, capture_output=True)
                return str(audio_path)
            except subprocess.CalledProcessError as e:
                raise RuntimeError(f"éŸ³é¢‘æå–å¤±è´¥: {e}")
    
    def transcribe_audio(self, audio_path: str) -> List[AudioSegment]:
        """æ”¹è¿›çš„è¯­éŸ³è¯†åˆ« - æ›´ç²¾ç¡®çš„æ—¶é—´æˆ³"""
        logger.info(f"å¼€å§‹è¯­éŸ³è¯†åˆ«: {audio_path}")
        self.load_whisper_model()
        
        try:
            result = self.whisper_model.transcribe(
                audio_path,
                language="ja",
                task="transcribe",
                verbose=True,
                fp16=self.device.type == 'cuda',
                word_timestamps=True,
                prepend_punctuations="\"'\"Â¿([{-",
                append_punctuations="\"'.ã€‚,ï¼Œ!ï¼?ï¼Ÿ:ï¼š\"ã€)]}ã€"
            )
            
            segments = []
            segment_id = 0
            
            for i, seg in enumerate(result['segments']):
                start_time = seg['start']
                end_time = seg['end']
                
                character = self.identify_character(seg['text'], seg['avg_logprob'])
                
                segment = AudioSegment(
                    id=segment_id,
                    start_time=start_time,
                    end_time=end_time,
                    text=seg['text'].strip(),
                    character=character,
                    confidence=seg['avg_logprob']
                )
                segments.append(segment)
                segment_id += 1
            
            logger.info(f"è¯­éŸ³è¯†åˆ«å®Œæˆ: {len(segments)}ä¸ªç‰‡æ®µ")
            self.segments = segments
            return segments
            
        except Exception as e:
            logger.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
            
            try:
                logger.info("å°è¯•ä½¿ç”¨åŸå§‹æ–¹æ³•è¿›è¡Œè¯­éŸ³è¯†åˆ«")
                result = self.whisper_model.transcribe(
                    audio_path,
                    language="ja",
                    task="transcribe",
                    verbose=True,
                    fp16=self.device.type == 'cuda'
                )
                
                segments = []
                for i, seg in enumerate(result['segments']):
                    character = self.identify_character(seg['text'], seg['avg_logprob'])
                    
                    segment = AudioSegment(
                        id=i,
                        start_time=seg['start'],
                        end_time=seg['end'],
                        text=seg['text'].strip(),
                        character=character,
                        confidence=seg['avg_logprob']
                    )
                    segments.append(segment)
                
                logger.info(f"è¯­éŸ³è¯†åˆ«å®Œæˆ(å›é€€æ–¹æ³•): {len(segments)}ä¸ªç‰‡æ®µ")
                self.segments = segments
                return segments
                
            except Exception as e2:
                logger.error(f"å›é€€æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                raise
    
    def identify_character(self, text: str, confidence: float) -> str:
        """è¯†åˆ«è¯´è¯è§’è‰²"""
        text_lower = text.lower()
        
        character_keywords = {
            "å“†å•¦Aæ¢¦": ["ãƒ‰ãƒ©ãˆã‚‚ã‚“", "å“†å•¦", "æœºå™¨çŒ«", "å®å½“", "dora", "ãƒ‰ãƒ©"],
            "å¤§é›„": ["ã®ã³å¤ª", "å¤§é›„", "nobita", "é‡æ¯”", "ã®ã³"],
            "é™é¦™": ["é™é¦™", "ã—ãšã‹", "shizuka", "å°é™", "ã—ãš"],
            "èƒ–è™": ["ã‚¸ãƒ£ã‚¤ã‚¢ãƒ³", "èƒ–è™", "åˆšç”°", "gian", "giant", "ã‚¸ãƒ£ã‚¤"],
            "å°å¤«": ["ã‚¹ãƒå¤«", "å°å¤«", "éª¨å·", "suneo", "ã‚¹ãƒ"],
            "å“†å•¦ç¾": ["ãƒ‰ãƒ©ãƒŸ", "å“†å•¦ç¾", "dorami"],
            "å‡ºæœ¨æ‰": ["å‡ºæœ¨æ‰", "å‡ºæ¥æ‰", "è‹±æ‰", "ã§ã‚‹ã"],
            "çˆ¸çˆ¸": ["ãƒ‘ãƒ‘", "çˆ¸çˆ¸", "çˆ¶äº²", "ãŠçˆ¶ã•ã‚“", "çˆ¶"],
            "å¦ˆå¦ˆ": ["ãƒãƒ", "å¦ˆå¦ˆ", "æ¯äº²", "ãŠæ¯ã•ã‚“", "æ¯"]
        }
        
        for character, keywords in character_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    return character
        
        return "å“†å•¦Aæ¢¦"
    
    def _translate_single_text_sync(self, text: str) -> str:
        """åŒæ­¥ç¿»è¯‘å•ä¸ªæ–‡æœ¬ - ä¿®å¤APIé€šä¿¡é—®é¢˜"""
        try:
            api_url = self.config.get_ollama_api_url()
            
            logger.info(f"ğŸ“¤ å‘é€ç¿»è¯‘è¯·æ±‚åˆ°: {api_url}")
            logger.info(f"ç¿»è¯‘æ–‡æœ¬: {text[:50]}...")
            
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚å®Œæˆç¿»è¯‘ï¼š
1. æºè¯­è¨€ï¼šæ—¥è¯­
2. ç›®æ ‡è¯­è¨€ï¼šä¸­æ–‡
3. ç¿»è¯‘è¦æ±‚ï¼šä¿æŒåŸæ„å‡†ç¡®ã€è¯­è¨€æµç•…ã€æ— è¯­æ³•é”™è¯¯ï¼Œåªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚

éœ€è¦ç¿»è¯‘çš„æ–‡æœ¬ï¼š
{text}"""
            
            data = {
                "model": self.config.translate_model,
                "prompt": prompt,
                "stream": False,
                "temperature": 0.1,
                "max_tokens": 4096
            }
            
            headers = {
                "Content-Type": "application/json"
            }
            
            response = requests.post(
                api_url,
                json=data,
                headers=headers,
                timeout=60
            )
            
            logger.info(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                
                if "response" in result:
                    reply_text = result["response"].strip()
                    
                    if reply_text:
                        reply_text = self._clean_translation_response(reply_text)
                        logger.info(f"âœ… ç¿»è¯‘æˆåŠŸ: {reply_text[:50]}...")
                        return reply_text
                    else:
                        logger.warning(f"âš ï¸ ç¿»è¯‘è¿”å›ç©ºæ–‡æœ¬")
                        return text
                else:
                    logger.warning(f"âš ï¸ å“åº”ä¸­æ²¡æœ‰'response'å­—æ®µ: {result}")
                    return text
            else:
                error_text = response.text[:500] if response.text else "æ— è¯¦ç»†é”™è¯¯ä¿¡æ¯"
                logger.error(f"âŒ ç¿»è¯‘è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                logger.error(f"é”™è¯¯è¯¦æƒ…: {error_text}")
                
                self._diagnose_ollama_problem(api_url, response.status_code, error_text)
                return text
                
        except requests.exceptions.ConnectionError as e:
            logger.error(f"âŒ è¿æ¥å¤±è´¥: {e}")
            logger.error(f"è¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ: ollama serve")
            return text
        except requests.exceptions.Timeout as e:
            logger.error(f"âŒ è¯·æ±‚è¶…æ—¶: {e}")
            return text
        except Exception as e:
            logger.error(f"âŒ ç¿»è¯‘å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return text
    
    def _diagnose_ollama_problem(self, api_url: str, status_code: int, error_text: str):
        """è¯Šæ–­Ollamaé—®é¢˜"""
        logger.error("ğŸ” Ollamaé—®é¢˜è¯Šæ–­:")
        logger.error(f"  1. API URL: {api_url}")
        logger.error(f"  2. çŠ¶æ€ç : {status_code}")
        logger.error(f"  3. é”™è¯¯ä¿¡æ¯: {error_text[:200]}")
        
        try:
            base_url = api_url.replace('/api/generate', '')
            models_url = f"{base_url}/api/tags"
            logger.info(f"å°è¯•æ£€æŸ¥æ¨¡å‹åˆ—è¡¨: {models_url}")
            
            response = requests.get(models_url, timeout=5)
            if response.status_code == 200:
                models = response.json()
                logger.info(f"âœ… æ¨¡å‹åˆ—è¡¨è·å–æˆåŠŸ: {len(models.get('models', []))} ä¸ªæ¨¡å‹")
            else:
                logger.error(f"âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨: {response.status_code}")
        except Exception as e:
            logger.error(f"âŒ è¯Šæ–­æ£€æŸ¥å¤±è´¥: {e}")
    
    def _clean_translation_response(self, reply: str) -> str:
        """æ¸…ç†ç¿»è¯‘å›å¤"""
        if not reply:
            return ""
        
        patterns_to_remove = [
            r'æ€è€ƒ.*?\n',
            r'é¦–å…ˆ.*?\n',
            r'åˆ†æ.*?\n',
            r'æ³¨æ„.*?\n',
            r'Okay.*?\n',
            r'å¥½çš„.*?\n',
            r'æ˜ç™½äº†.*?\n',
            r'æˆ‘æ¥ç¿»è¯‘.*?\n',
            r'Assistant.*?\n',
            r'åŠ©æ‰‹.*?\n',
            r'Translate.*?:',
            r'ç¿»è¯‘.*?:',
            r'ä»¥ä¸‹æ˜¯ç¿»è¯‘.*?:',
            r'è¯‘æ–‡.*?:'
        ]
        
        for pattern in patterns_to_remove:
            reply = re.sub(pattern, '', reply, flags=re.IGNORECASE)
        
        reply = re.sub(r'\n+', '\n', reply)
        reply = re.sub(r'\s+', ' ', reply)
        
        return reply.strip()
    
    def batch_translate_segments(self, segments: List[AudioSegment]) -> List[AudioSegment]:
        """æ‰¹é‡ç¿»è¯‘æ‰€æœ‰ç‰‡æ®µ - åŒæ­¥ç‰ˆæœ¬"""
        if not self.config.translate_to_chinese:
            logger.info("è·³è¿‡ç¿»è¯‘ï¼ˆé…ç½®ä¸ºä¸ç¿»è¯‘ï¼‰")
            return segments
        
        logger.info(f"å¼€å§‹æ‰¹é‡ç¿»è¯‘ {len(segments)} ä¸ªç‰‡æ®µ")
        
        api_url = self.config.get_ollama_api_url()
        logger.info(f"ä½¿ç”¨API: {api_url}")
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {self.config.translate_model}")
        
        for i, seg in enumerate(segments):
            if seg.text and len(seg.text.strip()) > 1:
                try:
                    translated = self._translate_single_text_sync(seg.text)
                    
                    import re
                    japanese_pattern = re.compile(r'[\u3040-\u309F\u30A0-\u30FF]')
                    
                    if japanese_pattern.search(translated):
                        logger.warning(f"âš ï¸ {i+1}/{len(segments)} ç¿»è¯‘åä»ä¸ºæ—¥æ–‡")
                        seg.translated_text = seg.text
                    elif translated and translated != seg.text:
                        seg.translated_text = translated
                        logger.info(f"âœ… {i+1}/{len(segments)} ç¿»è¯‘æˆåŠŸ: {translated[:30]}...")
                    else:
                        seg.translated_text = seg.text
                        logger.warning(f"âš ï¸ {i+1}/{len(segments)} ç¿»è¯‘è¿”å›ç©ºæˆ–ç›¸åŒï¼Œä½¿ç”¨åŸæ–‡")
                
                except Exception as e:
                    seg.translated_text = seg.text
                    logger.error(f"âŒ {i+1}/{len(segments)} ç¿»è¯‘å¼‚å¸¸: {e}")
            else:
                seg.translated_text = seg.text
            
            if (i + 1) % 5 == 0 or i + 1 == len(segments):
                logger.info(f"ç¿»è¯‘è¿›åº¦: {i+1}/{len(segments)}")
        
        translated_count = sum(1 for seg in segments if seg.translated_text != seg.text)
        logger.info(f"ç¿»è¯‘å®Œæˆ: {translated_count}/{len(segments)} ä¸ªç‰‡æ®µæˆåŠŸç¿»è¯‘")
        
        return segments
    
    def batch_apply_voice_styles(self, segments: List[AudioSegment]) -> List[AudioSegment]:
        """æ‰¹é‡åº”ç”¨è¯­éŸ³é£æ ¼"""
        logger.info(f"æ‰¹é‡åº”ç”¨è¯­éŸ³é£æ ¼åˆ° {len(segments)} ä¸ªç‰‡æ®µ")
        
        for seg in segments:
            if seg.translated_text:
                import re
                japanese_pattern = re.compile(r'[\u3040-\u309F\u30A0-\u30FF]')
                if japanese_pattern.search(seg.translated_text):
                    logger.warning(f"âš ï¸ ç‰‡æ®µ {seg.id} ç¿»è¯‘åä»ä¸ºæ—¥æ–‡: {seg.translated_text[:50]}...")
                    seg.styled_text = seg.text
                else:
                    try:
                        seg.styled_text = self.apply_voice_style(seg.translated_text, seg.character)
                    except Exception as e:
                        seg.styled_text = seg.translated_text
                        logger.warning(f"é£æ ¼è½¬æ¢å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸæ–‡: {seg.character}")
            else:
                seg.styled_text = seg.text
        
        logger.info("é£æ ¼è½¬æ¢å®Œæˆ")
        return segments
    
    def apply_voice_style(self, text: str, character: str) -> str:
        """åº”ç”¨è¯­éŸ³é£æ ¼"""
        if not self.config.use_style_transfer:
            return text
        
        profile = self.character_profiles.get(character)
        if not profile:
            return text
        
        styled_text = text
        
        if profile.voice_style == VoiceStyle.LI_YUNLONG:
            styled_text = self._apply_liyunlong_style(text)
        elif profile.voice_style == VoiceStyle.WANG_JINGZE:
            styled_text = self._apply_wangjingze_style(text)
        elif profile.voice_style == VoiceStyle.ZHANG_FEI:
            styled_text = self._apply_zhangfei_style(text)
        elif profile.voice_style == VoiceStyle.MA_BAOGUO:
            styled_text = self._apply_mabaoguo_style(text)
        elif profile.voice_style == VoiceStyle.XIE_GUANGKUN:
            styled_text = self._apply_xieguangkun_style(text)
        elif profile.voice_style == VoiceStyle.LUO_XIANG:
            styled_text = self._apply_luoxiang_style(text)
        elif profile.voice_style == VoiceStyle.GUO_DEGANG:
            styled_text = self._apply_guodegang_style(text)
        elif profile.voice_style == VoiceStyle.SUN_XIAOCHUAN:
            styled_text = self._apply_sunxiaochuan_style(text)
        elif profile.voice_style == VoiceStyle.TONG_XIANGYU:
            styled_text = self._apply_tongxiangyu_style(text)
        elif profile.voice_style == VoiceStyle.SHELDON:
            styled_text = self._apply_sheldon_style(text)
        
        if (self.config.add_catchphrases and profile.catchphrases and 
            np.random.random() < self.config.catchphrase_probability):
            catchphrase = np.random.choice(profile.catchphrases)
            styled_text = f"{catchphrase}ï¼Œ{styled_text}"
        
        return styled_text
    
    def _apply_liyunlong_style(self, text: str) -> str:
        """æäº‘é¾™é£æ ¼"""
        replacements = {
            "æˆ‘": "è€å­",
            "ä½ ": "ä½ å°å­",
            "ä»–": "é‚£å°å­",
            "æˆ‘ä»¬": "å’±ä»¬",
            "ä½ ä»¬": "ä½ ä»¬è¿™å¸®",
            "çœŸçš„å—": "ä»–å¨˜çš„çœŸçš„å‡çš„ï¼Ÿ",
            "å¤ªå¥½äº†": "çœŸä»–å¨˜çš„ç—›å¿«ï¼",
            "æ€ä¹ˆåŠ": "è¿™ä»—æ€ä¹ˆæ‰“ï¼Ÿ",
            "ä¸è¡Œ": "è¿™ç»å¯¹ä¸è¡Œï¼å¤©ç‹è€å­æ¥äº†ä¹Ÿä¸è¡Œï¼",
            "è°¢è°¢": "å¤šè°¢äº†å…„å¼Ÿï¼",
            "å¯¹ä¸èµ·": "å¯¹ä¸ä½äº†ï¼",
            "æ˜ç™½äº†": "æ™“å¾—äº†ï¼",
            "å¿«ç‚¹": "ç»™è€å­å¿«ç‚¹å„¿ï¼",
            "ç¬¨è›‹": "è ¢è´§ï¼",
            "å¯æ¶": "ä»–å¥¶å¥¶çš„ï¼",
            "å®³æ€•": "æ€•ä¸ªçƒï¼",
            "ä¸ºä»€ä¹ˆ": "ä¸ºå•¥å­ï¼Ÿ",
            "ä»€ä¹ˆ": "å•¥ç©æ„å„¿ï¼Ÿ",
            "æ€ä¹ˆ": "å’‹æ•´ï¼Ÿ",
            "éå¸¸": "è´¼ä»–å¨˜çš„",
            "å¾ˆ": "å¿’",
            "å¤ª": "è€",
            "çœŸçš„": "çœŸæ ¼çš„"
        }
        
        result = text
        for orig, repl in replacements.items():
            result = result.replace(orig, repl)
        
        if not result.endswith(('ï¼', 'ï¼Ÿ', 'ã€‚', '!')):
            result += 'ï¼'
        
        return result
    
    def _apply_wangjingze_style(self, text: str) -> str:
        """ç‹å¢ƒæ³½é£æ ¼"""
        replacements = {
            "æˆ‘": "æˆ‘ç‹å¢ƒæ³½",
            "ä½ ": "ä½ ",
            "ä¸": "ç»ä¸",
            "çœŸçš„": "çœŸé¦™ï¼",
            "å¥½åƒ": "å“å‘€å¦ˆå‘€çœŸé¦™ï¼",
            "ä¸é”™": "çœŸé¦™ï¼",
            "å–œæ¬¢": "çœŸé¦™ï¼",
            "åŒæ„": "çœŸé¦™ï¼",
            "æ‹’ç»": "æˆ‘å°±æ˜¯é¥¿æ­»ï¼Œæ­»å¤–è¾¹ï¼Œä»è¿™é‡Œè·³ä¸‹å»ï¼Œä¹Ÿä¸ä¼š",
            "æ”¹å˜ä¸»æ„": "çœŸé¦™ï¼",
            "åæ‚”": "å“å‘€çœŸé¦™ï¼"
        }
        
        result = text
        for orig, repl in replacements.items():
            if orig in result:
                result = result.replace(orig, repl)
        
        return result
    
    def _apply_zhangfei_style(self, text: str) -> str:
        """å¼ é£é£æ ¼"""
        replacements = {
            "æˆ‘": "ä¿º",
            "ä½ ": "æ±",
            "ä»–": "é‚£å®",
            "æˆ‘ä»¬": "ä¿ºä»¬",
            "ä½ ä»¬": "å°”ç­‰",
            "å•Š": "å“‡å‘€å‘€å‘€ï¼",
            "ä»€ä¹ˆ": "å•¥",
            "çœŸçš„": "å½“çœŸï¼Ÿ",
            "å¥½": "ç”šå¥½ï¼",
            "å‰å®³": "å¥½æ­¦è‰ºï¼",
            "æ‰“": "å¤§æˆ˜ä¸‰ç™¾å›åˆï¼",
            "æ€": "å–ä½ é¦–çº§ï¼",
            "ç”Ÿæ°”": "æ°”ç…æˆ‘ä¹Ÿï¼",
            "å¤§å“¥": "å¤§å“¥ï¼",
            "äºŒå“¥": "äºŒå“¥ï¼"
        }
        
        result = text
        for orig, repl in replacements.items():
            result = result.replace(orig, repl)
        
        return result
    
    def _apply_mabaoguo_style(self, text: str) -> str:
        """é©¬ä¿å›½é£æ ¼"""
        catchphrases = [
            "å¹´è½»äººä¸è®²æ­¦å¾·",
            "æˆ‘å¤§æ„äº†å•Šï¼Œæ²¡æœ‰é—ª",
            "è€—å­å°¾æ±",
            "ä¼ ç»ŸåŠŸå¤«è®²ç©¶åŒ–åŠ²å„¿",
            "äºŒç™¾å¤šæ–¤çš„è‹±å›½å¤§ç†çŸ³",
            "æ¥ï¼åŒ–ï¼å‘ï¼",
            "å•ªçš„ä¸€ä¸‹å°±ç«™èµ·æ¥äº†ï¼Œå¾ˆå¿«å•Šï¼",
            "æœ‰å¤‡è€Œæ¥",
            "æ­¦æ—è¦ä»¥å’Œä¸ºè´µ",
            "ä½ ä¸¤åˆ†é’Ÿä»¥åå°±å¥½äº†"
        ]
        
        if np.random.random() < 0.4:
            catchphrase = np.random.choice(catchphrases)
            return f"{catchphrase}ã€‚{text}"
        
        return text
    
    def _apply_xieguangkun_style(self, text: str) -> str:
        """è°¢å¹¿å¤é£æ ¼"""
        replacements = {
            "æˆ‘": "æˆ‘è°¢å¹¿å¤",
            "ä½ ": "ä½ ",
            "å„¿å­": "æ°¸å¼º",
            "å¥³å„¿": "å°è’™",
            "è€å©†": "ç‰ç”°å¨˜",
            "é‚»å±…": "åˆ˜èƒ½é‚£è€å°å­",
            "ç”Ÿæ°”": "å¹¿å¤å¾ˆç”Ÿæ°”ï¼Œåæœå¾ˆä¸¥é‡",
            "é«˜å…´": "æˆ‘è°¢å¹¿å¤ä»Šå¤©é«˜å…´",
            "ä¸è¡Œ": "è¿™äº‹æ²¡å®Œï¼",
            "å¯ä»¥": "é‚£å¾—çœ‹æ°¸å¼ºåŒä¸åŒæ„",
            "é’±": "éƒ½æ˜¯ä¸ºäº†æ°¸å¼º"
        }
        
        result = text
        for orig, repl in replacements.items():
            result = result.replace(orig, repl)
        
        return result
    
    def _apply_luoxiang_style(self, text: str) -> str:
        """ç½—ç¿”é£æ ¼"""
        law_terms = [
            "æ ¹æ®ã€Šä¸­åäººæ°‘å…±å’Œå›½åˆ‘æ³•ã€‹",
            "å¼ ä¸‰åˆæ¥äº†",
            "è¿™å±äºè¿æ³•è¡Œä¸º",
            "æ³•æ²»ç¤¾ä¼š",
            "æ³•å¾‹é¢å‰äººäººå¹³ç­‰",
            "æˆ‘ä»¬è¦å¿ƒå­˜æ•¬ç•",
            "è¿™å¾—çœ‹å…·ä½“æ¡ˆæƒ…",
            "ä»æ³•å¾‹è§’åº¦åˆ†æ",
            "ç½ªåˆ‘æ³•å®šåŸåˆ™",
            "ç¨‹åºæ­£ä¹‰"
        ]
        
        if np.random.random() < 0.3:
            term = np.random.choice(law_terms)
            return f"{term}ï¼Œ{text}"
        
        return text
    
    def _apply_guodegang_style(self, text: str) -> str:
        """éƒ­å¾·çº²é£æ ¼"""
        replacements = {
            "æˆ‘": "æˆ‘éƒ­å¾·çº²",
            "ä½ ": "ä½ ",
            "è¯´": "è¯´ç›¸å£°",
            "ç¬‘": "é€—ä½ ç©",
            "èªæ˜": "æœºçµ",
            "ç¬¨": "è„‘å­ä¸å¥½ä½¿",
            "æœ‹å‹": "äºè°¦",
            "çˆ¶äº²": "äºè°¦çš„çˆ¶äº²ç‹è€çˆ·å­",
            "å„¿å­": "éƒ­éº’éºŸ",
            "å¾’å¼Ÿ": "å²³äº‘é¹",
            "å¥½åƒ": "äºè°¦å®¶åƒçš„å°±æ˜¯å¥½"
        }
        
        result = text
        for orig, repl in replacements.items():
            result = result.replace(orig, repl)
        
        if "ï¼š" in result:
            parts = result.split("ï¼š", 1)
            result = f"{parts[0]}ï¼ˆæ§å“ï¼šäºè°¦ï¼‰ï¼š{parts[1]}"
        
        return result
    
    def _apply_sunxiaochuan_style(self, text: str) -> str:
        """å­™ç¬‘å·é£æ ¼"""
        abstract_terms = [
            "ä½ å¦ˆæ­»äº†",
            "å¸¦å“¥ä»¬",
            "æŠ½è±¡",
            "ç¼åˆæ€ª",
            "çƒ‚æ´»",
            "å¥½æ´»",
            "æ•´ä¸ä¼šäº†",
            "å…¸ä¸­å…¸",
            "æ€¥äº†æ€¥äº†",
            "å·®ä¸å¤šå¾—äº†"
        ]
        
        if np.random.random() < 0.4:
            term = np.random.choice(abstract_terms)
            return f"{term}ï¼Œ{text}"
        
        return text
    
    def _apply_tongxiangyu_style(self, text: str) -> str:
        """ä½Ÿæ¹˜ç‰é£æ ¼"""
        replacements = {
            "æˆ‘": "é¢",
            "ä½ ": "ä½ ",
            "çš„": "æ»´",
            "å•Š": "å•Šï½",
            "å—": "å˜›",
            "äº†": "å’§",
            "çœŸçš„": "çœŸæ»´",
            "ä¸æ˜¯": "ä¸æ˜¯æˆ‘è¯´ä½ ",
            "ä¸ºä»€ä¹ˆ": "è¿™æ˜¯ä¸ºå•¥å˜›",
            "æ€ä¹ˆåŠ": "é¢æ»´ç¥å•Šï¼Œè¿™å¯å’‹åŠå˜›",
            "åæ‚”": "æˆ‘å¥½åæ‚”å‘€",
            "ç”Ÿæ°”": "é¢æ»´å¿ƒå•Šï¼Œå“‡å‡‰å“‡å‡‰æ»´"
        }
        
        result = text
        for orig, repl in replacements.items():
            result = result.replace(orig, repl)
        
        return result
    
    def _apply_sheldon_style(self, text: str) -> str:
        """è°¢å°”é¡¿é£æ ¼"""
        replacements = {
            "æˆ‘": "æˆ‘",
            "ä½ ": "ä½ ",
            "èªæ˜": "æ˜¾ç„¶",
            "çŸ¥é“": "æ ¹æ®æˆ‘çš„è®¡ç®—",
            "åº”è¯¥": "ä»ç†è®ºä¸Šè®²",
            "å¯èƒ½": "æ¦‚ç‡ä¸Š",
            "æœ‹å‹": "è±çº³å¾·",
            "å®¤å‹": "è±çº³å¾·",
            "é‚»å±…": "ä½©å¦®",
            "å¦ˆå¦ˆ": "æˆ‘å¦ˆå¦ˆç»å¸¸è¯´",
            "åšå£«": "ä½œä¸ºä¸€ä¸ªç†è®ºç‰©ç†åšå£«"
        }
        
        result = text
        for orig, repl in replacements.items():
            result = result.replace(orig, repl)
        
        prefixes = ["Bazingaï¼", "äº‹å®ä¸Šï¼Œ", "å‡†ç¡®åœ°è¯´ï¼Œ", "æ ¹æ®å¼¦ç†è®ºï¼Œ"]
        if np.random.random() < 0.3:
            prefix = np.random.choice(prefixes)
            result = f"{prefix}{result}"
        
        return result
    
    async def batch_generate_voices(self, segments: List[AudioSegment]) -> List[AudioSegment]:
        """æ‰¹é‡ç”Ÿæˆè¯­éŸ³ - ä¸²è¡Œç‰ˆæœ¬"""
        logger.info(f"å¼€å§‹ä¸²è¡Œç”Ÿæˆè¯­éŸ³ï¼Œæ€»ç‰‡æ®µæ•°: {len(segments)}")
        
        valid_segments = [seg for seg in segments if seg.styled_text and len(seg.styled_text.strip()) > 1]
        logger.info(f"æœ‰æ•ˆç‰‡æ®µæ•°é‡: {len(valid_segments)}/{len(segments)}")
        
        if not valid_segments:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æœ¬ç‰‡æ®µéœ€è¦ç”Ÿæˆè¯­éŸ³")
            return segments
        
        processed_count = 0
        failed_count = 0
        
        for i, seg in enumerate(valid_segments):
            seg_num = i + 1
            total_segs = len(valid_segments)
            
            profile = self.character_profiles.get(seg.character)
            if not profile:
                profile = CharacterProfile.get_preset(seg.character)
                self.character_profiles[seg.character] = profile
            
            clean_text = self._clean_text_for_tts(seg.styled_text)
            
            if len(clean_text) < 2:
                seg.audio_data = None
                logger.warning(f"ç‰‡æ®µ {seg.id} æ–‡æœ¬æ— æ•ˆï¼Œè·³è¿‡")
                continue
            
            logger.info(f"æ­£åœ¨ç”Ÿæˆè¯­éŸ³ [{seg_num}/{total_segs}]: {clean_text[:50]}...")
            
            try:
                audio_data = await self._generate_single_voice_with_retry(
                    clean_text, profile, seg.id, max_retries=2
                )
                
                if audio_data is not None:
                    seg.audio_data = audio_data
                    processed_count += 1
                    
                    delay_seconds = 0.5
                    logger.debug(f"è¯­éŸ³ç”ŸæˆæˆåŠŸï¼Œç­‰å¾… {delay_seconds} ç§’åå¤„ç†ä¸‹ä¸€ä¸ª...")
                    await asyncio.sleep(delay_seconds)
                    
                else:
                    seg.audio_data = None
                    failed_count += 1
                    logger.warning(f"âŒ ç‰‡æ®µ {seg.id} è¯­éŸ³ç”Ÿæˆå¤±è´¥")
                    
            except Exception as e:
                seg.audio_data = None
                failed_count += 1
                logger.error(f"âŒ ç‰‡æ®µ {seg.id} è¯­éŸ³ç”Ÿæˆå¼‚å¸¸: {e}")
            
            if seg_num % 5 == 0 or seg_num == total_segs:
                progress = int(seg_num / total_segs * 100)
                logger.info(f"è¯­éŸ³ç”Ÿæˆè¿›åº¦: {seg_num}/{total_segs} ({progress}%)")
        
        logger.info(f"è¯­éŸ³ç”Ÿæˆå®Œæˆ: {processed_count}æˆåŠŸ, {failed_count}å¤±è´¥, å…±{len(valid_segments)}ä¸ªç‰‡æ®µ")
        return segments
    
    async def _generate_single_voice_with_retry(self, text: str, profile: CharacterProfile, seg_id: int, max_retries: int = 3) -> Optional[np.ndarray]:
        """ç”Ÿæˆå•ä¸ªè¯­éŸ³ï¼ˆå¸¦é‡è¯•ï¼‰"""
        for attempt in range(max_retries):
            try:
                audio_data = await self._generate_single_voice(text, profile)
                if audio_data is not None:
                    return audio_data
                else:
                    logger.warning(f"ç‰‡æ®µ {seg_id} è¯­éŸ³ç”Ÿæˆå°è¯• {attempt+1} è¿”å›ç©º")
            except Exception as e:
                logger.warning(f"ç‰‡æ®µ {seg_id} è¯­éŸ³ç”Ÿæˆå°è¯• {attempt+1} å¤±è´¥: {e}")
            
            if attempt < max_retries - 1:
                wait_time = 1 * (2 ** attempt)
                logger.info(f"ç‰‡æ®µ {seg_id} ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                await asyncio.sleep(wait_time)
        
        return None
    
    async def _generate_single_voice(self, text: str, profile: CharacterProfile) -> Optional[np.ndarray]:
        """ç”Ÿæˆå•ä¸ªè¯­éŸ³"""
        import base64
        
        if not text or len(text) < 2:
            return None
        
        try:
            import soundfile as sf
            from pathlib import Path
            
            temp_dir = Path(self.config.temp_dir)
            temp_dir.mkdir(exist_ok=True)
            
            prompt_audio_b64 = ""
            if profile.voice_file and os.path.exists(profile.voice_file):
                try:
                    audio_data, sr = sf.read(profile.voice_file)
                    temp_wav_path = temp_dir / f"prompt_{hash(text)}.wav"
                    sf.write(str(temp_wav_path), audio_data, sr)
                    
                    with open(temp_wav_path, 'rb') as f:
                        audio_bytes = f.read()
                    
                    prompt_audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
                    logger.debug(f"ä½¿ç”¨éŸ³è‰²æ–‡ä»¶: {profile.voice_file}")
                except Exception as e:
                    logger.warning(f"éŸ³è‰²æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤éŸ³é¢‘: {e}")
                    sr = 24000
                    silence = np.zeros(sr, dtype=np.float32)
                    temp_wav_path = temp_dir / f"silence_{hash(text)}.wav"
                    sf.write(temp_wav_path, silence, sr)
                    
                    with open(temp_wav_path, 'rb') as f:
                        audio_bytes = f.read()
                    
                    prompt_audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
            else:
                sr = 24000
                silence = np.zeros(sr, dtype=np.float32)
                temp_wav_path = temp_dir / f"silence_{hash(text)}.wav"
                sf.write(temp_wav_path, silence, sr)
                
                with open(temp_wav_path, 'rb') as f:
                    audio_bytes = f.read()
                
                prompt_audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
                logger.debug("ä½¿ç”¨é»˜è®¤éŸ³é¢‘")
            
            payload = {
                "tts_text": text[:150],
                "prompt_audio": prompt_audio_b64,
                "emo_control_method": 0,
                "do_sample": True,
                "temperature": 0.8,
                "top_p": 0.8,
                "top_k": 20,
                "repetition_penalty": 5.0,
                "max_mel_tokens": 200,
                "speed": min(max(profile.speed, 0.5), 2.0)
            }
            
            logger.debug(f"å‘é€TTSè¯·æ±‚: {text[:30]}...")
            logger.debug(f"TTS API URL: {self.config.tts_api_url}")
            
            import aiohttp
            timeout = aiohttp.ClientTimeout(total=60)
            
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(
                    self.config.tts_api_url, 
                    json=payload,
                    headers={"Content-Type": "application/json"}
                ) as response:
                    
                    logger.info(f"TTSå“åº”çŠ¶æ€: {response.status}")
                    
                    if response.status == 200:
                        result = await response.json()
                        logger.debug(f"TTSå“åº”: {result}")
                        
                        if result.get("status") == "success":
                            audio_base64 = result.get("audio", "")
                            if audio_base64:
                                audio_bytes = base64.b64decode(audio_base64)
                                temp_output_path = temp_dir / f"output_{hash(text)}.wav"
                                with open(temp_output_path, 'wb') as f:
                                    f.write(audio_bytes)
                                
                                audio_data, sr = sf.read(str(temp_output_path))
                                logger.debug(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ: {text[:30]}...")
                                return audio_data.astype(np.float32)
                            else:
                                logger.warning(f"TTS APIè¿”å›æ— éŸ³é¢‘æ•°æ®: {text[:30]}...")
                        else:
                            error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                            logger.warning(f"TTS APIè¿”å›é”™è¯¯çŠ¶æ€: {error_msg}")
                    elif response.status == 400:
                        error_text = await response.text()
                        logger.error(f"TTS API 400é”™è¯¯: {error_text[:200]}")
                    elif response.status == 500:
                        error_text = await response.text()
                        logger.error(f"TTS APIæœåŠ¡å™¨500é”™è¯¯: {error_text[:200]}")
                    else:
                        error_text = await response.text()
                        logger.warning(f"TTS API HTTPé”™è¯¯ {response.status}: {error_text[:200]}")
            
            return None
            
        except aiohttp.ClientConnectorError:
            logger.error(f"æ— æ³•è¿æ¥åˆ°TTSæœåŠ¡: {self.config.tts_api_url}")
            logger.error("è¯·ç¡®ä¿TTSæœåŠ¡å·²å¯åŠ¨: python api.py --port 5021")
            return None
        except asyncio.TimeoutError:
            logger.warning(f"TTSè¯·æ±‚è¶…æ—¶: {text[:30]}...")
            return None
        except Exception as e:
            logger.error(f"è¯­éŸ³ç”Ÿæˆå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _clean_text_for_tts(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦"""
        if not text:
            return ""
        
        text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
        text = re.sub(r'<[^>]+>', '', text)
        text = re.sub(r'https?://\S+', '', text)
        text = re.sub(r'(Okay|OK|æ€è€ƒ|åˆ†æ|æ³¨æ„).*?(user|ç”¨æˆ·|é—®é¢˜|æ–‡æœ¬)', '', text, flags=re.IGNORECASE)
        text = re.sub(r'\s+', ' ', text).strip()
        
        max_length = 200
        if len(text) > max_length:
            text = text[:max_length] + "ã€‚"
        
        return text
    
    def extract_background_audio(self, audio_path: str) -> np.ndarray:
        """æå–èƒŒæ™¯éŸ³é¢‘ï¼ˆå»é™¤äººå£°ï¼‰"""
        logger.info("æå–èƒŒæ™¯éŸ³é¢‘")
        
        try:
            audio, sr = librosa.load(audio_path, sr=self.config.sample_rate)
            
            if self.config.keep_background:
                nyquist = sr / 2
                
                b_low, a_low = butter(6, 300/nyquist, btype='low')
                low_freq = filtfilt(b_low, a_low, audio)
                
                b_high, a_high = butter(6, 80/nyquist, btype='high')
                background = filtfilt(b_high, a_high, audio)
                
                background = background * 0.7 + low_freq * 0.3
                background = background * self.config.background_volume
                
                self.background_audio = background
                return background
            else:
                self.background_audio = np.zeros_like(audio)
                return self.background_audio
                
        except Exception as e:
            logger.error(f"èƒŒæ™¯éŸ³é¢‘æå–å¤±è´¥: {e}")
            return np.array([])
    
    def _adjust_audio_duration(self, audio: np.ndarray, target_samples: int, sr: int) -> np.ndarray:
        """æ™ºèƒ½è°ƒæ•´éŸ³é¢‘æ—¶é•¿"""
        current_samples = len(audio)
        
        if current_samples == target_samples:
            return audio
        
        if target_samples <= 0:
            return np.array([], dtype=np.float32)
        
        try:
            from librosa.effects import time_stretch
            stretch_factor = target_samples / current_samples
            
            if 0.5 <= stretch_factor <= 2.0:
                stretched_audio = time_stretch(audio, rate=stretch_factor)
                if len(stretched_audio) > target_samples:
                    return stretched_audio[:target_samples]
                elif len(stretched_audio) < target_samples:
                    pad_length = target_samples - len(stretched_audio)
                    segment_audio = np.pad(stretched_audio, (0, pad_length), mode='constant')
                    return segment_audio
                else:
                    return stretched_audio
        except ImportError:
            pass
        
        if current_samples > 1:
            x_old = np.linspace(0, 1, current_samples)
            x_new = np.linspace(0, 1, target_samples)
            f = interp1d(x_old, audio, kind='linear')
            return f(x_new)
        else:
            if current_samples == 1:
                return np.full(target_samples, audio[0])
            else:
                return np.zeros(target_samples)
    
    def _apply_crossfade(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """åº”ç”¨äº¤å‰æ·¡å…¥æ·¡å‡º"""
        fade_duration = int(self.config.fade_duration * sr)
        
        if len(audio) > 2 * fade_duration:
            fade_in = np.linspace(0, 1, fade_duration)
            fade_out = np.linspace(1, 0, fade_duration)
            
            audio[:fade_duration] *= fade_in
            audio[-fade_duration:] *= fade_out
        
        return audio
    
    def _smart_normalize(self, audio: np.ndarray, target_db: float = -3.0) -> np.ndarray:
        """æ™ºèƒ½éŸ³é¢‘å½’ä¸€åŒ–"""
        if len(audio) == 0:
            return audio
        
        rms = np.sqrt(np.mean(audio ** 2))
        if rms < 1e-10:
            return audio
        
        current_db = 20 * np.log10(rms)
        gain_db = target_db - current_db
        gain = 10 ** (gain_db / 20)
        
        normalized = audio * gain
        
        max_val = np.max(np.abs(normalized))
        if max_val > 0.95:
            normalized = normalized * 0.95 / max_val
        
        return normalized
    
    def mix_audio(self, original_audio_path: str, voice_segments: List[AudioSegment], output_path: str):
        """æ”¹è¿›çš„éŸ³é¢‘æ··åˆæ–¹æ³• - ç¡®ä¿æ—¶é•¿ç²¾ç¡®å¯¹é½"""
        logger.info("å¼€å§‹éŸ³é¢‘æ··åˆï¼ˆæ”¹è¿›ç‰ˆï¼‰")
        
        try:
            audio, sr = sf.read(original_audio_path)
            if len(audio.shape) > 1:
                audio = np.mean(audio, axis=1)
            
            dubbing_track = np.zeros_like(audio, dtype=np.float32)
            
            for segment in voice_segments:
                if segment.audio_data is not None and segment.volume > 0:
                    start_sample = int(segment.start_time * sr)
                    end_sample = int(segment.end_time * sr)
                    segment_duration_samples = end_sample - start_sample
                    
                    if segment_duration_samples > 0:
                        segment_audio = self._adjust_audio_duration(
                            segment.audio_data, 
                            segment_duration_samples,
                            sr
                        )
                        
                        if len(segment_audio) > segment_duration_samples:
                            segment_audio = segment_audio[:segment_duration_samples]
                        elif len(segment_audio) < segment_duration_samples:
                            pad_length = segment_duration_samples - len(segment_audio)
                            segment_audio = np.pad(segment_audio, (0, pad_length), mode='constant')
                        
                        segment_audio = self._apply_crossfade(segment_audio, sr)
                        segment_audio = segment_audio * segment.volume * self.config.voice_volume
                        
                        end_idx = min(start_sample + len(segment_audio), len(dubbing_track))
                        if end_idx > start_sample:
                            dubbing_track[start_sample:end_idx] += segment_audio[:end_idx-start_sample]
            
            if self.background_audio is not None and len(self.background_audio) > 0:
                bg_len = min(len(self.background_audio), len(dubbing_track))
                dubbing_track[:bg_len] += self.background_audio[:bg_len]
            
            dubbing_track = self._smart_normalize(dubbing_track)
            
            sf.write(output_path, dubbing_track, sr)
            logger.info(f"éŸ³é¢‘æ··åˆå®Œæˆ: {output_path}")
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘æ··åˆå¤±è´¥: {e}")
            raise
    
    def replace_video_audio(self, video_path: str, audio_path: str, output_path: str):
        """æ›¿æ¢è§†é¢‘ä¸­çš„éŸ³é¢‘"""
        logger.info(f"åˆæˆæœ€ç»ˆè§†é¢‘: {output_path}")
        
        try:
            video = ffmpeg.input(video_path)
            audio = ffmpeg.input(audio_path)
            
            stream = ffmpeg.output(
                video.video,
                audio.audio,
                output_path,
                vcodec='copy',
                acodec='aac',
                audio_bitrate='192k',
                loglevel='quiet'
            )
            
            ffmpeg.run(stream, overwrite_output=True)
            logger.info(f"è§†é¢‘åˆæˆå®Œæˆ: {output_path}")
            
        except ffmpeg.Error as e:
            logger.error(f"FFmpegåˆæˆé”™è¯¯: {e}")
            
            cmd = [
                'ffmpeg',
                '-i', video_path,
                '-i', audio_path,
                '-c:v', 'copy',
                '-c:a', 'aac',
                '-map', '0:v:0',
                '-map', '1:a:0',
                '-shortest',
                '-y',
                output_path
            ]
            
            try:
                subprocess.run(cmd, check=True, capture_output=True)
                logger.info(f"è§†é¢‘åˆæˆå®Œæˆ: {output_path}")
            except subprocess.CalledProcessError as e:
                raise RuntimeError(f"è§†é¢‘åˆæˆå¤±è´¥: {e}")
    
    def process_episode_optimized(self, video_path: str) -> str:
        """ä¼˜åŒ–åçš„è§†é¢‘å¤„ç†æµç¨‹ - æ·»åŠ å£å‹å¯¹é½"""
        logger.info(f"å¼€å§‹ä¼˜åŒ–å¤„ç†è§†é¢‘: {video_path}")
        
        temp_dir = Path(self.config.temp_dir)
        temp_dir.mkdir(exist_ok=True)
        
        try:
            logger.info("é˜¶æ®µ1: æå–éŸ³é¢‘")
            audio_path = self.extract_audio(video_path)
            
            logger.info("é˜¶æ®µ2: è¯­éŸ³è¯†åˆ«")
            segments = self.transcribe_audio(audio_path)
            
            logger.info("é˜¶æ®µ3: æå–èƒŒæ™¯éŸ³é¢‘")
            self.extract_background_audio(audio_path)
            
            logger.info("é˜¶æ®µ4: æ‰¹é‡ç¿»è¯‘")
            segments = self.batch_translate_segments(segments)
            
            logger.info("é˜¶æ®µ5: æ‰¹é‡é£æ ¼è½¬æ¢")
            segments = self.batch_apply_voice_styles(segments)
            
            logger.info("é˜¶æ®µ6: æ‰¹é‡è¯­éŸ³ç”Ÿæˆï¼ˆä¸²è¡Œï¼‰")
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                original_batch_size = self.config.tts_batch_size
                self.config.tts_batch_size = 1
                
                segments = loop.run_until_complete(self.batch_generate_voices(segments))
                
                self.config.tts_batch_size = original_batch_size
            finally:
                loop.close()
            
            logger.info("é˜¶æ®µ7: æ··åˆéŸ³é¢‘")
            mixed_audio_path = temp_dir / "mixed_audio.wav"
            self.mix_audio(audio_path, segments, str(mixed_audio_path))
            
            logger.info("é˜¶æ®µ7.5: å£å‹åŒæ­¥å¯¹é½")
            post_processor = AudioPostProcessor(self.config)
            aligned_audio_path = post_processor.align_to_lip_sync(video_path, str(mixed_audio_path))
            
            logger.info("é˜¶æ®µ8: åˆæˆè§†é¢‘")
            output_path = self.config.output_video or str(Path(video_path).with_stem(f"{Path(video_path).stem}_dubbed"))
            
            if aligned_audio_path and os.path.exists(aligned_audio_path):
                self.replace_video_audio(video_path, aligned_audio_path, output_path)
            else:
                logger.warning("å£å‹å¯¹é½å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ··åˆéŸ³é¢‘")
                self.replace_video_audio(video_path, str(mixed_audio_path), output_path)
            
            logger.info("é˜¶æ®µ9: æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
            for temp_file in temp_dir.glob("*"):
                if temp_file.is_file():
                    try:
                        temp_file.unlink()
                    except:
                        pass
            
            logger.info(f"è§†é¢‘å¤„ç†å®Œæˆ: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"è§†é¢‘å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise

# ============================================
# GUIç•Œé¢ç±» - å¤„ç†çº¿ç¨‹
# ============================================

class ProcessingThread(QThread):
    """å¤„ç†çº¿ç¨‹"""
    
    progress_updated = Signal(int, str)
    stage_changed = Signal(str, str)
    segment_processed = Signal(int, int)
    log_message = Signal(str, str)
    finished = Signal(str)
    error = Signal(str)
    
    def __init__(self, engine: DubbingEngine, video_path: str):
        super().__init__()
        self.engine = engine
        self.video_path = video_path
        self.is_running = True
    
    def run(self):
        try:
            self.log_message.emit(f"å¼€å§‹å¤„ç†è§†é¢‘: {self.video_path}", "INFO")
            
            output_path = self.engine.process_episode_optimized(self.video_path)
            
            self.log_message.emit(f"å¤„ç†å®Œæˆ: {output_path}", "INFO")
            self.finished.emit(output_path)
            
        except Exception as e:
            error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
            self.log_message.emit(error_msg, "ERROR")
            self.error.emit(error_msg)
    
    def stop(self):
        self.is_running = False

class AnimationGenerationThread(QThread):
    """åŠ¨ç”»ç”Ÿæˆçº¿ç¨‹"""
    
    progress_updated = Signal(int, str)
    log_message = Signal(str, str)
    finished = Signal(str)
    error = Signal(str)
    
    def __init__(self, generator, script_path: str):
        super().__init__()
        self.generator = generator
        self.script_path = script_path
        self.is_running = True
    
    def run(self):
        try:
            self.log_message.emit("å¼€å§‹ç”ŸæˆAIé©±åŠ¨åŠ¨ç”»...", "INFO")
            
            import asyncio
            
            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                self.progress_updated.emit(10, "æ­£åœ¨åˆå§‹åŒ–...")
                
                # æ–¹æ³•1: ç›´æ¥è¿è¡Œåç¨‹
                result = loop.run_until_complete(self.generator.initialize())
                
                if result:
                    self.progress_updated.emit(30, "æ­£åœ¨å¤„ç†å‰§æœ¬...")
                    final_video = loop.run_until_complete(
                        self.generator.generate_complete_animation(self.script_path)
                    )
                    
                    if final_video:
                        self.progress_updated.emit(100, "å®Œæˆ")
                        self.log_message.emit(f"âœ… åŠ¨ç”»ç”Ÿæˆå®Œæˆ: {final_video}", "INFO")
                        self.finished.emit(final_video)
                    else:
                        self.error.emit("åŠ¨ç”»ç”Ÿæˆå¤±è´¥")
                else:
                    self.error.emit("AIåŠ¨ç”»ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥")
                    
            except Exception as e:
                error_msg = f"åŠ¨ç”»ç”Ÿæˆå¤±è´¥: {str(e)}"
                self.log_message.emit(error_msg, "ERROR")
                self.error.emit(error_msg)
                import traceback
                traceback.print_exc()
                
            finally:
                loop.close()
                
        except Exception as e:
            error_msg = f"åŠ¨ç”»ç”Ÿæˆçº¿ç¨‹å¤±è´¥: {str(e)}"
            self.log_message.emit(error_msg, "ERROR")
            self.error.emit(error_msg)
    
    def stop(self):
        self.is_running = False

# ============================================
# GUIç•Œé¢ç±» - è§’è‰²é…ç½®å¯¹è¯æ¡†
# ============================================

class CharacterConfigDialog(QDialog):
    """è§’è‰²é…ç½®å¯¹è¯æ¡†"""
    
    def __init__(self, character_name: str, parent=None):
        super().__init__(parent)
        self.character_name = character_name
        self.profile = CharacterProfile.get_preset(character_name)
        self.init_ui()
    
    def init_ui(self):
        self.setWindowTitle(f"é…ç½®è§’è‰²: {self.character_name}")
        self.setModal(True)
        self.resize(500, 600)
        
        layout = QVBoxLayout()
        
        info_group = QGroupBox("è§’è‰²ä¿¡æ¯")
        info_layout = QVBoxLayout()
        
        name_layout = QHBoxLayout()
        name_layout.addWidget(QLabel("è§’è‰²å:"))
        self.name_edit = QLineEdit(self.profile.name)
        name_layout.addWidget(self.name_edit)
        info_layout.addLayout(name_layout)
        
        info_group.setLayout(info_layout)
        layout.addWidget(info_group)
        
        voice_group = QGroupBox("éŸ³è‰²é…ç½®")
        voice_layout = QVBoxLayout()
        
        file_layout = QHBoxLayout()
        file_layout.addWidget(QLabel("éŸ³è‰²æ–‡ä»¶:"))
        self.file_edit = QLineEdit(self.profile.voice_file)
        file_layout.addWidget(self.file_edit)
        
        browse_btn = QPushButton("æµè§ˆ...")
        browse_btn.clicked.connect(self.browse_voice_file)
        file_layout.addWidget(browse_btn)
        voice_layout.addLayout(file_layout)
        
        style_layout = QHBoxLayout()
        style_layout.addWidget(QLabel("è¯­éŸ³é£æ ¼:"))
        self.style_combo = QComboBox()
        for style in VoiceStyle:
            self.style_combo.addItem(style.value, style)
        self.style_combo.setCurrentText(self.profile.voice_style.value)
        style_layout.addWidget(self.style_combo)
        voice_layout.addLayout(style_layout)
        
        voice_group.setLayout(voice_layout)
        layout.addWidget(voice_group)
        
        params_group = QGroupBox("è¯­éŸ³å‚æ•°")
        params_layout = QVBoxLayout()
        
        speed_layout = QHBoxLayout()
        speed_layout.addWidget(QLabel("è¯­é€Ÿ:"))
        self.speed_slider = QSlider(Qt.Horizontal)
        self.speed_slider.setRange(50, 200)
        self.speed_slider.setValue(int(self.profile.speed * 100))
        speed_layout.addWidget(self.speed_slider)
        self.speed_label = QLabel(f"{self.profile.speed:.1f}")
        speed_layout.addWidget(self.speed_label)
        self.speed_slider.valueChanged.connect(
            lambda v: self.speed_label.setText(f"{v/100:.1f}")
        )
        params_layout.addLayout(speed_layout)
        
        pitch_layout = QHBoxLayout()
        pitch_layout.addWidget(QLabel("éŸ³é«˜:"))
        self.pitch_slider = QSlider(Qt.Horizontal)
        self.pitch_slider.setRange(50, 200)
        self.pitch_slider.setValue(int(self.profile.pitch * 100))
        pitch_layout.addWidget(self.pitch_slider)
        self.pitch_label = QLabel(f"{self.profile.pitch:.1f}")
        pitch_layout.addWidget(self.pitch_label)
        self.pitch_slider.valueChanged.connect(
            lambda v: self.pitch_label.setText(f"{v/100:.1f}")
        )
        params_layout.addLayout(pitch_layout)
        
        intensity_layout = QHBoxLayout()
        intensity_layout.addWidget(QLabel("å¼ºåº¦:"))
        self.intensity_slider = QSlider(Qt.Horizontal)
        self.intensity_slider.setRange(50, 200)
        self.intensity_slider.setValue(int(self.profile.intensity * 100))
        intensity_layout.addWidget(self.intensity_slider)
        self.intensity_label = QLabel(f"{self.profile.intensity:.1f}")
        intensity_layout.addWidget(self.intensity_label)
        self.intensity_slider.valueChanged.connect(
            lambda v: self.intensity_label.setText(f"{v/100:.1f}")
        )
        params_layout.addLayout(intensity_layout)
        
        emotion_layout = QHBoxLayout()
        emotion_layout.addWidget(QLabel("æƒ…æ„Ÿ:"))
        self.emotion_combo = QComboBox()
        emotions = ["neutral", "happy", "sad", "angry", "surprised", "fearful", "excited"]
        self.emotion_combo.addItems(emotions)
        self.emotion_combo.setCurrentText(self.profile.emotion)
        emotion_layout.addWidget(self.emotion_combo)
        params_layout.addLayout(emotion_layout)
        
        params_group.setLayout(params_layout)
        layout.addWidget(params_group)
        
        catchphrase_group = QGroupBox("å£å¤´ç¦…")
        catchphrase_layout = QVBoxLayout()
        
        self.catchphrase_edit = QTextEdit()
        self.catchphrase_edit.setMaximumHeight(100)
        self.catchphrase_edit.setText("\n".join(self.profile.catchphrases))
        catchphrase_layout.addWidget(self.catchphrase_edit)
        
        catchphrase_group.setLayout(catchphrase_layout)
        layout.addWidget(catchphrase_group)
        
        button_layout = QHBoxLayout()
        
        test_btn = QPushButton("æµ‹è¯•éŸ³è‰²")
        test_btn.clicked.connect(self.test_voice)
        button_layout.addWidget(test_btn)
        
        button_layout.addStretch()
        
        ok_btn = QPushButton("ç¡®å®š")
        ok_btn.clicked.connect(self.accept)
        button_layout.addWidget(ok_btn)
        
        cancel_btn = QPushButton("å–æ¶ˆ")
        cancel_btn.clicked.connect(self.reject)
        button_layout.addWidget(cancel_btn)
        
        layout.addLayout(button_layout)
        self.setLayout(layout)
    
    def browse_voice_file(self):
        """æµè§ˆéŸ³è‰²æ–‡ä»¶"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©éŸ³è‰²æ–‡ä»¶", "", 
            "éŸ³é¢‘æ–‡ä»¶ (*.wav *.mp3 *.ogg);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
        )
        
        if file_path:
            self.file_edit.setText(file_path)
    
    def test_voice(self):
        """æµ‹è¯•éŸ³è‰²"""
        QMessageBox.information(self, "æµ‹è¯•", f"æµ‹è¯• {self.character_name} çš„éŸ³è‰²")
    
    def get_profile(self) -> CharacterProfile:
        """è·å–é…ç½®çš„è§’è‰²ä¿¡æ¯"""
        self.profile.name = self.name_edit.text()
        self.profile.voice_file = self.file_edit.text()
        self.profile.voice_style = self.style_combo.currentData()
        self.profile.speed = self.speed_slider.value() / 100
        self.profile.pitch = self.pitch_slider.value() / 100
        self.profile.intensity = self.intensity_slider.value() / 100
        self.profile.emotion = self.emotion_combo.currentText()
        
        catchphrases_text = self.catchphrase_edit.toPlainText()
        self.profile.catchphrases = [
            cp.strip() for cp in catchphrases_text.split('\n') 
            if cp.strip()
        ]
        
        return self.profile

# ============================================
# GUIç•Œé¢ç±» - ä¸»çª—å£
# ============================================

from PySide6.QtGui import QDesktopServices

class MainWindow(QMainWindow):
    """ä¸»çª—å£"""
    
    def __init__(self):
        super().__init__()
        self.engine = None
        self.processing_thread = None
        self.config = ProcessingConfig()
        self.character_profiles = {}
        self.current_video = ""
        self.animation_generator = None
        self.animation_thread = None
        
        self.init_ui()
        self.load_config()
        self.setup_default_characters()
        
        logger.info("ä¸»çª—å£åˆå§‹åŒ–å®Œæˆ")
    
    def init_ui(self):
        """åˆå§‹åŒ–ç•Œé¢"""
        self.setWindowTitle("ğŸ­ AIé…éŸ³å·¥å‚ - è¶…å¼ºå˜´ç‚®ç‰ˆ ğŸš€")
        self.setGeometry(100, 100, 1200, 800)
        
        self.setup_stylesheet()
        
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)
        
        self.tab_widget = QTabWidget()
        main_layout.addWidget(self.tab_widget)
        
        self.setup_project_tab()
        self.setup_character_tab()
        self.setup_settings_tab()
        self.setup_batch_tab()
        self.setup_animation_tab()
        
        self.setup_status_bar()
        self.setup_menu_bar()
    
    def setup_stylesheet(self):
        """è®¾ç½®æ ·å¼è¡¨"""
        self.setStyleSheet("""
            QMainWindow {
                background-color: #1e1e1e;
            }
            QTabWidget::pane {
                border: 1px solid #444;
                background-color: #2d2d2d;
            }
            QTabBar::tab {
                background-color: #3d3d3d;
                color: #ffffff;
                padding: 8px 16px;
                margin-right: 2px;
                border-top-left-radius: 4px;
                border-top-right-radius: 4px;
            }
            QTabBar::tab:selected {
                background-color: #007acc;
                color: white;
            }
            QTabBar::tab:hover {
                background-color: #505050;
            }
            QGroupBox {
                color: #ffffff;
                border: 2px solid #555;
                border-radius: 5px;
                margin-top: 10px;
                font-weight: bold;
                font-size: 14px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px 0 5px;
                color: #4ec9b0;
            }
            QLabel {
                color: #cccccc;
                font-size: 13px;
            }
            QPushButton {
                background-color: #007acc;
                border: none;
                color: white;
                padding: 8px 16px;
                border-radius: 4px;
                font-weight: bold;
                font-size: 13px;
                min-height: 28px;
            }
            QPushButton:hover {
                background-color: #1c97ea;
            }
            QPushButton:pressed {
                background-color: #005a9e;
            }
            QPushButton:disabled {
                background-color: #505050;
                color: #888888;
            }
            QLineEdit, QTextEdit, QComboBox, QSpinBox, QDoubleSpinBox {
                background-color: #3d3d3d;
                color: #ffffff;
                border: 1px solid #555;
                border-radius: 3px;
                padding: 5px;
                font-size: 13px;
                selection-background-color: #007acc;
            }
            QLineEdit:focus, QTextEdit:focus {
                border: 1px solid #007acc;
            }
            QProgressBar {
                border: 1px solid #555;
                border-radius: 3px;
                text-align: center;
                color: white;
                font-size: 12px;
                background-color: #3d3d3d;
            }
            QProgressBar::chunk {
                background-color: #007acc;
                border-radius: 3px;
            }
            QTableWidget {
                background-color: #2d2d2d;
                color: #ffffff;
                gridline-color: #444;
                font-size: 12px;
            }
            QTableWidget::item {
                padding: 5px;
            }
            QTableWidget::item:selected {
                background-color: #007acc;
            }
            QHeaderView::section {
                background-color: #3d3d3d;
                color: white;
                padding: 5px;
                border: 1px solid #444;
                font-weight: bold;
            }
            QScrollBar:vertical {
                background-color: #2d2d2d;
                width: 12px;
                margin: 0px;
            }
            QScrollBar::handle:vertical {
                background-color: #505050;
                border-radius: 6px;
                min-height: 20px;
            }
            QScrollBar::handle:vertical:hover {
                background-color: #606060;
            }
            QScrollBar::add-line:vertical, QScrollBar::sub-line:vertical {
                height: 0px;
            }
        """)
    
    def setup_project_tab(self):
        """è®¾ç½®é¡¹ç›®æ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        video_group = QGroupBox("è§†é¢‘æ–‡ä»¶")
        video_layout = QVBoxLayout()
        
        input_layout = QHBoxLayout()
        input_layout.addWidget(QLabel("è¾“å…¥è§†é¢‘:"))
        
        self.input_edit = QLineEdit()
        self.input_edit.setPlaceholderText("é€‰æ‹©è¦é…éŸ³çš„è§†é¢‘æ–‡ä»¶...")
        input_layout.addWidget(self.input_edit)
        
        self.input_browse_btn = QPushButton("æµè§ˆ...")
        self.input_browse_btn.clicked.connect(self.browse_input_video)
        input_layout.addWidget(self.input_browse_btn)
        
        video_layout.addLayout(input_layout)
        
        output_layout = QHBoxLayout()
        output_layout.addWidget(QLabel("è¾“å‡ºè·¯å¾„:"))
        
        self.output_edit = QLineEdit()
        self.output_edit.setPlaceholderText("è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºè·¯å¾„...")
        output_layout.addWidget(self.output_edit)
        
        self.output_browse_btn = QPushButton("æµè§ˆ...")
        self.output_browse_btn.clicked.connect(self.browse_output_path)
        output_layout.addWidget(self.output_browse_btn)
        
        video_layout.addLayout(output_layout)
        
        preview_layout = QHBoxLayout()
        self.preview_label = QLabel("æœªé€‰æ‹©è§†é¢‘")
        self.preview_label.setAlignment(Qt.AlignCenter)
        self.preview_label.setMinimumHeight(150)
        self.preview_label.setStyleSheet("""
            QLabel {
                background-color: #3d3d3d;
                border: 2px dashed #555;
                border-radius: 5px;
                color: #888;
                font-size: 14px;
            }
        """)
        preview_layout.addWidget(self.preview_label)
        video_layout.addLayout(preview_layout)
        
        video_group.setLayout(video_layout)
        layout.addWidget(video_group)
        
        control_group = QGroupBox("å¤„ç†æ§åˆ¶")
        control_layout = QVBoxLayout()
        
        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setTextVisible(True)
        control_layout.addWidget(self.progress_bar)
        
        button_layout = QHBoxLayout()
        
        self.start_btn = QPushButton("â–¶ å¼€å§‹å¤„ç†")
        self.start_btn.clicked.connect(self.start_processing)
        self.start_btn.setMinimumHeight(40)
        self.start_btn.setStyleSheet("""
            QPushButton {
                background-color: #4CAF50;
                font-size: 16px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #45a049;
            }
            QPushButton:disabled {
                background-color: #555;
            }
        """)
        button_layout.addWidget(self.start_btn)
        
        self.pause_btn = QPushButton("â¸ æš‚åœ")
        self.pause_btn.clicked.connect(self.pause_processing)
        self.pause_btn.setEnabled(False)
        self.pause_btn.setMinimumHeight(40)
        button_layout.addWidget(self.pause_btn)
        
        self.stop_btn = QPushButton("â¹ åœæ­¢")
        self.stop_btn.clicked.connect(self.stop_processing)
        self.stop_btn.setEnabled(False)
        self.stop_btn.setMinimumHeight(40)
        self.stop_btn.setStyleSheet("""
            QPushButton {
                background-color: #f44336;
            }
            QPushButton:hover {
                background-color: #da190b;
            }
        """)
        button_layout.addWidget(self.stop_btn)
        
        control_layout.addLayout(button_layout)
        control_group.setLayout(control_layout)
        layout.addWidget(control_group)
        
        log_group = QGroupBox("å¤„ç†æ—¥å¿—")
        log_layout = QVBoxLayout()
        
        self.log_text = QTextEdit()
        self.log_text.setReadOnly(True)
        self.log_text.setMaximumHeight(200)
        self.log_text.setStyleSheet("""
            QTextEdit {
                background-color: #1e1e1e;
                color: #d4d4d4;
                font-family: 'Consolas', 'Monaco', monospace;
                font-size: 12px;
            }
        """)
        log_layout.addWidget(self.log_text)
        
        log_control_layout = QHBoxLayout()
        log_control_layout.addWidget(QLabel("æ—¥å¿—çº§åˆ«:"))
        
        self.log_level_combo = QComboBox()
        self.log_level_combo.addItems(["DEBUG", "INFO", "WARNING", "ERROR"])
        self.log_level_combo.setCurrentText("INFO")
        self.log_level_combo.currentTextChanged.connect(self.change_log_level)
        log_control_layout.addWidget(self.log_level_combo)
        
        clear_log_btn = QPushButton("æ¸…ç©ºæ—¥å¿—")
        clear_log_btn.clicked.connect(self.clear_log)
        log_control_layout.addWidget(clear_log_btn)
        
        save_log_btn = QPushButton("ä¿å­˜æ—¥å¿—")
        save_log_btn.clicked.connect(self.save_log)
        log_control_layout.addWidget(save_log_btn)
        
        log_control_layout.addStretch()
        log_layout.addLayout(log_control_layout)
        
        log_group.setLayout(log_layout)
        layout.addWidget(log_group)
        
        self.tab_widget.addTab(tab, "ğŸ¬ é¡¹ç›®")
    
    def setup_character_tab(self):
        """è®¾ç½®è§’è‰²æ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        info_label = QLabel("ğŸ­ ä¸ºæ¯ä¸ªè§’è‰²é…ç½®éŸ³è‰²å’Œé£æ ¼ï¼Œæ‰“é€ ç‹¬ä¸€æ— äºŒçš„å˜´ç‚®å¤©å›¢ï¼")
        info_label.setStyleSheet("font-size: 14px; font-weight: bold; color: #4ec9b0;")
        layout.addWidget(info_label)
        
        self.character_table = QTableWidget()
        self.character_table.setColumnCount(8)
        self.character_table.setHorizontalHeaderLabels([
            "è§’è‰²", "åŸç‰ˆå", "è¯­éŸ³é£æ ¼", "éŸ³è‰²æ–‡ä»¶", "è¯­é€Ÿ", "å¼ºåº¦", "æƒ…æ„Ÿ", "æ“ä½œ"
        ])
        
        header = self.character_table.horizontalHeader()
        header.setSectionResizeMode(0, QHeaderView.ResizeToContents)
        header.setSectionResizeMode(1, QHeaderView.ResizeToContents)
        header.setSectionResizeMode(2, QHeaderView.Stretch)
        header.setSectionResizeMode(3, QHeaderView.Stretch)
        header.setSectionResizeMode(4, QHeaderView.ResizeToContents)
        header.setSectionResizeMode(5, QHeaderView.ResizeToContents)
        header.setSectionResizeMode(6, QHeaderView.ResizeToContents)
        header.setSectionResizeMode(7, QHeaderView.ResizeToContents)
        
        layout.addWidget(self.character_table)
        
        control_layout = QHBoxLayout()
        
        add_btn = QPushButton("â• æ·»åŠ è§’è‰²")
        add_btn.clicked.connect(self.add_character)
        control_layout.addWidget(add_btn)
        
        remove_btn = QPushButton("â– åˆ é™¤è§’è‰²")
        remove_btn.clicked.connect(self.remove_character)
        control_layout.addWidget(remove_btn)
        
        import_btn = QPushButton("ğŸ“¥ å¯¼å…¥é…ç½®")
        import_btn.clicked.connect(self.import_character_config)
        control_layout.addWidget(import_btn)
        
        export_btn = QPushButton("ğŸ“¤ å¯¼å‡ºé…ç½®")
        export_btn.clicked.connect(self.export_character_config)
        control_layout.addWidget(export_btn)
        
        preset_btn = QPushButton("ğŸ­ åŠ è½½é¢„è®¾")
        preset_btn.clicked.connect(self.load_preset_characters)
        control_layout.addWidget(preset_btn)
        
        test_all_btn = QPushButton("ğŸ”Š æµ‹è¯•å…¨éƒ¨")
        test_all_btn.clicked.connect(self.test_all_voices)
        control_layout.addWidget(test_all_btn)
        
        control_layout.addStretch()
        layout.addLayout(control_layout)
        
        preset_info = QLabel("""
        ğŸ¯ æ¨èé¢„è®¾ç»„åˆï¼š
        â€¢ å“†å•¦Aæ¢¦ â†’ æäº‘é¾™ï¼ˆæš´èºå°†å†›ï¼‰
        â€¢ å¤§é›„ â†’ ç‹å¢ƒæ³½ï¼ˆçœŸé¦™å®šå¾‹ï¼‰
        â€¢ é™é¦™ â†’ ä½Ÿæ¹˜ç‰ï¼ˆç¢ç¢å¿µæŒæŸœï¼‰
        â€¢ èƒ–è™ â†’ å¼ é£ï¼ˆæš´èºä¸‰çˆ·ï¼‰
        â€¢ å°å¤« â†’ é©¬ä¿å›½ï¼ˆæ··å…ƒå¤ªæï¼‰
        â€¢ å“†å•¦ç¾ â†’ ç½—ç¿”ï¼ˆæ³•å¾‹ç›¸å£°ï¼‰
        â€¢ å‡ºæœ¨æ‰ â†’ è°¢å°”é¡¿ï¼ˆå­¦éœ¸å˜²è®½ï¼‰
        """)
        preset_info.setStyleSheet("""
            QLabel {
                background-color: #252525;
                border: 1px solid #444;
                border-radius: 5px;
                padding: 10px;
                color: #b5cea8;
                font-size: 12px;
            }
        """)
        layout.addWidget(preset_info)
        
        self.tab_widget.addTab(tab, "ğŸ­ è§’è‰²")
    
    def setup_settings_tab(self):
        """è®¾ç½®è®¾ç½®æ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        ai_group = QGroupBox("ğŸ¤– AIæ¨¡å‹è®¾ç½®")
        ai_layout = QVBoxLayout()
        
        whisper_layout = QHBoxLayout()
        whisper_layout.addWidget(QLabel("è¯­éŸ³è¯†åˆ«æ¨¡å‹:"))
        self.whisper_combo = QComboBox()
        self.whisper_combo.addItems(["tiny", "base", "small", "medium", "large-v3"])
        self.whisper_combo.setCurrentText("large-v3")
        whisper_layout.addWidget(self.whisper_combo)
        whisper_layout.addStretch()
        ai_layout.addLayout(whisper_layout)
        
        translate_layout = QHBoxLayout()
        translate_layout.addWidget(QLabel("ç¿»è¯‘æ¨¡å‹:"))
        self.translate_combo = QComboBox()
        self.translate_combo.addItems([
            "qwen3:4b",
            "qwen3:14b",
            "llama3.2:3b",
            "moondream:latest",
            "llava:7b",
            "llava:13b",
            "huihui_ai/deepseek-r1-abliterated:14b",
            "huihui_ai/qwen3-abliterated:16b"
        ])
        self.translate_combo.setCurrentText("qwen3:4b")
        self.translate_combo.setEditable(True)
        translate_layout.addWidget(self.translate_combo)
        
        refresh_models_btn = QPushButton("ğŸ”„ åˆ·æ–°")
        refresh_models_btn.clicked.connect(self.refresh_ollama_models)
        translate_layout.addWidget(refresh_models_btn)
        
        translate_layout.addStretch()
        ai_layout.addLayout(translate_layout)
        
        ollama_layout = QHBoxLayout()
        ollama_layout.addWidget(QLabel("OllamaåŸºç¡€åœ°å€:"))
        self.ollama_api_edit = QLineEdit("http://127.0.0.1:11434")
        ollama_layout.addWidget(self.ollama_api_edit)
        
        test_ollama_btn = QPushButton("æµ‹è¯•é…ç½®")
        test_ollama_btn.clicked.connect(self.test_ollama_api)
        test_ollama_btn.setStyleSheet("background-color: #4CAF50; color: white; font-weight: bold;")
        ollama_layout.addWidget(test_ollama_btn)
        ai_layout.addLayout(ollama_layout)
        
        api_info = QLabel("ğŸ’¡ ä½¿ç”¨åŸç”ŸOllama API: {åŸºç¡€åœ°å€}/api/generate")
        api_info.setStyleSheet("color: #b5cea8; font-size: 11px;")
        ai_layout.addWidget(api_info)
        
        tts_layout = QHBoxLayout()
        tts_layout.addWidget(QLabel("TTS APIåœ°å€:"))
        self.tts_api_edit = QLineEdit("http://127.0.0.1:5021/api/tts")
        tts_layout.addWidget(self.tts_api_edit)
        test_tts_btn = QPushButton("æµ‹è¯•")
        test_tts_btn.clicked.connect(self.test_tts_api)
        tts_layout.addWidget(test_tts_btn)
        ai_layout.addLayout(tts_layout)
        
        tts_info = QLabel("ğŸ’¡ TTSæœåŠ¡: python api.py --port 5021")
        tts_info.setStyleSheet("color: #b5cea8; font-size: 11px;")
        ai_layout.addWidget(tts_info)
        
        params_layout = QHBoxLayout()
        params_layout.addWidget(QLabel("Temperature:"))
        self.temperature_spin = QDoubleSpinBox()
        self.temperature_spin.setRange(0.0, 2.0)
        self.temperature_spin.setSingleStep(0.1)
        self.temperature_spin.setValue(0.1)
        params_layout.addWidget(self.temperature_spin)
        
        params_layout.addWidget(QLabel("Max Tokens:"))
        self.max_tokens_spin = QSpinBox()
        self.max_tokens_spin.setRange(1, 100000)
        self.max_tokens_spin.setValue(4096)
        params_layout.addWidget(self.max_tokens_spin)
        
        params_layout.addWidget(QLabel("Timeout(sec):"))
        self.timeout_spin = QSpinBox()
        self.timeout_spin.setRange(1, 3600)
        self.timeout_spin.setValue(60)
        params_layout.addWidget(self.timeout_spin)
        
        ai_layout.addLayout(params_layout)
        ai_group.setLayout(ai_layout)
        layout.addWidget(ai_group)
        
        audio_group = QGroupBox("ğŸ”Š éŸ³é¢‘è®¾ç½®")
        audio_layout = QVBoxLayout()
        
        sr_layout = QHBoxLayout()
        sr_layout.addWidget(QLabel("é‡‡æ ·ç‡:"))
        self.sample_rate_combo = QComboBox()
        self.sample_rate_combo.addItems(["16000", "22050", "24000", "44100", "48000"])
        self.sample_rate_combo.setCurrentText("24000")
        sr_layout.addWidget(self.sample_rate_combo)
        audio_layout.addLayout(sr_layout)
        
        volume_layout = QHBoxLayout()
        volume_layout.addWidget(QLabel("é…éŸ³éŸ³é‡:"))
        self.voice_volume_slider = QSlider(Qt.Horizontal)
        self.voice_volume_slider.setRange(0, 200)
        self.voice_volume_slider.setValue(80)
        volume_layout.addWidget(self.voice_volume_slider)
        self.voice_volume_label = QLabel("80%")
        volume_layout.addWidget(self.voice_volume_label)
        self.voice_volume_slider.valueChanged.connect(
            lambda v: self.voice_volume_label.setText(f"{v}%")
        )
        audio_layout.addLayout(volume_layout)
        
        bg_volume_layout = QHBoxLayout()
        bg_volume_layout.addWidget(QLabel("èƒŒæ™¯éŸ³é‡:"))
        self.bg_volume_slider = QSlider(Qt.Horizontal)
        self.bg_volume_slider.setRange(0, 100)
        self.bg_volume_slider.setValue(30)
        bg_volume_layout.addWidget(self.bg_volume_slider)
        self.bg_volume_label = QLabel("30%")
        bg_volume_layout.addWidget(self.bg_volume_label)
        self.bg_volume_slider.valueChanged.connect(
            lambda v: self.bg_volume_label.setText(f"{v}%")
        )
        audio_layout.addLayout(bg_volume_layout)
        
        self.keep_bg_check = QCheckBox("ä¿ç•™èƒŒæ™¯éŸ³ä¹å’ŒéŸ³æ•ˆ")
        self.keep_bg_check.setChecked(True)
        audio_layout.addWidget(self.keep_bg_check)
        
        self.noise_reduction_check = QCheckBox("å¯ç”¨é™å™ª")
        self.noise_reduction_check.setChecked(True)
        audio_layout.addWidget(self.noise_reduction_check)
        
        self.normalize_check = QCheckBox("éŸ³é¢‘å½’ä¸€åŒ–")
        self.normalize_check.setChecked(True)
        audio_layout.addWidget(self.normalize_check)
        
        audio_group.setLayout(audio_layout)
        layout.addWidget(audio_group)
        
        lip_sync_group = QGroupBox("ğŸ‘„ å£å‹å¯¹é½è®¾ç½®")
        lip_sync_layout = QVBoxLayout()
        
        self.lip_sync_check = QCheckBox("å¯ç”¨å£å‹å¯¹é½")
        self.lip_sync_check.setChecked(True)
        lip_sync_layout.addWidget(self.lip_sync_check)
        
        strength_layout = QHBoxLayout()
        strength_layout.addWidget(QLabel("å¯¹é½å¼ºåº¦:"))
        self.lip_sync_strength_slider = QSlider(Qt.Horizontal)
        self.lip_sync_strength_slider.setRange(0, 100)
        self.lip_sync_strength_slider.setValue(80)
        strength_layout.addWidget(self.lip_sync_strength_slider)
        self.lip_sync_strength_label = QLabel("80%")
        strength_layout.addWidget(self.lip_sync_strength_label)
        self.lip_sync_strength_slider.valueChanged.connect(
            lambda v: self.lip_sync_strength_label.setText(f"{v}%")
        )
        lip_sync_layout.addLayout(strength_layout)
        
        method_layout = QHBoxLayout()
        method_layout.addWidget(QLabel("å¯¹é½æ–¹æ³•:"))
        self.lip_sync_method_combo = QComboBox()
        self.lip_sync_method_combo.addItems(["æ—¶é—´æ‹‰ä¼¸", "èŠ‚å¥åŒ¹é…", "æ™ºèƒ½å¯¹é½"])
        self.lip_sync_method_combo.setCurrentText("æ—¶é—´æ‹‰ä¼¸")
        method_layout.addWidget(self.lip_sync_method_combo)
        lip_sync_layout.addLayout(method_layout)
        
        lip_sync_group.setLayout(lip_sync_layout)
        layout.addWidget(lip_sync_group)
        
        process_group = QGroupBox("âš™ï¸ å¤„ç†è®¾ç½®")
        process_layout = QVBoxLayout()
        
        gpu_layout = QHBoxLayout()
        self.gpu_check = QCheckBox("å¯ç”¨GPUåŠ é€Ÿ")
        self.gpu_check.setChecked(True)
        gpu_layout.addWidget(self.gpu_check)
        
        gpu_layout.addWidget(QLabel("GPU ID:"))
        self.gpu_id_spin = QSpinBox()
        self.gpu_id_spin.setRange(0, 7)
        self.gpu_id_spin.setValue(0)
        gpu_layout.addWidget(self.gpu_id_spin)
        gpu_layout.addStretch()
        process_layout.addLayout(gpu_layout)
        
        batch_layout = QHBoxLayout()
        batch_layout.addWidget(QLabel("ç¿»è¯‘æ‰¹æ¬¡å¤§å°:"))
        self.translation_batch_spin = QSpinBox()
        self.translation_batch_spin.setRange(1, 50)
        self.translation_batch_spin.setValue(10)
        batch_layout.addWidget(self.translation_batch_spin)
        
        batch_layout.addWidget(QLabel("TTSæ‰¹æ¬¡å¤§å°:"))
        self.tts_batch_spin = QSpinBox()
        self.tts_batch_spin.setRange(1, 10)
        self.tts_batch_spin.setValue(3)
        batch_layout.addWidget(self.tts_batch_spin)
        batch_layout.addStretch()
        process_layout.addLayout(batch_layout)
        
        parallel_layout = QHBoxLayout()
        parallel_layout.addWidget(QLabel("å¹¶è¡Œçº¿ç¨‹æ•°:"))
        self.workers_spin = QSpinBox()
        self.workers_spin.setRange(1, 16)
        self.workers_spin.setValue(4)
        parallel_layout.addWidget(self.workers_spin)
        parallel_layout.addStretch()
        process_layout.addLayout(parallel_layout)
        
        cache_layout = QHBoxLayout()
        self.cache_check = QCheckBox("å¯ç”¨ç¼“å­˜")
        self.cache_check.setChecked(True)
        cache_layout.addWidget(self.cache_check)
        process_layout.addLayout(cache_layout)
        
        process_group.setLayout(process_layout)
        layout.addWidget(process_group)
        
        save_btn = QPushButton("ğŸ’¾ ä¿å­˜æ‰€æœ‰è®¾ç½®")
        save_btn.clicked.connect(self.save_settings)
        save_btn.setMinimumHeight(40)
        layout.addWidget(save_btn)
        
        layout.addStretch()
        self.tab_widget.addTab(tab, "âš™ï¸ è®¾ç½®")
    
    def setup_batch_tab(self):
        """è®¾ç½®æ‰¹é‡å¤„ç†æ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        info_label = QLabel("ğŸ“ æ‰¹é‡å¤„ç†æ•´ä¸ªæ–‡ä»¶å¤¹çš„è§†é¢‘æ–‡ä»¶ï¼Œè‡ªåŠ¨åº”ç”¨ç›¸åŒçš„è§’è‰²é…ç½®")
        info_label.setStyleSheet("font-size: 14px; font-weight: bold; color: #4ec9b0;")
        layout.addWidget(info_label)
        
        folder_group = QGroupBox("æ–‡ä»¶å¤¹è®¾ç½®")
        folder_layout = QVBoxLayout()
        
        input_folder_layout = QHBoxLayout()
        input_folder_layout.addWidget(QLabel("è¾“å…¥æ–‡ä»¶å¤¹:"))
        self.input_folder_edit = QLineEdit()
        self.input_folder_edit.setPlaceholderText("é€‰æ‹©åŒ…å«è§†é¢‘æ–‡ä»¶çš„æ–‡ä»¶å¤¹...")
        input_folder_layout.addWidget(self.input_folder_edit)
        
        self.input_folder_browse_btn = QPushButton("æµè§ˆ...")
        self.input_folder_browse_btn.clicked.connect(self.browse_input_folder)
        input_folder_layout.addWidget(self.input_folder_browse_btn)
        folder_layout.addLayout(input_folder_layout)
        
        output_folder_layout = QHBoxLayout()
        output_folder_layout.addWidget(QLabel("è¾“å‡ºæ–‡ä»¶å¤¹:"))
        self.output_folder_edit = QLineEdit()
        self.output_folder_edit.setPlaceholderText("é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹...")
        output_folder_layout.addWidget(self.output_folder_edit)
        
        self.output_folder_browse_btn = QPushButton("æµè§ˆ...")
        self.output_folder_browse_btn.clicked.connect(self.browse_output_folder)
        output_folder_layout.addWidget(self.output_folder_browse_btn)
        folder_layout.addLayout(output_folder_layout)
        
        filter_layout = QHBoxLayout()
        filter_layout.addWidget(QLabel("æ–‡ä»¶æ ¼å¼:"))
        self.file_filter_combo = QComboBox()
        self.file_filter_combo.addItems(["*.mp4", "*.avi", "*.mkv", "*.mov", "æ‰€æœ‰è§†é¢‘æ–‡ä»¶"])
        filter_layout.addWidget(self.file_filter_combo)
        filter_layout.addStretch()
        folder_layout.addLayout(filter_layout)
        
        folder_group.setLayout(folder_layout)
        layout.addWidget(folder_group)
        
        files_group = QGroupBox("æ–‡ä»¶åˆ—è¡¨")
        files_layout = QVBoxLayout()
        
        self.file_list = QListWidget()
        self.file_list.setSelectionMode(QListWidget.ExtendedSelection)
        files_layout.addWidget(self.file_list)
        
        file_control_layout = QHBoxLayout()
        
        scan_btn = QPushButton("ğŸ” æ‰«ææ–‡ä»¶")
        scan_btn.clicked.connect(self.scan_video_files)
        file_control_layout.addWidget(scan_btn)
        
        select_all_btn = QPushButton("âœ“ å…¨é€‰")
        select_all_btn.clicked.connect(lambda: self.file_list.selectAll())
        file_control_layout.addWidget(select_all_btn)
        
        clear_all_btn = QPushButton("âœ— æ¸…ç©º")
        clear_all_btn.clicked.connect(lambda: self.file_list.clear())
        file_control_layout.addWidget(clear_all_btn)
        
        file_control_layout.addStretch()
        files_layout.addLayout(file_control_layout)
        
        files_group.setLayout(files_layout)
        layout.addWidget(files_group)
        
        batch_control_group = QGroupBox("æ‰¹é‡å¤„ç†")
        batch_control_layout = QVBoxLayout()
        
        self.batch_progress_bar = QProgressBar()
        self.batch_progress_bar.setRange(0, 100)
        batch_control_layout.addWidget(self.batch_progress_bar)
        
        batch_button_layout = QHBoxLayout()
        
        self.batch_start_btn = QPushButton("â–¶ å¼€å§‹æ‰¹é‡å¤„ç†")
        self.batch_start_btn.clicked.connect(self.start_batch_processing)
        batch_button_layout.addWidget(self.batch_start_btn)
        
        self.batch_stop_btn = QPushButton("â¹ åœæ­¢")
        self.batch_stop_btn.clicked.connect(self.stop_batch_processing)
        self.batch_stop_btn.setEnabled(False)
        batch_button_layout.addWidget(self.batch_stop_btn)
        
        batch_button_layout.addStretch()
        batch_control_layout.addLayout(batch_button_layout)
        
        batch_control_group.setLayout(batch_control_layout)
        layout.addWidget(batch_control_group)
        
        self.tab_widget.addTab(tab, "ğŸ“ æ‰¹é‡")
    
    def setup_animation_tab(self):
        """è®¾ç½®åŠ¨ç”»æ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        info_label = QLabel("ğŸ¬ AIé©±åŠ¨åŠ¨ç”»ç”Ÿæˆ - é›†æˆComfyUIäººç‰©ä¸€è‡´æ€§")
        info_label.setStyleSheet("font-size: 16px; font-weight: bold; color: #4ec9b0;")
        layout.addWidget(info_label)
        
        desc_label = QLabel("""ğŸ¤– åˆ©ç”¨AIç”Ÿæˆå¼äººå·¥æ™ºèƒ½è¿›è¡Œæ™ºèƒ½æ–‡æœ¬åˆ†æå’ŒåŠ¨ç”»æç¤ºæå–
ğŸ­ è‡ªåŠ¨å£å‹åŒæ­¥ï¼šç”ŸæˆéŸ³ç´ æ•°æ®ï¼Œä½¿è§’è‰²å˜´éƒ¨åŠ¨ä½œä¸å¯¹è¯åŒæ­¥
ğŸ‘ï¸ åŠ¨æ€è§’è‰²è¡¨æƒ…ï¼šæ”¯æŒå¤´éƒ¨åŠ¨ä½œã€çœ¼ç¥è¡¨æƒ…å’Œè‚¢ä½“è¯­è¨€
ğŸ¨ å¤šè§’è‰²æ”¯æŒï¼šå¤„ç†å¤šä¸ªå…·æœ‰é²œæ˜è§†è§‰ç´ æå’Œä¸ªæ€§çš„è§’è‰²
ğŸµ éŸ³é¢‘åŒæ­¥ï¼šé€šè¿‡è½¬å½•æœåŠ¡ï¼Œå°†åŠ¨ç”»ä¸éŸ³é¢‘æ—¶é—´å®Œç¾å¯¹é½
ğŸ–¼ï¸ å¯æ‰©å±•èµ„äº§ç³»ç»Ÿï¼šæ˜“ç”¨çš„è§’è‰²å’ŒèƒŒæ™¯èµ„äº§ç®¡ç†
ğŸ“¹ é€å¸§ç”Ÿæˆï¼šé€šè¿‡åˆæˆå•ä¸ªå¸§æ¥åˆ›å»ºæµç•…åŠ¨ç”»
ğŸ”„ è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹ï¼šä»å‰§æœ¬åˆ°æœ€ç»ˆè§†é¢‘çš„å®Œæ•´æµç¨‹""")
        desc_label.setStyleSheet("""
            QLabel {
                background-color: #252525;
                border: 1px solid #444;
                border-radius: 5px;
                padding: 10px;
                color: #b5cea8;
                font-size: 12px;
                line-height: 1.5;
            }
        """)
        layout.addWidget(desc_label)
        
        comfyui_group = QGroupBox("ğŸ”— ComfyUIè¿æ¥")
        comfyui_layout = QVBoxLayout()
        
        status_layout = QHBoxLayout()
        status_layout.addWidget(QLabel("è¿æ¥çŠ¶æ€:"))
        self.comfyui_status_label = QLabel("æœªè¿æ¥")
        self.comfyui_status_label.setStyleSheet("color: #f44747; font-weight: bold;")
        status_layout.addWidget(self.comfyui_status_label)
        comfyui_layout.addLayout(status_layout)
        
        server_layout = QHBoxLayout()
        server_layout.addWidget(QLabel("æœåŠ¡å™¨åœ°å€:"))
        self.comfyui_host_edit = QLineEdit("127.0.0.1")
        server_layout.addWidget(self.comfyui_host_edit)
        
        server_layout.addWidget(QLabel("ç«¯å£:"))
        self.comfyui_port_edit = QSpinBox()
        self.comfyui_port_edit.setRange(1, 65535)
        self.comfyui_port_edit.setValue(8188)
        server_layout.addWidget(self.comfyui_port_edit)
        comfyui_layout.addLayout(server_layout)
        
        connect_btn = QPushButton("ğŸ”Œ è¿æ¥ComfyUI")
        connect_btn.clicked.connect(self.connect_comfyui)
        comfyui_layout.addWidget(connect_btn)
        
        comfyui_group.setLayout(comfyui_layout)
        layout.addWidget(comfyui_group)
        
        animation_config_group = QGroupBox("âš™ï¸ åŠ¨ç”»é…ç½®")
        animation_config_layout = QVBoxLayout()
        
        resolution_layout = QHBoxLayout()
        resolution_layout.addWidget(QLabel("åˆ†è¾¨ç‡:"))
        self.animation_width_spin = QSpinBox()
        self.animation_width_spin.setRange(256, 4096)
        self.animation_width_spin.setValue(512)
        resolution_layout.addWidget(self.animation_width_spin)
        resolution_layout.addWidget(QLabel("Ã—"))
        self.animation_height_spin = QSpinBox()
        self.animation_height_spin.setRange(256, 4096)
        self.animation_height_spin.setValue(768)
        resolution_layout.addWidget(self.animation_height_spin)
        animation_config_layout.addLayout(resolution_layout)
        
        fps_layout = QHBoxLayout()
        fps_layout.addWidget(QLabel("å¸§ç‡(FPS):"))
        self.animation_fps_spin = QSpinBox()
        self.animation_fps_spin.setRange(1, 60)
        self.animation_fps_spin.setValue(24)
        fps_layout.addWidget(self.animation_fps_spin)
        animation_config_layout.addLayout(fps_layout)
        
        style_layout = QHBoxLayout()
        style_layout.addWidget(QLabel("åŠ¨ç”»é£æ ¼:"))
        self.animation_style_combo = QComboBox()
        self.animation_style_combo.addItems(["åŠ¨æ¼«", "ç”µå½±", "å¡é€š", "å†™å®", "ç»˜ç”»", "åƒç´ è‰ºæœ¯"])
        self.animation_style_combo.setCurrentText("åŠ¨æ¼«")
        style_layout.addWidget(self.animation_style_combo)
        animation_config_layout.addLayout(style_layout)
        
        consistency_layout = QHBoxLayout()
        consistency_layout.addWidget(QLabel("äººç‰©ä¸€è‡´æ€§æ–¹æ³•:"))
        self.consistency_method_combo = QComboBox()
        self.consistency_method_combo.addItems(["IP-Adapter", "InstantID", "PhotoMaker", "LoRA", "ControlNet"])
        self.consistency_method_combo.setCurrentText("IP-Adapter")
        style_layout.addWidget(self.consistency_method_combo)
        animation_config_layout.addLayout(consistency_layout)
        
        strength_layout = QHBoxLayout()
        strength_layout.addWidget(QLabel("ä¸€è‡´æ€§å¼ºåº¦:"))
        self.consistency_strength_slider = QSlider(Qt.Horizontal)
        self.consistency_strength_slider.setRange(10, 100)
        self.consistency_strength_slider.setValue(70)
        strength_layout.addWidget(self.consistency_strength_slider)
        self.consistency_strength_label = QLabel("70%")
        strength_layout.addWidget(self.consistency_strength_label)
        self.consistency_strength_slider.valueChanged.connect(
            lambda v: self.consistency_strength_label.setText(f"{v}%")
        )
        animation_config_layout.addLayout(strength_layout)
        
        scene_layout = QHBoxLayout()
        scene_layout.addWidget(QLabel("åœºæ™¯æè¿°:"))
        self.scene_description_edit = QLineEdit()
        self.scene_description_edit.setPlaceholderText("ä¾‹å¦‚ï¼šç¾ä¸½çš„èŠ±å›­ï¼Œæ¨±èŠ±ç››å¼€ï¼Œé˜³å…‰æ˜åªš")
        scene_layout.addWidget(self.scene_description_edit)
        animation_config_layout.addLayout(scene_layout)
        
        features_layout = QHBoxLayout()
        self.animation_lip_sync_check = QCheckBox("å£å‹åŒæ­¥")
        self.animation_lip_sync_check.setChecked(True)
        features_layout.addWidget(self.animation_lip_sync_check)
        
        self.expression_check = QCheckBox("è¡¨æƒ…åŠ¨ç”»")
        self.expression_check.setChecked(True)
        features_layout.addWidget(self.expression_check)
        
        self.head_movement_check = QCheckBox("å¤´éƒ¨åŠ¨ä½œ")
        self.head_movement_check.setChecked(True)
        features_layout.addWidget(self.head_movement_check)
        
        self.eye_movement_check = QCheckBox("çœ¼éƒ¨åŠ¨ä½œ")
        self.eye_movement_check.setChecked(True)
        features_layout.addWidget(self.eye_movement_check)
        
        animation_config_layout.addLayout(features_layout)
        
        animation_config_group.setLayout(animation_config_layout)
        layout.addWidget(animation_config_group)
        
        character_binding_group = QGroupBox("ğŸ­ è§’è‰²ç»‘å®š")
        character_binding_layout = QVBoxLayout()
        
        self.animation_character_table = QTableWidget()
        self.animation_character_table.setColumnCount(4)
        self.animation_character_table.setHorizontalHeaderLabels([
            "é…éŸ³è§’è‰²", "å‚è€ƒå›¾ç‰‡", "åŠ¨ç”»è§’è‰²å", "æ“ä½œ"
        ])
        character_binding_layout.addWidget(self.animation_character_table)
        
        binding_btn_layout = QHBoxLayout()
        
        auto_bind_btn = QPushButton("ğŸ¤– è‡ªåŠ¨ç»‘å®šè§’è‰²")
        auto_bind_btn.clicked.connect(self.auto_bind_characters)
        binding_btn_layout.addWidget(auto_bind_btn)
        
        manual_bind_btn = QPushButton("âœï¸ æ‰‹åŠ¨ç»‘å®š")
        manual_bind_btn.clicked.connect(self.manual_bind_character)
        binding_btn_layout.addWidget(manual_bind_btn)
        
        clear_bindings_btn = QPushButton("ğŸ—‘ï¸ æ¸…ç©ºç»‘å®š")
        clear_bindings_btn.clicked.connect(self.clear_character_bindings)
        binding_btn_layout.addWidget(clear_bindings_btn)
        
        character_binding_layout.addLayout(binding_btn_layout)
        character_binding_group.setLayout(character_binding_layout)
        layout.addWidget(character_binding_group)
        
        generation_group = QGroupBox("ğŸš€ åŠ¨ç”»ç”Ÿæˆ")
        generation_layout = QVBoxLayout()
        
        self.animation_progress_bar = QProgressBar()
        self.animation_progress_bar.setRange(0, 100)
        generation_layout.addWidget(self.animation_progress_bar)
        
        button_layout = QHBoxLayout()
        
        self.animation_generate_btn = QPushButton("ğŸ¬ ç”ŸæˆåŠ¨ç”»")
        self.animation_generate_btn.clicked.connect(self.generate_animation)
        self.animation_generate_btn.setMinimumHeight(40)
        self.animation_generate_btn.setStyleSheet("""
            QPushButton {
                background-color: #9C27B0;
                font-size: 16px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #7B1FA2;
            }
            QPushButton:disabled {
                background-color: #555;
            }
        """)
        button_layout.addWidget(self.animation_generate_btn)
        
        self.animation_stop_btn = QPushButton("â¹ åœæ­¢")
        self.animation_stop_btn.clicked.connect(self.stop_animation_generation)
        self.animation_stop_btn.setEnabled(False)
        self.animation_stop_btn.setMinimumHeight(40)
        button_layout.addWidget(self.animation_stop_btn)
        
        preview_btn = QPushButton("ğŸ‘ï¸ é¢„è§ˆ")
        preview_btn.clicked.connect(self.preview_animation)
        preview_btn.setMinimumHeight(40)
        button_layout.addWidget(preview_btn)
        
        button_layout.addStretch()
        generation_layout.addLayout(button_layout)
        
        generation_group.setLayout(generation_layout)
        layout.addWidget(generation_group)
        
        openai_group = QGroupBox("ğŸ¤– OpenAIé›†æˆ (å¯é€‰)")
        openai_layout = QVBoxLayout()
        
        openai_layout.addWidget(QLabel("APIå¯†é’¥:"))
        self.openai_api_key_edit = QLineEdit()
        self.openai_api_key_edit.setPlaceholderText("è¾“å…¥OpenAI APIå¯†é’¥")
        self.openai_api_key_edit.setEchoMode(QLineEdit.Password)
        openai_layout.addWidget(self.openai_api_key_edit)
        
        openai_layout.addWidget(QLabel("åŸºç¡€URL:"))
        self.openai_base_url_edit = QLineEdit("https://apis.iflow.cn/v1")
        openai_layout.addWidget(self.openai_base_url_edit)
        
        self.enable_openai_check = QCheckBox("å¯ç”¨OpenAIå¢å¼º")
        self.enable_openai_check.setChecked(False)
        openai_layout.addWidget(self.enable_openai_check)
        
        openai_group.setLayout(openai_layout)
        layout.addWidget(openai_group)
        
        layout.addStretch()
        self.tab_widget.addTab(tab, "ğŸ¬ åŠ¨ç”»ç”Ÿæˆ")
    
    def setup_status_bar(self):
        """è®¾ç½®çŠ¶æ€æ """
        self.status_bar = self.statusBar()
        
        self.status_label = QLabel("å°±ç»ª")
        self.status_bar.addWidget(self.status_label)
        
        self.progress_label = QLabel("")
        self.status_bar.addWidget(self.progress_label)
        
        self.time_label = QLabel("")
        self.status_bar.addWidget(self.time_label)
        
        self.status_timer = QTimer()
        self.status_timer.timeout.connect(self.update_status_time)
        self.status_timer.start(1000)
    
    def setup_menu_bar(self):
        """è®¾ç½®èœå•æ """
        menubar = self.menuBar()
        
        file_menu = menubar.addMenu("ğŸ“ æ–‡ä»¶")
        
        new_project_action = QAction("ğŸ†• æ–°å»ºé¡¹ç›®", self)
        new_project_action.triggered.connect(self.new_project)
        file_menu.addAction(new_project_action)
        
        open_project_action = QAction("ğŸ“‚ æ‰“å¼€é¡¹ç›®", self)
        open_project_action.triggered.connect(self.open_project)
        file_menu.addAction(open_project_action)
        
        save_project_action = QAction("ğŸ’¾ ä¿å­˜é¡¹ç›®", self)
        save_project_action.triggered.connect(self.save_project)
        file_menu.addAction(save_project_action)
        
        file_menu.addSeparator()
        
        exit_action = QAction("ğŸšª é€€å‡º", self)
        exit_action.triggered.connect(self.close)
        file_menu.addAction(exit_action)
        
        tools_menu = menubar.addMenu("ğŸ› ï¸ å·¥å…·")
        
        voice_manager_action = QAction("ğŸµ éŸ³è‰²ç®¡ç†å™¨", self)
        voice_manager_action.triggered.connect(self.open_voice_manager)
        tools_menu.addAction(voice_manager_action)
        
        subtitle_editor_action = QAction("ğŸ“ å­—å¹•ç¼–è¾‘å™¨", self)
        subtitle_editor_action.triggered.connect(self.open_subtitle_editor)
        tools_menu.addAction(subtitle_editor_action)
        
        audio_editor_action = QAction("ğŸ›ï¸ éŸ³é¢‘ç¼–è¾‘å™¨", self)
        audio_editor_action.triggered.connect(self.open_audio_editor)
        tools_menu.addAction(audio_editor_action)
        
        help_menu = menubar.addMenu("â“ å¸®åŠ©")
        
        docs_action = QAction("ğŸ“š ä½¿ç”¨æ–‡æ¡£", self)
        docs_action.triggered.connect(self.open_documentation)
        help_menu.addAction(docs_action)
        
        about_action = QAction("â„¹ï¸ å…³äº", self)
        about_action.triggered.connect(self.show_about)
        help_menu.addAction(about_action)
    
    def setup_default_characters(self):
        """è®¾ç½®é»˜è®¤è§’è‰²"""
        default_characters = [
            ("å“†å•¦Aæ¢¦", "ãƒ‰ãƒ©ãˆã‚‚ã‚“", VoiceStyle.LI_YUNLONG),
            ("å¤§é›„", "é‡æ¯”ã®ã³å¤ª", VoiceStyle.WANG_JINGZE),
            ("é™é¦™", "æºé™é¦™", VoiceStyle.TONG_XIANGYU),
            ("èƒ–è™", "å‰›ç”°æ­¦", VoiceStyle.ZHANG_FEI),
            ("å°å¤«", "éª¨å·ã‚¹ãƒå¤«", VoiceStyle.MA_BAOGUO),
            ("å“†å•¦ç¾", "ãƒ‰ãƒ©ãƒŸ", VoiceStyle.LUO_XIANG),
            ("å‡ºæœ¨æ‰", "å‡ºæœ¨æ‰è‹±æ‰", VoiceStyle.SHELDON),
            ("å°å®å½“", "", VoiceStyle.GUO_DEGANG),
        ]
        
        for name, original_name, style in default_characters:
            profile = CharacterProfile.get_preset(name)
            profile.original_name = original_name
            profile.voice_style = style
            self.character_profiles[name] = profile
    
    def load_config(self):
        """åŠ è½½é…ç½®"""
        config_file = Path("config.json")
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                self.input_edit.setText(config_data.get('last_input_video', ''))
                self.output_edit.setText(config_data.get('last_output_path', ''))
                self.tts_api_edit.setText(config_data.get('tts_api', 'http://127.0.0.1:5021/api/tts'))
                self.ollama_api_edit.setText(config_data.get('ollama_api', 'http://127.0.0.1:11434'))
                self.whisper_combo.setCurrentText(config_data.get('whisper_model', 'large-v3'))
                self.translate_combo.setCurrentText(config_data.get('translate_model', 'qwen3:4b'))
                self.translation_batch_spin.setValue(config_data.get('translation_batch_size', 10))
                self.tts_batch_spin.setValue(config_data.get('tts_batch_size', 3))
                
                self.lip_sync_check.setChecked(config_data.get('lip_sync_enabled', True))
                self.lip_sync_strength_slider.setValue(config_data.get('lip_sync_strength', 80))
                self.lip_sync_method_combo.setCurrentText(config_data.get('lip_sync_method', 'æ—¶é—´æ‹‰ä¼¸'))
                
                self.character_profiles.clear()
                
                char_profiles = config_data.get('character_profiles', {})
                for name, char_data in char_profiles.items():
                    try:
                        voice_file = char_data.get('voice_file', '')
                        if voice_file:
                            voice_filename = os.path.basename(voice_file)
                            possible_paths = [
                                os.path.join('voices', voice_filename),
                                os.path.join('.', voice_filename),
                                voice_filename,
                                os.path.join('voices', f"{voice_filename}.wav"),
                                os.path.join('voices', f"{voice_filename}.mp3")
                            ]
                            
                            for path in possible_paths:
                                if os.path.exists(path):
                                    voice_file = path
                                    logger.info(f"æ‰¾åˆ°éŸ³è‰²æ–‡ä»¶: {path}")
                                    break
                            else:
                                logger.warning(f"éŸ³è‰²æ–‡ä»¶ä¸å­˜åœ¨: {char_data.get('voice_file')}")
                                voice_file = ""
                        
                        voice_style_value = char_data.get('voice_style', 'é»˜è®¤')
                        try:
                            voice_style = VoiceStyle(voice_style_value)
                        except:
                            voice_style = VoiceStyle.DEFAULT
                        
                        profile = CharacterProfile(
                            name=char_data.get('name', name),
                            original_name=char_data.get('original_name', name),
                            voice_style=voice_style,
                            voice_file=voice_file,
                            speed=float(char_data.get('speed', 1.0)),
                            pitch=float(char_data.get('pitch', 1.0)),
                            emotion=char_data.get('emotion', 'neutral'),
                            intensity=float(char_data.get('intensity', 1.0)),
                            catchphrases=list(char_data.get('catchphrases', [])),
                            reference_image=char_data.get('reference_image', '')
                        )
                        self.character_profiles[name] = profile
                    except Exception as e:
                        logger.warning(f"åŠ è½½è§’è‰² {name} é…ç½®å¤±è´¥: {e}")
                        self.character_profiles[name] = CharacterProfile.get_preset(name)
                
                logger.info("é…ç½®åŠ è½½æˆåŠŸ")
                self.refresh_character_table()
                
            except json.JSONDecodeError as e:
                logger.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
                self.setup_default_characters()
                self.refresh_character_table()
            except Exception as e:
                logger.error(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
                self.setup_default_characters()
                self.refresh_character_table()
        else:
            self.setup_default_characters()
            self.refresh_character_table()
    
    def save_config(self):
        """ä¿å­˜é…ç½®"""
        config_data = {
            'last_input_video': self.input_edit.text(),
            'last_output_path': self.output_edit.text(),
            'tts_api': self.tts_api_edit.text(),
            'ollama_api': self.ollama_api_edit.text(),
            'whisper_model': self.whisper_combo.currentText(),
            'translate_model': self.translate_combo.currentText(),
            'translation_batch_size': self.translation_batch_spin.value(),
            'tts_batch_size': self.tts_batch_spin.value(),
            'lip_sync_enabled': self.lip_sync_check.isChecked(),
            'lip_sync_strength': self.lip_sync_strength_slider.value(),
            'lip_sync_method': self.lip_sync_method_combo.currentText(),
            'character_profiles': {}
        }
        
        for name, profile in self.character_profiles.items():
            config_data['character_profiles'][name] = {
                'name': profile.name,
                'original_name': profile.original_name,
                'voice_style': profile.voice_style.value,
                'voice_file': profile.voice_file or '',
                'speed': float(profile.speed),
                'pitch': float(profile.pitch),
                'emotion': profile.emotion,
                'intensity': float(profile.intensity),
                'catchphrases': list(profile.catchphrases),
                'reference_image': profile.reference_image or ''
            }
        
        try:
            with open('config.json', 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            logger.info("é…ç½®ä¿å­˜æˆåŠŸ")
        except Exception as e:
            logger.error(f"é…ç½®ä¿å­˜å¤±è´¥: {e}")
    
    # ============== äº‹ä»¶å¤„ç†å‡½æ•° ==============
    
    def browse_input_video(self):
        """æµè§ˆè¾“å…¥è§†é¢‘"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©è§†é¢‘æ–‡ä»¶", "", 
            "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mkv *.mov *.flv);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
        )
        
        if file_path:
            self.input_edit.setText(file_path)
            self.current_video = file_path
            
            video_path = Path(file_path)
            output_path = video_path.parent / f"{video_path.stem}_dubbed{video_path.suffix}"
            self.output_edit.setText(str(output_path))
            
            self.preview_label.setText(f"å·²é€‰æ‹©: {video_path.name}\nå¤§å°: {video_path.stat().st_size // 1024 // 1024}MB")
    
    def browse_output_path(self):
        """æµè§ˆè¾“å‡ºè·¯å¾„"""
        file_path, _ = QFileDialog.getSaveFileName(
            self, "é€‰æ‹©è¾“å‡ºæ–‡ä»¶", self.output_edit.text(),
            "è§†é¢‘æ–‡ä»¶ (*.mp4);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
        )
        
        if file_path:
            self.output_edit.setText(file_path)
    
    def browse_input_folder(self):
        """æµè§ˆè¾“å…¥æ–‡ä»¶å¤¹"""
        folder_path = QFileDialog.getExistingDirectory(self, "é€‰æ‹©è¾“å…¥æ–‡ä»¶å¤¹")
        if folder_path:
            self.input_folder_edit.setText(folder_path)
    
    def browse_output_folder(self):
        """æµè§ˆè¾“å‡ºæ–‡ä»¶å¤¹"""
        folder_path = QFileDialog.getExistingDirectory(self, "é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹")
        if folder_path:
            self.output_folder_edit.setText(folder_path)
    
    def start_processing(self):
        """å¼€å§‹å¤„ç†"""
        video_path = self.input_edit.text()
        output_path = self.output_edit.text()
        
        if not video_path or not os.path.exists(video_path):
            QMessageBox.warning(self, "é”™è¯¯", "è¯·é€‰æ‹©æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶")
            return
        
        if not output_path:
            QMessageBox.warning(self, "é”™è¯¯", "è¯·æŒ‡å®šè¾“å‡ºè·¯å¾„")
            return
        
        if not self.character_profiles:
            QMessageBox.warning(self, "é”™è¯¯", "è¯·è‡³å°‘é…ç½®ä¸€ä¸ªè§’è‰²")
            return
        
        self.config.input_video = video_path
        self.config.output_video = output_path
        self.config.tts_api_url = self.tts_api_edit.text()
        self.config.ollama_url = self.ollama_api_edit.text()
        self.config.whisper_model = self.whisper_combo.currentText()
        self.config.translate_model = self.translate_combo.currentText()
        self.config.sample_rate = int(self.sample_rate_combo.currentText())
        self.config.use_gpu = self.gpu_check.isChecked()
        self.config.gpu_id = self.gpu_id_spin.value()
        self.config.num_workers = self.workers_spin.value()
        self.config.cache_enabled = self.cache_check.isChecked()
        self.config.keep_background = self.keep_bg_check.isChecked()
        self.config.background_volume = self.bg_volume_slider.value() / 100
        self.config.voice_volume = self.voice_volume_slider.value() / 100
        self.config.noise_reduction = self.noise_reduction_check.isChecked()
        self.config.normalize_audio = self.normalize_check.isChecked()
        self.config.translation_batch_size = self.translation_batch_spin.value()
        self.config.tts_batch_size = self.tts_batch_spin.value()
        
        self.config.lip_sync_enabled = self.lip_sync_check.isChecked()
        self.config.lip_sync_strength = self.lip_sync_strength_slider.value() / 100
        self.config.lip_sync_method = self.lip_sync_method_combo.currentText()
        
        self.add_log_message(f"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}", "INFO")
        self.add_log_message(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}", "INFO")
        self.add_log_message(f"ğŸ¤– OllamaåŸºç¡€åœ°å€: {self.config.ollama_url}", "INFO")
        self.add_log_message(f"ğŸ¤– æ„å»ºçš„API URL: {self.config.get_ollama_api_url()}", "INFO")
        self.add_log_message(f"ğŸ¤– Ollamaæ¨¡å‹: {self.config.translate_model}", "INFO")
        self.add_log_message(f"ğŸµ TTS API: {self.config.tts_api_url}", "INFO")
        self.add_log_message(f"ğŸ­ è§’è‰²æ•°é‡: {len(self.character_profiles)}", "INFO")
        self.add_log_message(f"ğŸ‘„ å£å‹å¯¹é½: {'å¯ç”¨' if self.config.lip_sync_enabled else 'ç¦ç”¨'}", "INFO")
        
        try:
            test_url = self.config.get_ollama_api_url().replace('/api/generate', '/api/tags')
            test_response = requests.get(test_url, timeout=5)
            if test_response.status_code == 200:
                self.add_log_message("âœ… OllamaæœåŠ¡è¿æ¥æ­£å¸¸", "INFO")
            else:
                self.add_log_message(f"âš ï¸ OllamaæœåŠ¡æµ‹è¯•å¤±è´¥: {test_response.status_code}", "WARNING")
        except Exception as e:
            self.add_log_message(f"âš ï¸ OllamaæœåŠ¡æµ‹è¯•å¼‚å¸¸: {e}", "WARNING")
        
        try:
            self.engine = DubbingEngine(self.config)
            
            for profile in self.character_profiles.values():
                self.engine.add_character_profile(profile)
            
            self.processing_thread = ProcessingThread(self.engine, video_path)
            
            self.processing_thread.progress_updated.connect(self.update_progress)
            self.processing_thread.log_message.connect(self.add_log_message)
            self.processing_thread.finished.connect(self.processing_finished)
            self.processing_thread.error.connect(self.processing_error)
            
            self.start_btn.setEnabled(False)
            self.pause_btn.setEnabled(True)
            self.stop_btn.setEnabled(True)
            self.progress_bar.setValue(0)
            self.log_text.clear()
            
            self.processing_thread.start()
            
            logger.info("å¼€å§‹å¤„ç†è§†é¢‘")
            
        except TypeError as e:
            error_msg = f"åˆ›å»ºDubbingEngineå¤±è´¥: {str(e)}"
            self.add_log_message(f"âŒ {error_msg}", "ERROR")
            QMessageBox.critical(self, "åˆå§‹åŒ–é”™è¯¯", error_msg)
            self.start_btn.setEnabled(True)
            self.pause_btn.setEnabled(False)
            self.stop_btn.setEnabled(False)
    
    def pause_processing(self):
        """æš‚åœå¤„ç†"""
        if self.processing_thread:
            pass
    
    def stop_processing(self):
        """åœæ­¢å¤„ç†"""
        if self.processing_thread and self.processing_thread.isRunning():
            self.processing_thread.terminate()
            self.processing_thread.wait()
            
            self.start_btn.setEnabled(True)
            self.pause_btn.setEnabled(False)
            self.stop_btn.setEnabled(False)
            
            self.add_log_message("å¤„ç†å·²åœæ­¢", "WARNING")
    
    def update_progress(self, value: int, message: str):
        """æ›´æ–°è¿›åº¦"""
        self.progress_bar.setValue(value)
        self.status_label.setText(message)
    
    def add_log_message(self, message: str, level: str):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        level_color = {
            "DEBUG": "#888888",
            "INFO": "#4ec9b0",
            "WARNING": "#d7ba7d",
            "ERROR": "#f44747"
        }.get(level, "#cccccc")
        
        html = f'<span style="color:#888888">[{timestamp}]</span> <span style="color:{level_color}">{message}</span><br>'
        
        current_html = self.log_text.toHtml()
        self.log_text.setHtml(current_html + html)
        
        scrollbar = self.log_text.verticalScrollBar()
        scrollbar.setValue(scrollbar.maximum())
    
    def processing_finished(self, output_path: str):
        """å¤„ç†å®Œæˆ"""
        self.start_btn.setEnabled(True)
        self.pause_btn.setEnabled(False)
        self.stop_btn.setEnabled(False)
        self.progress_bar.setValue(100)
        
        self.add_log_message(f"âœ… å¤„ç†å®Œæˆ: {output_path}", "INFO")
        
        reply = QMessageBox.question(
            self, "å¤„ç†å®Œæˆ",
            f"è§†é¢‘å·²ä¿å­˜åˆ°:\n{output_path}\n\næ˜¯å¦æ‰“å¼€æ‰€åœ¨æ–‡ä»¶å¤¹ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            folder_path = os.path.dirname(output_path)
            QDesktopServices.openUrl(QUrl.fromLocalFile(folder_path))
    
    def processing_error(self, error_msg: str):
        """å¤„ç†é”™è¯¯"""
        self.start_btn.setEnabled(True)
        self.pause_btn.setEnabled(False)
        self.stop_btn.setEnabled(False)
        
        self.add_log_message(error_msg, "ERROR")
        QMessageBox.critical(self, "å¤„ç†é”™è¯¯", error_msg)
    
    def add_character(self):
        """æ·»åŠ è§’è‰²"""
        name, ok = QInputDialog.getText(self, "æ·»åŠ è§’è‰²", "è¯·è¾“å…¥è§’è‰²åç§°:")
        if ok and name:
            if name in self.character_profiles:
                QMessageBox.warning(self, "é”™è¯¯", f"è§’è‰² {name} å·²å­˜åœ¨")
                return
            
            dialog = CharacterConfigDialog(name, self)
            if dialog.exec():
                profile = dialog.get_profile()
                self.character_profiles[name] = profile
                self.refresh_character_table()
    
    def remove_character(self):
        """åˆ é™¤è§’è‰²"""
        selected_items = self.character_table.selectedItems()
        if not selected_items:
            QMessageBox.warning(self, "é”™è¯¯", "è¯·å…ˆé€‰æ‹©è¦åˆ é™¤çš„è§’è‰²")
            return
        
        rows = set(item.row() for item in selected_items)
        
        reply = QMessageBox.question(
            self, "ç¡®è®¤åˆ é™¤",
            f"ç¡®å®šè¦åˆ é™¤ {len(rows)} ä¸ªè§’è‰²å—ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            characters_to_remove = []
            for row in rows:
                char_name = self.character_table.item(row, 0).text()
                characters_to_remove.append(char_name)
            
            for char_name in characters_to_remove:
                if char_name in self.character_profiles:
                    del self.character_profiles[char_name]
            
            self.refresh_character_table()
    
    def refresh_character_table(self):
        """åˆ·æ–°è§’è‰²è¡¨æ ¼"""
        self.character_table.setRowCount(len(self.character_profiles))
        
        for i in range(len(self.character_profiles)):
            self.character_table.setRowHeight(i, 35)
        
        for i, (name, profile) in enumerate(self.character_profiles.items()):
            self.character_table.setItem(i, 0, QTableWidgetItem(name))
            self.character_table.setItem(i, 1, QTableWidgetItem(profile.original_name))
            self.character_table.setItem(i, 2, QTableWidgetItem(profile.voice_style.value))
            
            voice_display = ""
            if profile.voice_file:
                voice_path = Path(profile.voice_file)
                if voice_path.exists():
                    voice_display = voice_path.name
                else:
                    voice_display = "âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨"
            else:
                voice_display = "æœªè®¾ç½®"
            
            self.character_table.setItem(i, 3, QTableWidgetItem(voice_display))
            self.character_table.setItem(i, 4, QTableWidgetItem(f"{profile.speed:.1f}"))
            self.character_table.setItem(i, 5, QTableWidgetItem(f"{profile.intensity:.1f}"))
            self.character_table.setItem(i, 6, QTableWidgetItem(profile.emotion))
            
            btn_widget = QWidget()
            btn_widget.setStyleSheet("background-color: transparent;")
            btn_layout = QHBoxLayout(btn_widget)
            btn_layout.setContentsMargins(4, 2, 4, 2)
            btn_layout.setSpacing(4)
            
            edit_btn = QPushButton("ç¼–è¾‘")
            edit_btn.clicked.connect(lambda checked, idx=i: self.edit_character(idx))
            edit_btn.setFixedSize(45, 24)
            edit_btn.setStyleSheet("""
                QPushButton {
                    background-color: #3d3d3d;
                    color: #cccccc;
                    border: 1px solid #555;
                    border-radius: 2px;
                    font-size: 10px;
                    padding: 2px;
                }
                QPushButton:hover {
                    background-color: #505050;
                    border: 1px solid #666;
                }
                QPushButton:pressed {
                    background-color: #2d2d2d;
                }
            """)
            btn_layout.addWidget(edit_btn)
            
            voice_btn = QPushButton("éŸ³è‰²")
            voice_btn.clicked.connect(lambda checked, idx=i: self.select_voice_for_character(idx))
            voice_btn.setFixedSize(45, 24)
            voice_btn.setStyleSheet("""
                QPushButton {
                    background-color: #3d3d3d;
                    color: #cccccc;
                    border: 1px solid #555;
                    border-radius: 2px;
                    font-size: 10px;
                    padding: 2px;
                }
                QPushButton:hover {
                    background-color: #505050;
                    border: 1px solid #666;
                }
                QPushButton:pressed {
                    background-color: #2d2d2d;
                }
            """)
            btn_layout.addWidget(voice_btn)
            
            test_btn = QPushButton("æµ‹è¯•")
            test_btn.clicked.connect(lambda checked, idx=i: self.test_character_voice(idx))
            test_btn.setFixedSize(45, 24)
            test_btn.setStyleSheet("""
                QPushButton {
                    background-color: #3d3d3d;
                    color: #cccccc;
                    border: 1px solid #555;
                    border-radius: 2px;
                    font-size: 10px;
                    padding: 2px;
                }
                QPushButton:hover {
                    background-color: #505050;
                    border: 1px solid #666;
                }
                QPushButton:pressed {
                    background-color: #2d2d2d;
                }
            """)
            btn_layout.addWidget(test_btn)
            
            self.character_table.setCellWidget(i, 7, btn_widget)
    
    def edit_character(self, row_index):
        """ç¼–è¾‘è§’è‰²"""
        char_name = self.character_table.item(row_index, 0).text()
        
        if char_name in self.character_profiles:
            dialog = CharacterConfigDialog(char_name, self)
            
            dialog.profile = self.character_profiles[char_name]
            dialog.name_edit.setText(dialog.profile.name)
            dialog.file_edit.setText(dialog.profile.voice_file)
            dialog.style_combo.setCurrentText(dialog.profile.voice_style.value)
            dialog.speed_slider.setValue(int(dialog.profile.speed * 100))
            dialog.pitch_slider.setValue(int(dialog.profile.pitch * 100))
            dialog.intensity_slider.setValue(int(dialog.profile.intensity * 100))
            dialog.emotion_combo.setCurrentText(dialog.profile.emotion)
            dialog.catchphrase_edit.setText("\n".join(dialog.profile.catchphrases))
            
            if dialog.exec():
                profile = dialog.get_profile()
                self.character_profiles[char_name] = profile
                self.refresh_character_table()
    
    def select_voice_for_character(self, row_index):
        """ä¸ºè§’è‰²é€‰æ‹©éŸ³è‰²"""
        char_name = self.character_table.item(row_index, 0).text()
        
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©éŸ³è‰²æ–‡ä»¶", "", 
            "éŸ³é¢‘æ–‡ä»¶ (*.wav *.mp3 *.ogg);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
        )
        
        if file_path:
            self.character_profiles[char_name].voice_file = file_path
            self.character_table.item(row_index, 3).setText(Path(file_path).name)
            
            self.add_log_message(
                f"å·²ä¸ºè§’è‰² '{char_name}' è®¾ç½®éŸ³è‰²: {Path(file_path).name}",
                "INFO"
            )
    
    def test_character_voice(self, row_index):
        """æµ‹è¯•è§’è‰²éŸ³è‰²"""
        char_name = self.character_table.item(row_index, 0).text()
        
        if char_name in self.character_profiles:
            profile = self.character_profiles[char_name]
            
            if not profile.voice_file:
                QMessageBox.warning(self, "é”™è¯¯", f"è§’è‰² {char_name} æœªé…ç½®éŸ³è‰²æ–‡ä»¶")
                return
            
            QMessageBox.information(
                self, "æµ‹è¯•éŸ³è‰²",
                f"æµ‹è¯• {char_name} çš„éŸ³è‰²\n"
                f"é£æ ¼: {profile.voice_style.value}\n"
                f"è¯­é€Ÿ: {profile.speed:.1f}\n"
                f"æƒ…æ„Ÿ: {profile.emotion}"
            )
    
    def test_all_voices(self):
        """æµ‹è¯•æ‰€æœ‰éŸ³è‰²"""
        if not self.character_profiles:
            QMessageBox.warning(self, "é”™è¯¯", "æ²¡æœ‰é…ç½®ä»»ä½•è§’è‰²")
            return
        
        QMessageBox.information(
            self, "æµ‹è¯•å…¨éƒ¨éŸ³è‰²",
            f"å¼€å§‹æµ‹è¯• {len(self.character_profiles)} ä¸ªè§’è‰²çš„éŸ³è‰²..."
        )
    
    def load_preset_characters(self):
        """åŠ è½½é¢„è®¾è§’è‰²"""
        reply = QMessageBox.question(
            self, "åŠ è½½é¢„è®¾",
            "ç¡®å®šè¦åŠ è½½é¢„è®¾è§’è‰²é…ç½®å—ï¼Ÿè¿™å°†è¦†ç›–å½“å‰çš„é…ç½®ã€‚",
            QMessageBox.Yes | QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            self.setup_default_characters()
            self.refresh_character_table()
            self.add_log_message("å·²åŠ è½½é¢„è®¾è§’è‰²é…ç½®", "INFO")
    
    def import_character_config(self):
        """å¯¼å…¥è§’è‰²é…ç½®"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "å¯¼å…¥è§’è‰²é…ç½®", "", "JSONæ–‡ä»¶ (*.json)"
        )
        
        if file_path:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                imported_count = 0
                
                for char_data in config_data.get('characters', []):
                    try:
                        char_name = char_data.get('name', 'æœªçŸ¥è§’è‰²')
                        
                        profile = CharacterProfile(
                            name=char_name,
                            original_name=char_data.get('original_name', char_name),
                            voice_style=VoiceStyle(char_data.get('voice_style', 'é»˜è®¤')),
                            voice_file=char_data.get('voice_file', ''),
                            speed=float(char_data.get('speed', 1.0)),
                            pitch=float(char_data.get('pitch', 1.0)),
                            emotion=char_data.get('emotion', 'neutral'),
                            intensity=float(char_data.get('intensity', 1.0)),
                            catchphrases=list(char_data.get('catchphrases', [])),
                            reference_image=char_data.get('reference_image', '')
                        )
                        
                        self.character_profiles[char_name] = profile
                        imported_count += 1
                        
                    except Exception as e:
                        logger.warning(f"å¯¼å…¥è§’è‰² {char_data.get('name', 'unknown')} å¤±è´¥: {e}")
                        continue
                
                self.refresh_character_table()
                
                success_msg = f"å·²æˆåŠŸå¯¼å…¥ {imported_count} ä¸ªè§’è‰²é…ç½®"
                self.add_log_message(f"{success_msg}: {file_path}", "INFO")
                QMessageBox.information(self, "å¯¼å…¥æˆåŠŸ", success_msg)
                
            except json.JSONDecodeError as e:
                error_msg = f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}"
                QMessageBox.critical(self, "å¯¼å…¥å¤±è´¥", error_msg)
                logger.error(error_msg)
            except Exception as e:
                error_msg = f"å¯¼å…¥å¤±è´¥: {str(e)}"
                QMessageBox.critical(self, "å¯¼å…¥å¤±è´¥", error_msg)
                logger.error(f"å¯¼å…¥è§’è‰²é…ç½®å¤±è´¥: {e}")
    
    def export_character_config(self):
        """å¯¼å‡ºè§’è‰²é…ç½®"""
        file_path, _ = QFileDialog.getSaveFileName(
            self, "å¯¼å‡ºè§’è‰²é…ç½®", "character_config.json", "JSONæ–‡ä»¶ (*.json)"
        )
        
        if file_path:
            try:
                config_data = {
                    'characters': []
                }
                
                for profile in self.character_profiles.values():
                    char_dict = {
                        'name': profile.name,
                        'original_name': profile.original_name,
                        'voice_style': profile.voice_style.value,
                        'voice_file': profile.voice_file,
                        'speed': float(profile.speed),
                        'pitch': float(profile.pitch),
                        'emotion': profile.emotion,
                        'intensity': float(profile.intensity),
                        'catchphrases': list(profile.catchphrases),
                        'reference_image': profile.reference_image or ''
                    }
                    config_data['characters'].append(char_dict)
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(config_data, f, ensure_ascii=False, indent=2)
                
                self.add_log_message(f"å·²å¯¼å‡ºè§’è‰²é…ç½®: {file_path}", "INFO")
                
                QMessageBox.information(self, "å¯¼å‡ºæˆåŠŸ", 
                    f"è§’è‰²é…ç½®å·²æˆåŠŸå¯¼å‡ºåˆ°:\n{file_path}\n\n"
                    f"å¯¼å‡ºäº† {len(self.character_profiles)} ä¸ªè§’è‰²")
                
            except Exception as e:
                error_msg = f"å¯¼å‡ºå¤±è´¥: {str(e)}"
                QMessageBox.critical(self, "å¯¼å‡ºå¤±è´¥", error_msg)
                logger.error(f"å¯¼å‡ºè§’è‰²é…ç½®å¤±è´¥: {e}")
    
    def test_tts_api(self):
        """æµ‹è¯•TTS API"""
        api_url = self.tts_api_edit.text()
        
        self.add_log_message(f"ğŸ” æµ‹è¯•TTS API: {api_url}", "INFO")
        
        try:
            import base64
            import numpy as np
            import soundfile as sf
            
            sr = 24000
            silence = np.zeros(sr, dtype=np.float32)
            test_audio_path = "test_connection.wav"
            sf.write(test_audio_path, silence, sr)
            
            with open(test_audio_path, 'rb') as f:
                audio_bytes = f.read()
            
            prompt_audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
            
            payload = {
                "tts_text": "ä½ å¥½ï¼Œä¸–ç•Œã€‚",
                "prompt_audio": prompt_audio_b64,
                "emo_control_method": 0,
                "do_sample": True,
                "temperature": 0.8,
                "top_p": 0.8,
                "top_k": 20,
                "repetition_penalty": 5.0,
                "max_mel_tokens": 200
            }
            
            self.add_log_message(f"å‘é€æµ‹è¯•è¯·æ±‚åˆ°: {api_url}", "INFO")
            self.add_log_message(f"Payload: {json.dumps(payload, ensure_ascii=False)[:200]}...", "DEBUG")
            
            response = requests.post(api_url, json=payload, timeout=30)
            
            self.add_log_message(f"APIå“åº”çŠ¶æ€: {response.status_code}", "INFO")
            
            if response.status_code == 200:
                try:
                    result = response.json()
                    self.add_log_message(f"APIå“åº”JSON: {str(result)[:200]}...", "DEBUG")
                    
                    if result.get("status") == "success":
                        self.add_log_message("âœ… TTS APIæµ‹è¯•æˆåŠŸï¼", "INFO")
                        
                        if "audio" in result:
                            audio_bytes = base64.b64decode(result["audio"])
                            with open("test_output.wav", "wb") as f:
                                f.write(audio_bytes)
                            self.add_log_message("âœ… æµ‹è¯•éŸ³é¢‘å·²ä¿å­˜: test_output.wav", "INFO")
                        
                        QMessageBox.information(self, "æµ‹è¯•æˆåŠŸ", "TTS APIè¿æ¥æ­£å¸¸ï¼ŒåŠŸèƒ½å¯ç”¨")
                    else:
                        error_msg = f"TTS APIè¿”å›é”™è¯¯çŠ¶æ€: {result.get('message', 'æœªçŸ¥é”™è¯¯')}"
                        self.add_log_message(f"âŒ {error_msg}", "ERROR")
                        QMessageBox.warning(self, "æµ‹è¯•å¤±è´¥", error_msg)
                        
                except json.JSONDecodeError as e:
                    error_msg = f"APIè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON: {e}\nå“åº”æ–‡æœ¬: {response.text[:200]}"
                    self.add_log_message(f"âŒ {error_msg}", "ERROR")
                    QMessageBox.warning(self, "æµ‹è¯•å¤±è´¥", error_msg)
            
            elif response.status_code == 400:
                error_msg = f"TTS APIè¿”å›400é”™è¯¯ï¼ˆè¯·æ±‚æ ¼å¼é”™è¯¯ï¼‰\n"
                try:
                    result = response.json()
                    error_msg += f"é”™è¯¯ä¿¡æ¯: {result.get('message', 'æ— è¯¦ç»†ä¿¡æ¯')}"
                except:
                    error_msg += f"å“åº”å†…å®¹: {response.text[:500]}"
                
                self.add_log_message(f"âŒ {error_msg}", "ERROR")
                
                self.add_log_message("ğŸ’¡ è¯Šæ–­å»ºè®®:", "INFO")
                self.add_log_message("1. æ£€æŸ¥TTS APIè¯·æ±‚æ ¼å¼æ˜¯å¦æ­£ç¡®", "INFO")
                self.add_log_message("2. æ£€æŸ¥éŸ³è‰²æ–‡ä»¶base64ç¼–ç æ˜¯å¦æ­£ç¡®", "INFO")
                self.add_log_message("3. å‚è€ƒTTS APIæ–‡æ¡£è°ƒæ•´å‚æ•°", "INFO")
                
                QMessageBox.critical(self, "æµ‹è¯•å¤±è´¥ - è¯·æ±‚æ ¼å¼é”™è¯¯", 
                    f"TTS APIè¿”å›400é”™è¯¯ï¼ˆè¯·æ±‚æ ¼å¼é”™è¯¯ï¼‰\n\n"
                    f"è¯·æ£€æŸ¥:\n"
                    f"1. è¯·æ±‚JSONæ ¼å¼æ˜¯å¦æ­£ç¡®\n"
                    f"2. éŸ³è‰²æ–‡ä»¶base64ç¼–ç \n"
                    f"3. è¯·æ±‚å‚æ•°æ˜¯å¦å®Œæ•´\n\n"
                    f"å“åº”å†…å®¹:\n{response.text[:300]}")
            
            elif response.status_code == 404:
                error_msg = f"APIç«¯ç‚¹ä¸å­˜åœ¨ (404)\nURL: {api_url}"
                self.add_log_message(f"âŒ {error_msg}", "ERROR")
                QMessageBox.warning(self, "æµ‹è¯•å¤±è´¥", error_msg)
            else:
                error_msg = f"TTS APIè¿”å›é”™è¯¯: {response.status_code}"
                try:
                    error_msg += f"\nå“åº”: {response.text[:300]}"
                except:
                    pass
                self.add_log_message(f"âŒ {error_msg}", "ERROR")
                QMessageBox.warning(self, "æµ‹è¯•å¤±è´¥", error_msg)
                    
        except requests.exceptions.ConnectionError:
            error_msg = f"æ— æ³•è¿æ¥åˆ°TTS API\nURL: {api_url}\nè¯·ç¡®ä¿TTSæœåŠ¡å·²å¯åŠ¨"
            self.add_log_message(f"âŒ {error_msg}", "ERROR")
            QMessageBox.critical(self, "æµ‹è¯•å¤±è´¥", error_msg)
        except requests.exceptions.Timeout:
            error_msg = "è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æœåŠ¡æ˜¯å¦æ­£å¸¸"
            self.add_log_message(f"âŒ {error_msg}", "ERROR")
            QMessageBox.critical(self, "æµ‹è¯•å¤±è´¥", error_msg)
        except Exception as e:
            error_msg = f"æµ‹è¯•æ—¶å‘ç”Ÿé”™è¯¯: {str(e)[:200]}"
            self.add_log_message(f"âŒ {error_msg}", "ERROR")
            QMessageBox.critical(self, "æµ‹è¯•å¤±è´¥", error_msg)
    
    def refresh_ollama_models(self):
        """åˆ·æ–°Ollamaæ¨¡å‹åˆ—è¡¨"""
        base_url = self.ollama_api_edit.text()
        
        base_url = base_url.rstrip('/')
        if '/v1' in base_url:
            base_url = base_url.split('/v1')[0].rstrip('/')
        elif '/api/generate' in base_url:
            base_url = base_url.split('/api/generate')[0].rstrip('/')
        elif '/api/chat' in base_url:
            base_url = base_url.split('/api/chat')[0].rstrip('/')
        
        models_url = f"{base_url}/api/tags"
        
        try:
            self.add_log_message(f"æ­£åœ¨è·å–æ¨¡å‹åˆ—è¡¨...", "INFO")
            response = requests.get(models_url, timeout=10)
            
            if response.status_code == 200:
                models_data = response.json()
                available_models = []
                
                if "models" in models_data:
                    for model in models_data["models"]:
                        model_name = model.get("name", "")
                        if model_name:
                            available_models.append(model_name)
                
                current_model = self.translate_combo.currentText()
                
                self.translate_combo.clear()
                for model in available_models:
                    self.translate_combo.addItem(model)
                
                if current_model in available_models:
                    self.translate_combo.setCurrentText(current_model)
                elif available_models:
                    self.translate_combo.setCurrentText(available_models[0])
                
                self.add_log_message(f"âœ… å·²åˆ·æ–°æ¨¡å‹åˆ—è¡¨ï¼Œæ‰¾åˆ° {len(available_models)} ä¸ªæ¨¡å‹", "INFO")
                
                QMessageBox.information(
                    self,
                    "åˆ·æ–°æˆåŠŸ",
                    f"å·²ä»Ollamaè·å–æ¨¡å‹åˆ—è¡¨\n\næ‰¾åˆ° {len(available_models)} ä¸ªæ¨¡å‹"
                )
                
            else:
                self.add_log_message(f"âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼ŒçŠ¶æ€ç : {response.status_code}", "ERROR")
                QMessageBox.warning(
                    self,
                    "åˆ·æ–°å¤±è´¥",
                    f"æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡\nçŠ¶æ€ç : {response.status_code}"
                )
                
        except requests.exceptions.ConnectionError:
            self.add_log_message(f"âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡", "ERROR")
            QMessageBox.critical(
                self,
                "è¿æ¥å¤±è´¥",
                "æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·ç¡®ä¿Ollamaå·²å¯åŠ¨"
            )
        except Exception as e:
            self.add_log_message(f"âŒ åˆ·æ–°æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}", "ERROR")
            QMessageBox.critical(
                self,
                "åˆ·æ–°å¤±è´¥",
                f"åˆ·æ–°æ¨¡å‹åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯:\n{str(e)}"
            )
    
    def test_ollama_api(self):
        """æµ‹è¯•Ollama APIé…ç½®"""
        base_url = self.ollama_api_edit.text()
        model_name = self.translate_combo.currentText()
        
        self.add_log_message(f"å¼€å§‹æµ‹è¯•Ollamaé…ç½®...", "INFO")
        
        try:
            temp_config = ProcessingConfig()
            temp_config.ollama_url = base_url
            api_url = temp_config.get_ollama_api_url()
            
            self.add_log_message(f"æ„å»ºçš„API URL: {api_url}", "INFO")
            
            test_url = api_url.replace('/api/generate', '/api/tags')
            self.add_log_message(f"æµ‹è¯•è¿æ¥URL: {test_url}", "DEBUG")
            
            test_response = requests.get(test_url, timeout=10)
            
            if test_response.status_code == 200:
                models_data = test_response.json()
                available_models = [m.get("name", "") for m in models_data.get("models", [])]
                
                if model_name in available_models:
                    self.add_log_message(f"âœ… æ‰¾åˆ°æ¨¡å‹: {model_name}", "INFO")
                else:
                    self.add_log_message(f"âš ï¸ æ¨¡å‹ {model_name} ä¸åœ¨å¯ç”¨æ¨¡å‹ä¸­", "WARNING")
            
            prompt = "Translate this Japanese to Chinese: ã“ã‚“ã«ã¡ã¯"
            
            data = {
                "model": model_name,
                "prompt": prompt,
                "stream": False,
                "temperature": 0.1,
                "max_tokens": 4096
            }
            
            headers = {
                "Content-Type": "application/json"
            }
            
            self.add_log_message(f"å‘é€æµ‹è¯•è¯·æ±‚åˆ°: {api_url}", "INFO")
            self.add_log_message(f"ä½¿ç”¨æ¨¡å‹: {model_name}", "INFO")
            
            response = requests.post(
                api_url,
                json=data,
                headers=headers,
                timeout=30
            )
            
            self.add_log_message(f"å“åº”çŠ¶æ€ç : {response.status_code}", "INFO")
            
            if response.status_code == 200:
                result = response.json()
                
                if "response" in result:
                    reply_text = result["response"].strip()
                    
                    if reply_text:
                        self.add_log_message("âœ… Ollamaé…ç½®æµ‹è¯•æˆåŠŸï¼", "INFO")
                        self.add_log_message(f"æµ‹è¯•å›å¤: {reply_text}", "INFO")
                        
                        QMessageBox.information(
                            self, 
                            "æµ‹è¯•æˆåŠŸ", 
                            f"Ollamaé…ç½®æµ‹è¯•æˆåŠŸï¼\n\n"
                            f"APIåœ°å€: {api_url}\n"
                            f"æ¨¡å‹: {model_name}\n"
                            f"å›å¤: {reply_text}"
                        )
                    else:
                        self.add_log_message("âŒ Ollamaé…ç½®æµ‹è¯•å¤±è´¥ï¼šæœªè·å–åˆ°å“åº”", "ERROR")
                        QMessageBox.warning(
                            self,
                            "æµ‹è¯•å¤±è´¥",
                            "Ollamaé…ç½®æµ‹è¯•å¤±è´¥ï¼šæœªè·å–åˆ°å“åº”\nè¯·æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ"
                        )
                else:
                    self.add_log_message("âŒ Ollama APIè¿”å›æ ¼å¼é”™è¯¯", "ERROR")
                    QMessageBox.warning(
                        self,
                        "æµ‹è¯•å¤±è´¥",
                        "Ollama APIè¿”å›æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥APIç«¯ç‚¹æ˜¯å¦æ­£ç¡®"
                    )
            else:
                error_text = response.text[:500] if response.text else "æ— è¯¦ç»†é”™è¯¯ä¿¡æ¯"
                self.add_log_message(f"âŒ Ollamaé…ç½®æµ‹è¯•å‡ºé”™: HTTP {response.status_code}", "ERROR")
                self.add_log_message(f"é”™è¯¯è¯¦æƒ…: {error_text}", "ERROR")
                
                QMessageBox.critical(
                    self,
                    "æµ‹è¯•å¤±è´¥",
                    f"Ollamaé…ç½®æµ‹è¯•å¤±è´¥\n\nHTTPçŠ¶æ€ç : {response.status_code}\né”™è¯¯: {error_text[:200]}"
                )
                
        except requests.exceptions.ConnectionError as e:
            self.add_log_message(f"âŒ Ollamaé…ç½®æµ‹è¯•å‡ºé”™: è¿æ¥å¤±è´¥ - {str(e)}", "ERROR")
            QMessageBox.critical(
                self,
                "è¿æ¥å¤±è´¥",
                f"æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡\n\nURL: {base_url}\nè¯·ç¡®ä¿OllamaæœåŠ¡å·²å¯åŠ¨\nå‘½ä»¤: ollama serve"
            )
        except requests.exceptions.Timeout as e:
            self.add_log_message(f"âŒ Ollamaé…ç½®æµ‹è¯•å‡ºé”™: è¿æ¥è¶…æ—¶ - {str(e)}", "ERROR")
            QMessageBox.critical(
                self,
                "è¶…æ—¶",
                f"è¿æ¥è¶…æ—¶\n\nè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å¢åŠ è¶…æ—¶æ—¶é—´"
            )
        except Exception as e:
            self.add_log_message(f"âŒ Ollamaé…ç½®æµ‹è¯•å‡ºé”™: {str(e)}", "ERROR")
            QMessageBox.critical(
                self,
                "æµ‹è¯•å¤±è´¥",
                f"æµ‹è¯•æ—¶å‘ç”Ÿé”™è¯¯:\n{str(e)[:200]}"
            )
    
    def save_settings(self):
        """ä¿å­˜è®¾ç½®"""
        self.save_config()
        QMessageBox.information(self, "ä¿å­˜æˆåŠŸ", "æ‰€æœ‰è®¾ç½®å·²ä¿å­˜")
    
    def scan_video_files(self):
        """æ‰«æè§†é¢‘æ–‡ä»¶"""
        input_folder = self.input_folder_edit.text()
        
        if not input_folder or not os.path.exists(input_folder):
            QMessageBox.warning(self, "é”™è¯¯", "è¯·é€‰æ‹©æœ‰æ•ˆçš„è¾“å…¥æ–‡ä»¶å¤¹")
            return
        
        self.file_list.clear()
        
        video_extensions = ['.mp4', '.avi', '.mkv', '.mov', '.flv']
        for root, dirs, files in os.walk(input_folder):
            for file in files:
                if any(file.lower().endswith(ext) for ext in video_extensions):
                    file_path = os.path.join(root, file)
                    item = QListWidgetItem(file_path)
                    self.file_list.addItem(item)
        
        self.add_log_message(f"æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {self.file_list.count()} ä¸ªè§†é¢‘æ–‡ä»¶", "INFO")
    
    def start_batch_processing(self):
        """å¼€å§‹æ‰¹é‡å¤„ç†"""
        QMessageBox.information(self, "æ‰¹é‡å¤„ç†", "æ‰¹é‡å¤„ç†åŠŸèƒ½å¼€å‘ä¸­...")
    
    def stop_batch_processing(self):
        """åœæ­¢æ‰¹é‡å¤„ç†"""
        pass
    
    def change_log_level(self, level: str):
        """æ›´æ”¹æ—¥å¿—çº§åˆ«"""
        logging.getLogger().setLevel(getattr(logging, level))
        logger.info(f"æ—¥å¿—çº§åˆ«å·²æ›´æ”¹ä¸º: {level}")
    
    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.log_text.clear()
    
    def save_log(self):
        """ä¿å­˜æ—¥å¿—"""
        file_path, _ = QFileDialog.getSaveFileName(
            self, "ä¿å­˜æ—¥å¿—", "dubbing_log.txt", "æ–‡æœ¬æ–‡ä»¶ (*.txt)"
        )
        
        if file_path:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(self.log_text.toPlainText())
                self.add_log_message(f"æ—¥å¿—å·²ä¿å­˜: {file_path}", "INFO")
            except Exception as e:
                QMessageBox.critical(self, "ä¿å­˜å¤±è´¥", str(e))
    
    def update_status_time(self):
        """æ›´æ–°çŠ¶æ€æ æ—¶é—´"""
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.time_label.setText(current_time)
    
    def new_project(self):
        """æ–°å»ºé¡¹ç›®"""
        reply = QMessageBox.question(
            self, "æ–°å»ºé¡¹ç›®",
            "ç¡®å®šè¦æ–°å»ºé¡¹ç›®å—ï¼Ÿæ‰€æœ‰æœªä¿å­˜çš„æ›´æ”¹å°†ä¼šä¸¢å¤±ã€‚",
            QMessageBox.Yes | QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            self.input_edit.clear()
            self.output_edit.clear()
            self.log_text.clear()
            self.character_profiles.clear()
            self.refresh_character_table()
            
            self.add_log_message("å·²åˆ›å»ºæ–°é¡¹ç›®", "INFO")
    
    def open_project(self):
        """æ‰“å¼€é¡¹ç›®"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "æ‰“å¼€é¡¹ç›®", "", "AIé…éŸ³å·¥å‚é¡¹ç›® (*.aiproj);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
        )
        
        if file_path:
            QMessageBox.information(self, "æ‰“å¼€é¡¹ç›®", f"æ‰“å¼€é¡¹ç›®: {file_path}")
    
    def save_project(self):
        """ä¿å­˜é¡¹ç›®"""
        file_path, _ = QFileDialog.getSaveFileName(
            self, "ä¿å­˜é¡¹ç›®", "my_project.aiproj", "AIé…éŸ³å·¥å‚é¡¹ç›® (*.aiproj)"
        )
        
        if file_path:
            QMessageBox.information(self, "ä¿å­˜é¡¹ç›®", f"ä¿å­˜é¡¹ç›®: {file_path}")
    
    def open_voice_manager(self):
        """æ‰“å¼€éŸ³è‰²ç®¡ç†å™¨"""
        QMessageBox.information(self, "éŸ³è‰²ç®¡ç†å™¨", "éŸ³è‰²ç®¡ç†å™¨å¼€å‘ä¸­...")
    
    def open_subtitle_editor(self):
        """æ‰“å¼€å­—å¹•ç¼–è¾‘å™¨"""
        QMessageBox.information(self, "å­—å¹•ç¼–è¾‘å™¨", "å­—å¹•ç¼–è¾‘å™¨å¼€å‘ä¸­...")
    
    def open_audio_editor(self):
        """æ‰“å¼€éŸ³é¢‘ç¼–è¾‘å™¨"""
        QMessageBox.information(self, "éŸ³é¢‘ç¼–è¾‘å™¨", "éŸ³é¢‘ç¼–è¾‘å™¨å¼€å‘ä¸­...")
    
    def open_documentation(self):
        """æ‰“å¼€æ–‡æ¡£"""
        QDesktopServices.openUrl(QUrl("https://github.com/yourusername/dubbing_factory"))
    
    def show_about(self):
        """æ˜¾ç¤ºå…³äºå¯¹è¯æ¡†"""
        about_text = """
        <h2>ğŸ­ AIé…éŸ³å·¥å‚ - è¶…å¼ºå˜´ç‚®ç‰ˆ ğŸš€</h2>
        <p><b>ç‰ˆæœ¬:</b> 3.4.0 - AIåŠ¨ç”»ç”Ÿæˆé›†æˆç‰ˆ</p>
        <p><b>ä½œè€…:</b> AIåŠ©æ‰‹</p>
        <p><b>æè¿°:</b> åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨è§†é¢‘é…éŸ³å·¥å…·ï¼Œé›†æˆComfyUIäººç‰©ä¸€è‡´æ€§å’ŒAIåŠ¨ç”»ç”Ÿæˆã€‚</p>
        <p><b>æ ¸å¿ƒåŠŸèƒ½:</b></p>
        <ul>
            <li>âœ… æ™ºèƒ½é…éŸ³ç”Ÿæˆä¸é£æ ¼è½¬æ¢</li>
            <li>âœ… ComfyUIäººç‰©ä¸€è‡´æ€§é›†æˆ</li>
            <li>âœ… AIé©±åŠ¨åŠ¨ç”»ç”Ÿæˆ</li>
            <li>âœ… è‡ªåŠ¨å£å‹åŒæ­¥</li>
            <li>âœ… åŠ¨æ€è§’è‰²è¡¨æƒ…å’ŒåŠ¨ä½œ</li>
        </ul>
        <p><b>AIåŠ¨ç”»ç”Ÿæˆç‰¹æ€§:</b></p>
        <ul>
            <li>ğŸ¤– AIç”Ÿæˆå¼æ–‡æœ¬åˆ†æå’Œæç¤ºæå–</li>
            <li>ğŸ­ å¤šè§’è‰²æ”¯æŒä¸äººç‰©ç»‘å®š</li>
            <li>ğŸ‘„ éŸ³ç´ åˆ†æä¸å£å‹åŒæ­¥</li>
            <li>ğŸ‘ï¸ å¤´éƒ¨ã€çœ¼éƒ¨ã€èº«ä½“åŠ¨ä½œç”Ÿæˆ</li>
            <li>ğŸ–¼ï¸ é€å¸§ç”Ÿæˆæµç•…åŠ¨ç”»</li>
        </ul>
        <p><b>ç³»ç»Ÿè¦æ±‚:</b> Python 3.8+, NVIDIA GPU (æ¨è), FFmpeg, ComfyUI</p>
        <p><b>è®¸å¯è¯:</b> MIT</p>
        """
        
        QMessageBox.about(self, "å…³äº AIé…éŸ³å·¥å‚", about_text)
    
    # ============== åŠ¨ç”»ç”Ÿæˆç›¸å…³æ–¹æ³• ==============
    
    def connect_comfyui(self):
        """è¿æ¥åˆ°ComfyUI"""
        host = self.comfyui_host_edit.text()
        port = self.comfyui_port_edit.value()
        
        self.add_log_message(f"æ­£åœ¨è¿æ¥åˆ°ComfyUI: {host}:{port}", "INFO")
        
        try:
            response = requests.get(f"http://{host}:{port}", timeout=5)
            if response.status_code == 200:
                self.comfyui_status_label.setText("å·²è¿æ¥")
                self.comfyui_status_label.setStyleSheet("color: #4CAF50; font-weight: bold;")
                self.add_log_message("âœ… ComfyUIè¿æ¥æˆåŠŸ", "INFO")
            else:
                self.comfyui_status_label.setText("è¿æ¥å¤±è´¥")
                self.comfyui_status_label.setStyleSheet("color: #f44336; font-weight: bold;")
                self.add_log_message(f"âŒ ComfyUIè¿æ¥å¤±è´¥: HTTP {response.status_code}", "ERROR")
        except requests.exceptions.ConnectionError:
            self.comfyui_status_label.setText("æœªè¿æ¥")
            self.comfyui_status_label.setStyleSheet("color: #f44336; font-weight: bold;")
            self.add_log_message("âŒ æ— æ³•è¿æ¥åˆ°ComfyUIæœåŠ¡å™¨", "ERROR")
            QMessageBox.critical(self, "è¿æ¥å¤±è´¥", 
                f"æ— æ³•è¿æ¥åˆ°ComfyUIæœåŠ¡å™¨\n\n"
                f"è¯·ç¡®ä¿ComfyUIå·²å¯åŠ¨:\n"
                f"python main.py --port {port}\n\n"
                f"æˆ–ä½¿ç”¨è‡ªå®šä¹‰å¯åŠ¨å‘½ä»¤")
    
    def auto_bind_characters(self):
        """è‡ªåŠ¨ç»‘å®šè§’è‰²"""
        if not self.character_profiles:
            QMessageBox.warning(self, "é”™è¯¯", "æ²¡æœ‰é…ç½®é…éŸ³è§’è‰²")
            return
        
        self.animation_character_table.setRowCount(0)
        
        row = 0
        for char_name, profile in self.character_profiles.items():
            self.animation_character_table.insertRow(row)
            
            self.animation_character_table.setItem(row, 0, QTableWidgetItem(char_name))
            
            ref_item = QTableWidgetItem("æœªè®¾ç½®")
            if profile.voice_file:
                ref_item = QTableWidgetItem(Path(profile.voice_file).name)
            self.animation_character_table.setItem(row, 1, ref_item)
            
            self.animation_character_table.setItem(row, 2, QTableWidgetItem(char_name))
            
            btn_widget = QWidget()
            btn_layout = QHBoxLayout(btn_widget)
            btn_layout.setContentsMargins(0, 0, 0, 0)
            
            select_btn = QPushButton("é€‰æ‹©å›¾ç‰‡")
            select_btn.clicked.connect(lambda checked, r=row: self.select_reference_image(r))
            select_btn.setFixedSize(80, 24)
            btn_layout.addWidget(select_btn)
            
            self.animation_character_table.setCellWidget(row, 3, btn_widget)
            
            row += 1
        
        self.add_log_message(f"è‡ªåŠ¨ç»‘å®šäº† {row} ä¸ªè§’è‰²", "INFO")
    
    def select_reference_image(self, row):
        """é€‰æ‹©å‚è€ƒå›¾ç‰‡"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©è§’è‰²å‚è€ƒå›¾ç‰‡", "", 
            "å›¾ç‰‡æ–‡ä»¶ (*.jpg *.jpeg *.png *.bmp);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
        )
        
        if file_path:
            self.animation_character_table.setItem(row, 1, QTableWidgetItem(Path(file_path).name))
            
            char_name = self.animation_character_table.item(row, 0).text()
            if char_name in self.character_profiles:
                self.character_profiles[char_name].reference_image = file_path
            
            self.add_log_message(f"ä¸ºè§’è‰² {char_name} è®¾ç½®å‚è€ƒå›¾ç‰‡: {file_path}", "INFO")
    
    def manual_bind_character(self):
        """æ‰‹åŠ¨ç»‘å®šè§’è‰²"""
        row = self.animation_character_table.rowCount()
        self.animation_character_table.insertRow(row)
        
        char_combo = QComboBox()
        for char_name in self.character_profiles.keys():
            char_combo.addItem(char_name)
        
        self.animation_character_table.setCellWidget(row, 0, char_combo)
        
        self.animation_character_table.setItem(row, 1, QTableWidgetItem("æœªè®¾ç½®"))
        
        name_edit = QLineEdit()
        if char_combo.count() > 0:
            name_edit.setText(char_combo.currentText())
        self.animation_character_table.setCellWidget(row, 2, name_edit)
        
        btn_widget = QWidget()
        btn_layout = QHBoxLayout(btn_widget)
        btn_layout.setContentsMargins(0, 0, 0, 0)
        
        select_btn = QPushButton("é€‰æ‹©å›¾ç‰‡")
        select_btn.clicked.connect(lambda checked, r=row: self.select_reference_image(r))
        select_btn.setFixedSize(80, 24)
        btn_layout.addWidget(select_btn)
        
        remove_btn = QPushButton("åˆ é™¤")
        remove_btn.clicked.connect(lambda checked, r=row: self.remove_character_binding(r))
        remove_btn.setFixedSize(60, 24)
        btn_layout.addWidget(remove_btn)
        
        self.animation_character_table.setCellWidget(row, 3, btn_widget)
    
    def remove_character_binding(self, row):
        """åˆ é™¤è§’è‰²ç»‘å®š"""
        self.animation_character_table.removeRow(row)
    
    def clear_character_bindings(self):
        """æ¸…ç©ºè§’è‰²ç»‘å®š"""
        reply = QMessageBox.question(
            self, "ç¡®è®¤æ¸…ç©º",
            "ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰è§’è‰²ç»‘å®šå—ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            self.animation_character_table.setRowCount(0)
            self.add_log_message("å·²æ¸…ç©ºè§’è‰²ç»‘å®š", "INFO")
    
    def generate_animation(self):
        """ç”ŸæˆåŠ¨ç”»"""
        if self.comfyui_status_label.text() != "å·²è¿æ¥":
            QMessageBox.warning(self, "é”™è¯¯", "è¯·å…ˆè¿æ¥åˆ°ComfyUIæœåŠ¡å™¨")
            return
        
        if self.animation_character_table.rowCount() == 0:
            QMessageBox.warning(self, "é”™è¯¯", "è¯·å…ˆç»‘å®šè‡³å°‘ä¸€ä¸ªè§’è‰²")
            return
        
        video_path = self.output_edit.text()
        if not video_path or not os.path.exists(video_path):
            reply = QMessageBox.question(
                self, "æ²¡æœ‰é…éŸ³ä½œå“",
                "å°šæœªç”Ÿæˆé…éŸ³ä½œå“ã€‚æ˜¯å¦ä»å½“å‰é…ç½®åˆ›å»ºæ–°åŠ¨ç”»ï¼Ÿ",
                QMessageBox.Yes | QMessageBox.No
            )
            
            if reply == QMessageBox.No:
                return
            
            video_path = ""
        
        if not COMFYUI_AVAILABLE:
            QMessageBox.critical(self, "é”™è¯¯", "ComfyUIå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œæ— æ³•ç”ŸæˆåŠ¨ç”»")
            return
        
        style_map = {
            "åŠ¨æ¼«": AnimationStyle.ANIME,
            "ç”µå½±": AnimationStyle.CINEMATIC,
            "å¡é€š": AnimationStyle.CARTOON,
            "å†™å®": AnimationStyle.REALISTIC,
            "ç»˜ç”»": AnimationStyle.PAINTERLY,
            "åƒç´ è‰ºæœ¯": AnimationStyle.PIXEL_ART
        }
        
        method_map = {
            "IP-Adapter": CharacterMethod.IP_ADAPTER,
            "InstantID": CharacterMethod.INSTANT_ID,
            "PhotoMaker": CharacterMethod.PHOTO_MAKER,
            "LoRA": CharacterMethod.LORA,
            "ControlNet": CharacterMethod.CONTROLNET
        }
        
        animation_config = AnimationConfig(
            resolution=(
                self.animation_width_spin.value(),
                self.animation_height_spin.value()
            ),
            fps=self.animation_fps_spin.value(),
            duration=30.0,
            style=style_map.get(self.animation_style_combo.currentText(), AnimationStyle.ANIME),
            consistency_method=method_map.get(self.consistency_method_combo.currentText(), CharacterMethod.IP_ADAPTER),
            consistency_strength=self.consistency_strength_slider.value() / 100.0,
            lip_sync_enabled=self.animation_lip_sync_check.isChecked(),
            expression_enabled=self.expression_check.isChecked(),
            head_movement_enabled=self.head_movement_check.isChecked(),
            eye_movement_enabled=self.eye_movement_check.isChecked(),
            scene_description=self.scene_description_edit.text(),
            camera_movement="subtle",
            lighting="natural"
        )
        
        self.animation_generator = AIAnimationGenerator(
            animation_config,
            comfyui_host=self.comfyui_host_edit.text(),
            comfyui_port=self.comfyui_port_edit.value()
        )
        
        for row in range(self.animation_character_table.rowCount()):
            char_widget = self.animation_character_table.cellWidget(row, 0)
            if isinstance(char_widget, QComboBox):
                char_name = char_widget.currentText()
            else:
                char_name = self.animation_character_table.item(row, 0).text()
            
            if char_name in self.character_profiles:
                profile = self.character_profiles[char_name]
                
                ref_item = self.animation_character_table.item(row, 1)
                ref_image = ""
                if ref_item and ref_item.text() != "æœªè®¾ç½®":
                    ref_image = "characters/" + ref_item.text()
                
                name_widget = self.animation_character_table.cellWidget(row, 2)
                if isinstance(name_widget, QLineEdit):
                    anim_name = name_widget.text()
                else:
                    anim_name = self.animation_character_table.item(row, 2).text()
                
                character_model = CharacterModel(
                    name=anim_name,
                    voice_profile=profile
                )
                
                if ref_image and os.path.exists(ref_image):
                    character_model.add_reference_image(ref_image)
                
                self.animation_generator.add_character(character_model)
        
        script_path = Path("ai_animation_output") / "animation_script.txt"
        if video_path and os.path.exists(video_path):
            script_content = self._extract_script_from_video(video_path)
        else:
            script_content = self._create_example_script()
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        self.animation_generate_btn.setEnabled(False)
        self.animation_stop_btn.setEnabled(True)
        self.animation_progress_bar.setValue(0)
        
        self.add_log_message("ğŸš€ å¼€å§‹ç”ŸæˆAIé©±åŠ¨åŠ¨ç”»...", "INFO")
        
        self.animation_thread = AnimationGenerationThread(
            self.animation_generator,
            str(script_path)
        )
        
        self.animation_thread.progress_updated.connect(self.update_animation_progress)
        self.animation_thread.log_message.connect(self.add_log_message)
        self.animation_thread.finished.connect(self.animation_generation_finished)
        self.animation_thread.error.connect(self.animation_generation_error)
        
        self.animation_thread.start()
    
    def _extract_script_from_video(self, video_path: str) -> str:
        """ä»è§†é¢‘æå–å‰§æœ¬"""
        return self._create_example_script()
    
    def _create_example_script(self) -> str:
        """åˆ›å»ºç¤ºä¾‹å‰§æœ¬"""
        script = ""
        
        characters = list(self.character_profiles.keys())[:3]
        
        if len(characters) >= 2:
            script = f"""{characters[0]}: ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼
{characters[1]}: æ˜¯å•Šï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆå¤–å‡ºã€‚
{characters[0]}: ä½ æœ‰ä»€ä¹ˆè®¡åˆ’å—ï¼Ÿ
{characters[1]}: æˆ‘æƒ³å»å…¬å›­æ•£æ­¥ã€‚
{characters[0]}: å¥½ä¸»æ„ï¼Œæˆ‘ä¹Ÿä¸€èµ·å»å§ï¼"""
        
        return script
    
    def update_animation_progress(self, value: int, message: str):
        """æ›´æ–°åŠ¨ç”»è¿›åº¦"""
        self.animation_progress_bar.setValue(value)
        self.status_label.setText(f"åŠ¨ç”»ç”Ÿæˆ: {message}")
    
    def animation_generation_finished(self, output_path: str):
        """åŠ¨ç”»ç”Ÿæˆå®Œæˆ"""
        self.animation_generate_btn.setEnabled(True)
        self.animation_stop_btn.setEnabled(False)
        self.animation_progress_bar.setValue(100)
        
        self.add_log_message(f"âœ… AIåŠ¨ç”»ç”Ÿæˆå®Œæˆ: {output_path}", "INFO")
        
        reply = QMessageBox.question(
            self, "åŠ¨ç”»ç”Ÿæˆå®Œæˆ",
            f"AIé©±åŠ¨åŠ¨ç”»å·²ç”Ÿæˆ:\n{output_path}\n\næ˜¯å¦ç«‹å³æ’­æ”¾ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            self.preview_animation(output_path)
    
    def animation_generation_error(self, error_msg: str):
        """åŠ¨ç”»ç”Ÿæˆé”™è¯¯"""
        self.animation_generate_btn.setEnabled(True)
        self.animation_stop_btn.setEnabled(False)
        
        self.add_log_message(f"âŒ åŠ¨ç”»ç”Ÿæˆå¤±è´¥: {error_msg}", "ERROR")
        QMessageBox.critical(self, "åŠ¨ç”»ç”Ÿæˆå¤±è´¥", error_msg)
    
    def stop_animation_generation(self):
        """åœæ­¢åŠ¨ç”»ç”Ÿæˆ"""
        if self.animation_thread and self.animation_thread.isRunning():
            self.animation_thread.terminate()
            self.animation_thread.wait()
            
            self.animation_generate_btn.setEnabled(True)
            self.animation_stop_btn.setEnabled(False)
            
            self.add_log_message("åŠ¨ç”»ç”Ÿæˆå·²åœæ­¢", "WARNING")
    
    def preview_animation(self, video_path: str = None):
        """é¢„è§ˆåŠ¨ç”»"""
        if not video_path:
            file_path, _ = QFileDialog.getOpenFileName(
                self, "é€‰æ‹©åŠ¨ç”»è§†é¢‘", "", 
                "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mkv);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
            )
            
            if not file_path:
                return
            
            video_path = file_path
        
        import subprocess
        import platform
        
        try:
            if platform.system() == 'Darwin':
                subprocess.call(('open', video_path))
            elif platform.system() == 'Windows':
                os.startfile(video_path)
            else:
                subprocess.call(('xdg-open', video_path))
        except Exception as e:
            logger.error(f"æ— æ³•æ’­æ”¾è§†é¢‘: {e}")
            QMessageBox.information(self, "æ’­æ”¾å¤±è´¥", f"æ— æ³•æ’­æ”¾è§†é¢‘:\n{e}")
    
    def closeEvent(self, event):
        """å…³é—­äº‹ä»¶"""
        reply = QMessageBox.question(
            self, "ç¡®è®¤é€€å‡º",
            "ç¡®å®šè¦é€€å‡ºå—ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            if self.processing_thread and self.processing_thread.isRunning():
                self.processing_thread.terminate()
                self.processing_thread.wait()
            
            if self.animation_thread and self.animation_thread.isRunning():
                self.animation_thread.terminate()
                self.animation_thread.wait()
            
            self.save_config()
            
            logger.info("åº”ç”¨ç¨‹åºé€€å‡º")
            event.accept()
        else:
            event.ignore()

# ============================================
# ä¸»ç¨‹åºå…¥å£
# ============================================

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("ğŸ” æ£€æŸ¥ç³»ç»Ÿä¾èµ–...")
    
    import sys
    if sys.version_info < (3, 8):
        print("âŒ éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
        return False
    
    try:
        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        print("âœ… FFmpegå·²å®‰è£…")
    except:
        print("âŒ FFmpegæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…FFmpeg")
        print("   ä¸‹è½½åœ°å€: https://ffmpeg.org/download.html")
        return False
    
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨ - {torch.cuda.get_device_name(0)}")
            print(f"   GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼ï¼ˆæ€§èƒ½è¾ƒä½ï¼‰")
    except:
        print("âš ï¸  æ— æ³•æ£€æµ‹CUDAçŠ¶æ€")
    
    print("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥å®Œæˆ")
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘         ğŸ­ AIé…éŸ³å·¥å‚ - è¶…å¼ºå˜´ç‚®ç‰ˆ ğŸš€                   â•‘
    â•‘         AIåŠ¨ç”»ç”Ÿæˆé›†æˆç‰ˆ - å½±éŸ³åŒæ­¥åˆ›ä½œå¹³å°               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    if not check_dependencies():
        print("\næŒ‰Enteré”®é€€å‡º...")
        input()
        return
    
    print("\nğŸ” æ£€æŸ¥å¿…è¦æœåŠ¡...")
    
    print("æ£€æŸ¥OllamaæœåŠ¡...")
    try:
        base_url = "http://127.0.0.1:11434"
        api_url = f"{base_url}/api/tags"
        try:
            response = requests.get(api_url, timeout=3)
            if response.status_code == 200:
                models_data = response.json()
                model_names = [m.get('name', '') for m in models_data.get('models', [])]
                print(f"  âœ… OllamaæœåŠ¡æ­£å¸¸")
                print(f"     å¯ç”¨æ¨¡å‹: {', '.join(model_names[:5])}" + ("..." if len(model_names) > 5 else ""))
                
                required_models = ["qwen", "llama", "deepseek"]
                found_models = [name for name in model_names if any(req in name.lower() for req in required_models)]
                if found_models:
                    print(f"     æ‰¾åˆ°ç¿»è¯‘æ¨¡å‹: {', '.join(found_models[:3])}")
                else:
                    print("     âš ï¸  å»ºè®®å®‰è£…ç¿»è¯‘æ¨¡å‹: ollama pull qwen3:4b")
            else:
                print(f"  âš ï¸  Ollama APIè¿”å›: {response.status_code}")
        except requests.exceptions.ConnectionError:
            print("  âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡")
            print("     è¯·è¿è¡Œ: ollama serve")
        except Exception as e:
            print(f"  âš ï¸  Ollamaæ£€æŸ¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"  âš ï¸  OllamaæœåŠ¡æ£€æŸ¥å¼‚å¸¸: {e}")
    
    print("æ£€æŸ¥TTSæœåŠ¡...")
    try:
        api_url = "http://127.0.0.1:5021/api/tts"
        try:
            test_payload = {
                "tts_text": "æµ‹è¯•è¿æ¥",
                "prompt_audio": "",
                "emo_control_method": 0,
                "do_sample": True
            }
            response = requests.post(api_url, json=test_payload, timeout=5)
            
            if response.status_code == 200:
                result = response.json()
                if result.get("status") == "success":
                    print("  âœ… TTS APIç«¯ç‚¹æ­£å¸¸å·¥ä½œ")
                else:
                    print(f"  âš ï¸  TTS APIè¿”å›éæˆåŠŸçŠ¶æ€: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            elif response.status_code == 400:
                print("  âš ï¸  TTS APIè¿”å›400é”™è¯¯ï¼ˆè¯·æ±‚æ ¼å¼é—®é¢˜ï¼‰")
                print("     è¯·æ£€æŸ¥GUIä¸­çš„æµ‹è¯•æŒ‰é’®")
            else:
                print(f"  âš ï¸  TTS APIç«¯ç‚¹è¿”å›: {response.status_code}")
                
        except requests.exceptions.ConnectionError:
            print("  âŒ æ— æ³•è¿æ¥åˆ°TTS APIç«¯ç‚¹")
            print("     è¯·ç¡®ä¿TTSæœåŠ¡å·²å¯åŠ¨")
        except requests.exceptions.Timeout:
            print("  âš ï¸  TTS APIè¿æ¥è¶…æ—¶")
        except Exception as e:
            print(f"  âš ï¸  TTS APIæ£€æŸ¥é”™è¯¯: {e}")
            
    except Exception as e:
        print(f"  âš ï¸  TTSæœåŠ¡æ£€æŸ¥å¼‚å¸¸: {e}")
    
    print("æ£€æŸ¥ComfyUIæœåŠ¡...")
    try:
        response = requests.get("http://127.0.0.1:8188", timeout=3)
        if response.status_code == 200:
            print("  âœ… ComfyUIæœåŠ¡å™¨æ­£å¸¸")
            print("     å¦‚éœ€ä½¿ç”¨AIåŠ¨ç”»ç”ŸæˆåŠŸèƒ½ï¼Œè¯·ç¡®ä¿å·²å®‰è£…å¿…è¦èŠ‚ç‚¹")
        else:
            print(f"  âš ï¸  ComfyUIæœåŠ¡å™¨è¿”å›: {response.status_code}")
    except requests.exceptions.ConnectionError:
        print("  âŒ æ— æ³•è¿æ¥åˆ°ComfyUIæœåŠ¡å™¨")
        print("     å¦‚éœ€ä½¿ç”¨AIåŠ¨ç”»ç”ŸæˆåŠŸèƒ½ï¼Œè¯·å¯åŠ¨ComfyUI")
    except Exception as e:
        print(f"  âš ï¸  ComfyUIæœåŠ¡æ£€æŸ¥å¼‚å¸¸: {e}")
    
    print("\nğŸ¯ æœåŠ¡çŠ¶æ€æ€»ç»“:")
    print("   1. Ollama: âœ“ ä½¿ç”¨åŸç”ŸAPI (http://127.0.0.1:11434/api/generate)")
    print("   2. TTS API: ä½¿ç”¨GUIä¸­çš„æµ‹è¯•æŒ‰é’®éªŒè¯")
    print("   3. ComfyUI: ç”¨äºAIåŠ¨ç”»ç”Ÿæˆ")
    print("   4. FFmpeg: âœ“ æ­£å¸¸")
    print("   5. CUDA: âœ“ æ­£å¸¸")
    
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("   1. é¦–æ¬¡ä½¿ç”¨æ—¶ï¼Œå…ˆåœ¨è®¾ç½®æ ‡ç­¾é¡µæµ‹è¯•Ollamaå’ŒTTSé…ç½®")
    print("   2. ç¡®ä¿éŸ³è‰²æ–‡ä»¶(.wav)å·²æ”¾åœ¨voicesæ–‡ä»¶å¤¹ä¸­")
    print("   3. è§’è‰²å‚è€ƒå›¾ç‰‡æ”¾åœ¨charactersæ–‡ä»¶å¤¹ä¸­")
    print("   4. AIåŠ¨ç”»ç”Ÿæˆéœ€è¦ComfyUIæ”¯æŒäººç‰©ä¸€è‡´æ€§èŠ‚ç‚¹")
    print("   5. å¯é€‰çš„OpenAIé›†æˆç”¨äºå¢å¼ºå‰§æœ¬åˆ†æå’Œæç¤ºç”Ÿæˆ")
    
    print("\nğŸš€ æ­£åœ¨å¯åŠ¨åº”ç”¨ç¨‹åº...")
    
    app = QApplication(sys.argv)
    app.setApplicationName("AIé…éŸ³å·¥å‚")
    app.setApplicationVersion("3.4.0")
    
    if os.path.exists("icon.png"):
        app.setWindowIcon(QIcon("icon.png"))
    
    window = MainWindow()
    window.show()
    
    window.add_log_message("ğŸ­ AIé…éŸ³å·¥å‚å¯åŠ¨æˆåŠŸï¼", "INFO")
    window.add_log_message("ğŸ“– ä½¿ç”¨è¯´æ˜:", "INFO")
    window.add_log_message("  1. é€‰æ‹©è¦é…éŸ³çš„è§†é¢‘æ–‡ä»¶", "INFO")
    window.add_log_message("  2. ä¸ºæ¯ä¸ªè§’è‰²é…ç½®éŸ³è‰²å’Œé£æ ¼", "INFO")
    window.add_log_message("  3. ç‚¹å‡»å¼€å§‹å¤„ç†ï¼Œç­‰å¾…å®Œæˆ", "INFO")
    window.add_log_message("  4. äº«å—ä½ çš„å˜´ç‚®ç‰ˆæœºå™¨çŒ«ï¼", "INFO")
    window.add_log_message("  5. å¯åœ¨åŠ¨ç”»æ ‡ç­¾é¡µç”ŸæˆAIåŠ¨ç”»", "INFO")
    
    window.add_log_message("ğŸ’¡ é‡è¦æç¤º:", "INFO")
    window.add_log_message("  - é¦–æ¬¡ä½¿ç”¨æ—¶ï¼Œè¯·åœ¨è®¾ç½®æ ‡ç­¾é¡µæµ‹è¯•APIé…ç½®", "INFO")
    window.add_log_message("  - ç¡®ä¿OllamaæœåŠ¡å·²å¯åŠ¨: ollama serve", "INFO")
    window.add_log_message("  - ç¡®ä¿TTSæœåŠ¡å·²å¯åŠ¨: python api.py --port 5021", "INFO")
    window.add_log_message("  - ç¡®ä¿éŸ³è‰²æ–‡ä»¶(.wav)å·²æ”¾åœ¨voicesæ–‡ä»¶å¤¹ä¸­", "INFO")
    window.add_log_message("  - AIåŠ¨ç”»ç”Ÿæˆéœ€è¦ComfyUIè¿è¡Œåœ¨8188ç«¯å£", "INFO")
    
    sys.exit(app.exec())

if __name__ == "__main__":
    main()